{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac6bbe9-83bd-48a0-a37d-89e1101dd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))   \n",
    "def sir_1(X, y, H, K):\n",
    "    Z = X-np.mean(X, axis=0)\n",
    "    width = (np.max(y) - np.min(y)) / H\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    for h in range(H):\n",
    "        h_index = np.logical_and(np.min(y)+h*width <= y, y < np.min(y)+(h+1)*width)\n",
    "        ph_hat = np.mean(h_index)\n",
    "        if ph_hat == 0:\n",
    "            continue\n",
    "        mh = np.mean(Z[h_index, :], axis=0)\n",
    "        V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors       \n",
    "    return  edr_est\n",
    "\n",
    "def sir_1_time_series(X, y, H, K):\n",
    "    Z = X-np.mean(X, axis=0)\n",
    "    width = (np.max(y) - np.min(y)) / H\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    for h in range(H):\n",
    "        h_index = np.logical_and(np.min(y)+h*width <= y, y < np.min(y)+(h+1)*width)\n",
    "        h_index = h_index[len(y) - X.shape[0]:]\n",
    "        # h_index = h_index[:X.shape[0]]\n",
    "        ph_hat = np.mean(h_index)\n",
    "        if ph_hat == 0:\n",
    "            continue\n",
    "        # if np.all((h_index == 1) < X.shape[0]):\n",
    "        mh = np.mean(Z[h_index, :], axis=0)\n",
    "        V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
    "        # else:\n",
    "        #     h_index = h_index\n",
    "        #     mh = np.mean(Z[h_index, :], axis=0)\n",
    "        #     V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors         \n",
    "    return  (V_hat, edr_est, eigenvalues ** 2)\n",
    "\n",
    "def sir_1_time_series1(X, y, num_slices, K):\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    \n",
    "    if len(sorted_indices) > X.shape[0]:\n",
    "        X_sorted = X[sorted_indices[-n_samples:]]\n",
    "    else:\n",
    "        X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means - np.mean(X_means, axis=0)\n",
    "\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return (V_hat, edr_est, eigenvalues ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db12da7-45ba-466b-a5aa-8407061674b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9999 is out of bounds for axis 0 with size 9999",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m V \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,S\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 68\u001b[0m     M, edr, lam1 \u001b[38;5;241m=\u001b[39m \u001b[43msir_1_time_series1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_obs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     V\u001b[38;5;241m.\u001b[39mappend(M)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, S\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36msir_1_time_series1\u001b[1;34m(X, y, num_slices, K)\u001b[0m\n\u001b[0;32m      6\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(y)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sorted_indices) \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m----> 9\u001b[0m     X_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     X_sorted \u001b[38;5;241m=\u001b[39m X[sorted_indices]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9999 is out of bounds for axis 0 with size 9999"
     ]
    }
   ],
   "source": [
    "#from 0 to Q \n",
    "def sir_1_time_series1(X, y, num_slices, K):\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    \n",
    "    if len(sorted_indices) > X.shape[0]:\n",
    "        X_sorted = X[sorted_indices[-n_samples:]]\n",
    "    else:\n",
    "        X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means - np.mean(X_means, axis=0)\n",
    "\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return (V_hat, edr_est, eigenvalues ** 2)\n",
    "    \n",
    "from tabulate import tabulate\n",
    "ar_coeff = [0.2,0.2,0.2,0.2]\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "P = 4\n",
    "K = 1\n",
    "S = 20\n",
    "hat = [np.zeros((P, 1)) for i in range(S)]\n",
    "# ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "for w in range(n):    \n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    V = []\n",
    "    for a in range(0,S+1):\n",
    "        M, edr, lam1 = sir_1_time_series1(X[:n_obs - a], y, H, K)\n",
    "        V.append(M)\n",
    "    for q in range(1, S+1):\n",
    "        Q = np.zeros((P, P))\n",
    "        phi = ar_coeff\n",
    "        for j in range(P):\n",
    "            for k in range(P):\n",
    "                Q[j,k] = sum(sum(phi[j]**a * V[a][j,k] * phi[k]**a for a in range(0,l)) for l in range(0, q))\n",
    "        eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
    "        K_index = np.argpartition(np.abs(eigenvalues1), P-K) >= P-K\n",
    "        K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "        edr_est =  K_largest_eigenvectors\n",
    "        if edr_est[0]<0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est/np.linalg.norm(edr_est)\n",
    "        hat[q-1] += edr_est       \n",
    "for i in range(S):\n",
    "    hat[i] = hat[i]/n\n",
    "\n",
    "array = np.array(hat)\n",
    "print(tabulate(array, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b83254c-b3d0-4602-b240-e7b8e9279eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea235a-6a2a-41fd-8b50-bdd6cfd448c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab0308-1b6a-4435-8b9f-0150ac4084ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedee1dc-9d80-4d7f-8784-2cb8eb872015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
