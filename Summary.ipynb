{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weirdmini/SIR-time-series/blob/main/Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "106731a6-d34a-4d8f-89fc-280d6065e35e",
      "metadata": {
        "id": "106731a6-d34a-4d8f-89fc-280d6065e35e"
      },
      "source": [
        "# Defined functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d652bf8-1044-494a-8193-c00ed38f2447",
      "metadata": {
        "id": "7d652bf8-1044-494a-8193-c00ed38f2447"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.arima_process import ArmaProcess\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.linalg import sqrtm\n",
        "def euclidean_distance(point1, point2):\n",
        "    return np.sqrt(np.sum((point1 - point2)**2))\n",
        "# equal slice\n",
        "def sir_1(X, y, H, K):\n",
        "    Z = X-np.mean(X, axis=0)\n",
        "    width = (np.max(y) - np.min(y)) / H\n",
        "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "    for h in range(H):\n",
        "        h_index = np.logical_and(np.min(y)+h*width <= y, y < np.min(y)+(h+1)*width)\n",
        "        ph_hat = np.mean(h_index)\n",
        "        if ph_hat == 0:\n",
        "            continue\n",
        "        mh = np.mean(Z[h_index, :], axis=0)\n",
        "        V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "    edr_est =  K_largest_eigenvectors\n",
        "    return  edr_est\n",
        "\n",
        "# equal slice\n",
        "def sir_1_time_series(X, y, s, H, K):\n",
        "    from collections import deque\n",
        "    def move_left(queue, steps):\n",
        "        # Length of the queue\n",
        "        n = len(queue)\n",
        "        # Create a new list filled with 0\n",
        "        new_queue = [0] * n\n",
        "\n",
        "        # Move elements to the left by the specified number of steps\n",
        "        for i in range(n):\n",
        "            new_position = i - steps\n",
        "            if new_position >= 0:\n",
        "                new_queue[new_position] = queue[i]\n",
        "\n",
        "        return new_queue\n",
        "\n",
        "    Z = X-np.mean(X, axis=0)\n",
        "    width = (np.max(y) - np.min(y)) / H\n",
        "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "    for h in range(H):\n",
        "        h_index = np.logical_and(np.min(y)+h*width <= y, y < np.min(y)+(h+1)*width)\n",
        "        # queue moves s locations backward\n",
        "        h_index = move_left(h_index, s)\n",
        "        # h_index = h_index[len(y) - X.shape[0]:]\n",
        "        # h_index = h_index[:X.shape[0]]\n",
        "        ph_hat = np.mean(h_index)\n",
        "        if ph_hat == 0:\n",
        "            continue\n",
        "        # if np.all((h_index == 1) < X.shape[0]):\n",
        "        mh = np.mean(Z[h_index, :], axis=0)\n",
        "        V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
        "        # else:\n",
        "        #     h_index = h_index\n",
        "        #     mh = np.mean(Z[h_index, :], axis=0)\n",
        "        #     V_hat = np.add(V_hat,ph_hat * np.matmul(mh[:, np.newaxis], mh[np.newaxis, :]))\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "    edr_est =  K_largest_eigenvectors\n",
        "    return  (V_hat, edr_est, eigenvalues ** 2)\n",
        "\n",
        "#equal number in each slice\n",
        "#queue structure\n",
        "def sir_1_time_series1(X, y, s, num_slices, K):\n",
        "    n_samples, n_features = X.shape\n",
        "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "    # Step 1: Sort the data by the response variable\n",
        "    sorted_indices = np.argsort(y)\n",
        "    # sorted_indices1 = np.argsort(y[0:X.shape[0]])\n",
        "    # if len(sorted_indices) > X.shape[0]:\n",
        "    #     X_sorted = X[0:X.shape[0]][sorted_indices1]\n",
        "    # else:\n",
        "    X_sorted = X[sorted_indices]\n",
        "    y_sorted = y[sorted_indices]\n",
        "    # Step 2: Divide the data into slices\n",
        "    slice_size = n_samples // num_slices\n",
        "    ph_hat = slice_size/n_samples\n",
        "    slices = []\n",
        "    # original indices are the order of t, the sorted indices are the order of y from its size\n",
        "    # argsort gives the indices for the order of y from its size\n",
        "    for i in range(num_slices):\n",
        "        start_idx = i * slice_size\n",
        "        if i < num_slices - 1:\n",
        "            end_idx = (i + 1) * slice_size\n",
        "        else:  # Last slice includes any remaining samples\n",
        "            end_idx = n_samples\n",
        "        if start_idx-s>0:\n",
        "            slices.append((X[[x - s for x in sorted_indices[start_idx:end_idx]]], y_sorted[start_idx:end_idx]))\n",
        "        else:\n",
        "            slices.append((X[sorted_indices[0:end_idx-s]], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "    # Step 3: Compute the means of the predictors within each slice\n",
        "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "    # Step 4: Center the predictor means\n",
        "    X_centered = X_means - np.mean(X_means, axis=0)\n",
        "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "    # Check for NaN or inf values in V_hat\n",
        "    if np.isnan(V_hat).any() or np.isinf(V_hat).any():\n",
        "        # Handle NaN or inf values appropriately\n",
        "        # For example, replace NaN values with 0 and inf values with a large number\n",
        "        V_hat[np.isnan(V_hat)] = 0\n",
        "        V_hat[np.isinf(V_hat)] = np.nanmax(np.abs(V_hat))  # Replace inf with maximum absolute value in V_hat\n",
        "\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "    edr_est =  K_largest_eigenvectors\n",
        "\n",
        "    return (V_hat, edr_est, eigenvalues ** 2)\n",
        "\n",
        "# def sir_1_time_series2(X, y, num_slices, K):\n",
        "#     n_samples, n_features = X.shape\n",
        "#     V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "#     # Step 1: Sort the data by the response variable\n",
        "#     sorted_indices = np.argsort(y)\n",
        "#     # sorted_indices1 = np.argsort(y[0:X.shape[0]])\n",
        "#     # if len(sorted_indices) > X.shape[0]:\n",
        "#     #     X_sorted = X[0:X.shape[0]][sorted_indices1]\n",
        "#     # else:\n",
        "#     X_sorted = X[sorted_indices]\n",
        "#     y_sorted = y[sorted_indices]\n",
        "#     # Step 2: Divide the data into slices\n",
        "#     slice_size = n_samples // num_slices\n",
        "#     ph_hat = slice_size/n_samples\n",
        "#     slices = []\n",
        "#     # original indices are the order of t, the sorted indices are the order of y from its size\n",
        "#     # argsort gives the indices for the order of y from its size\n",
        "#     for i in range(num_slices):\n",
        "#         start_idx = i * slice_size\n",
        "#         if i < num_slices - 1:\n",
        "#             end_idx = (i + 1) * slice_size\n",
        "#         else:  # Last slice includes any remaining samples\n",
        "#             end_idx = n_samples\n",
        "#         if start_idx-s>0:\n",
        "#             slices.append((X[[x - s for x in sorted_indices[start_idx:end_idx]]], y_sorted[start_idx:end_idx]))\n",
        "#         else:\n",
        "#             slices.append((X[sorted_indices[0:end_idx-s]], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "#     # Step 3: Compute the means of the predictors within each slice\n",
        "#     X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "#     # Step 4: Center the predictor means\n",
        "#     X_centered = X_means - np.mean(X_means, axis=0)\n",
        "#     V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "#     # Check for NaN or inf values in V_hat\n",
        "#     if np.isnan(V_hat).any() or np.isinf(V_hat).any():\n",
        "#         # Handle NaN or inf values appropriately\n",
        "#         # For example, replace NaN values with 0 and inf values with a large number\n",
        "#         V_hat[np.isnan(V_hat)] = 0\n",
        "#         V_hat[np.isinf(V_hat)] = np.nanmax(np.abs(V_hat))  # Replace inf with maximum absolute value in V_hat\n",
        "\n",
        "#     eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "#     K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "#     K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "#     edr_est =  K_largest_eigenvectors\n",
        "\n",
        "#     return (V_hat, edr_est, eigenvalues ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f10fbad-b12f-49ff-98c5-52919c6c245f",
      "metadata": {
        "id": "0f10fbad-b12f-49ff-98c5-52919c6c245f",
        "outputId": "fb658718-dcc9-4541-c530-bfc17ae3473a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 3, 1, 2, 4], dtype=int64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = [1,4,5,3,7]\n",
        "sort1 = np.argsort(X)\n",
        "sort1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3defc2-ada7-4437-b5cb-95105232076f",
      "metadata": {
        "id": "3f3defc2-ada7-4437-b5cb-95105232076f"
      },
      "outputs": [],
      "source": [
        "#equal number in each slice for SIR\n",
        "def sir_11(X, y, num_slices, K):\n",
        "    n_samples, n_features = X.shape\n",
        "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "    # Step 1: Sort the data by the response variable\n",
        "    sorted_indices = np.argsort(y)\n",
        "    X_sorted = X[sorted_indices]\n",
        "    y_sorted = y[sorted_indices]\n",
        "\n",
        "    # Step 2: Divide the data into slices\n",
        "    slice_size = n_samples // num_slices\n",
        "    ph_hat = slice_size/n_samples\n",
        "    slices = []\n",
        "\n",
        "    for i in range(num_slices):\n",
        "        start_idx = i * slice_size\n",
        "        if i < num_slices - 1:\n",
        "            end_idx = (i + 1) * slice_size\n",
        "        else:  # Last slice includes any remaining samples\n",
        "            end_idx = n_samples\n",
        "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "    # Step 3: Compute the means of the predictors within each slice\n",
        "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "    # Step 4: Center the predictor means\n",
        "    X_centered = X_means - np.mean(X_means, axis=0)\n",
        "\n",
        "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "    edr_est =  K_largest_eigenvectors\n",
        "\n",
        "    return edr_est"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8222b45-5723-4b4e-90e2-b84fa569d11f",
      "metadata": {
        "id": "d8222b45-5723-4b4e-90e2-b84fa569d11f"
      },
      "source": [
        "### Above are functions for SIR, SIR different output(V_hat, edr_est, eigenvalues ** 2 and edr_est), SIR for equal number in each slice and SIR with equal slice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eacc3ebb-3bce-4040-94bd-8b030103584a",
      "metadata": {
        "id": "eacc3ebb-3bce-4040-94bd-8b030103584a"
      },
      "source": [
        "# SIR\n",
        "## The results are shown by 1. directions; 2. ratio between first two coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc84e58c-d632-4b1e-a0bd-5e3c7c56e03c",
      "metadata": {
        "id": "fc84e58c-d632-4b1e-a0bd-5e3c7c56e03c"
      },
      "source": [
        "# Curious why SIR fails when given time series data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd2d0bb-0755-4fd0-b02f-aebeeed17803",
      "metadata": {
        "id": "3bd2d0bb-0755-4fd0-b02f-aebeeed17803"
      },
      "source": [
        "# For iid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af898a9c-898d-41bd-84a0-48b2ea792658",
      "metadata": {
        "id": "af898a9c-898d-41bd-84a0-48b2ea792658",
        "outputId": "2108f40c-ea6d-4477-deaa-5dc4d8af6c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.4822566 ]\n",
            " [ 0.4923153 ]\n",
            " [ 0.47870703]\n",
            " [ 0.48558868]\n",
            " [-0.02222339]]\n"
          ]
        }
      ],
      "source": [
        "#average\n",
        "# example 1 : y = x_1 + x_2 + x_3 + x_4 + 0x_5 + epsilon\n",
        "hat = 0\n",
        "for a in range(100):\n",
        "    n = 100\n",
        "    H = 5\n",
        "    K = 1\n",
        "    beta = np.array([1, 1, 1, 1, 0])\n",
        "#     print('beta : ', beta)\n",
        "    X = np.random.normal(0, 1, [n, 5])\n",
        "    epsilon = np.random.normal(0, 1, n)\n",
        "    y = np.matmul(X, beta) + epsilon\n",
        "\n",
        "#     print('SIR Method 1, beta_hat : ')\n",
        "    sir_1_result = sir_1(X, y, H=H, K=K)\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "\n",
        "hat = hat/100\n",
        "print(hat)\n",
        "# print('SIR Method 1, projection matrix F norm : ')\n",
        "# print(projection_matrix_F_norm(beta[:, np.newaxis], sir_1_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee471cf-68c8-4a0c-9027-b6f826444d02",
      "metadata": {
        "id": "dee471cf-68c8-4a0c-9027-b6f826444d02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f4a4a0b6-d4a8-4005-95a3-fcefb64e73df",
      "metadata": {
        "id": "f4a4a0b6-d4a8-4005-95a3-fcefb64e73df"
      },
      "source": [
        "# For time series data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "671069b6-1c27-4bb5-8f9c-2575323e6896",
      "metadata": {
        "id": "671069b6-1c27-4bb5-8f9c-2575323e6896"
      },
      "source": [
        "For model\n",
        "\\begin{align}\n",
        "   & y_t = 2z_{1,t-1} + 3z_{2,t-1} +\\epsilon_t\n",
        "    \\label{model:time series 2}\n",
        "\\end{align}\n",
        "with four components $z_1 \\sim \\text{AR}(1)$ with $\\phi_1$, $z_2 \\sim \\text{AR}(1)$ with $\\phi_2$, $z_3 \\sim \\text{ARMA}(1, 1)$ with $\\phi = 0.3$ and $\\theta = 0.4$ and $z_4 \\sim \\text{MA}(1)$ with $\\theta = -0.4$. Dimension $p = 4$. $K = 1$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2e12d9-c131-4043-b458-bf65c2abeb19",
      "metadata": {
        "id": "ee2e12d9-c131-4043-b458-bf65c2abeb19"
      },
      "source": [
        "## Results under equal slice and equal number in each slice"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c61b90-4232-4a3d-be6b-b836c092734b",
      "metadata": {
        "id": "90c61b90-4232-4a3d-be6b-b836c092734b"
      },
      "source": [
        "### coefficient 0.2 0.2, correct direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565d947b-1906-4ac8-8647-3ce74a187d39",
      "metadata": {
        "id": "565d947b-1906-4ac8-8647-3ce74a187d39",
        "outputId": "07e0500a-3709-4316-ec3e-9dd6cbcb5698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 0.55022728]\n",
            " [ 0.82705784]\n",
            " [-0.00266489]\n",
            " [-0.00193875]]\n",
            "Equal slice ratio:[0.66528271]\n",
            "Equal number in each slice direction:[[ 5.47185641e-01]\n",
            " [ 8.29002510e-01]\n",
            " [-3.05165667e-03]\n",
            " [-7.34620269e-04]]\n",
            "Equal number in each slice ratio:[0.66005306]\n"
          ]
        }
      ],
      "source": [
        "#0.2 0.2 correct direction\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff1 = 0.2\n",
        "ar_coeff2 = 0.2\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "Hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
        "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb65e84c-b191-4bad-aa24-01d826f5d3c9",
      "metadata": {
        "id": "eb65e84c-b191-4bad-aa24-01d826f5d3c9"
      },
      "source": [
        "### coefficient 0.2 0.8, incorrect direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028c0ac8-d4ce-41aa-acef-99402f84dd75",
      "metadata": {
        "id": "028c0ac8-d4ce-41aa-acef-99402f84dd75",
        "outputId": "9c05c5b3-9a39-4b49-920e-4e291900d29f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 2.41554690e-01]\n",
            " [ 9.70260558e-01]\n",
            " [-7.19133248e-04]\n",
            " [ 2.93346564e-04]]\n",
            "Equal slice ratio:[0.24895858]\n",
            "Equal number in each slice direction:[[ 2.41509793e-01]\n",
            " [ 9.70272399e-01]\n",
            " [-7.28361284e-04]\n",
            " [ 3.32651879e-04]]\n",
            "Equal number in each slice ratio:[0.24890927]\n"
          ]
        }
      ],
      "source": [
        "#0.2 0.8 incorrect direction\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff1 = 0.2\n",
        "ar_coeff2 = 0.8\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "Hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
        "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "\n",
        "\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d18057-89f6-46d3-8b0d-4fa5c7f86a75",
      "metadata": {
        "id": "11d18057-89f6-46d3-8b0d-4fa5c7f86a75"
      },
      "source": [
        "### coefficient 0.8 0.8, correct direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "781619fa-0024-447a-8750-9d1e4a96b74f",
      "metadata": {
        "id": "781619fa-0024-447a-8750-9d1e4a96b74f",
        "outputId": "c59a5ea2-4b8c-4144-cca5-81c57eb92e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 5.51164249e-01]\n",
            " [ 8.33834171e-01]\n",
            " [ 7.05916426e-04]\n",
            " [-2.35679570e-04]]\n",
            "Equal slice ratio:[0.66099983]\n",
            "Equal number in each slice direction:[[ 5.51118853e-01]\n",
            " [ 8.33869763e-01]\n",
            " [ 7.60820593e-04]\n",
            " [-2.48872414e-04]]\n",
            "Equal number in each slice ratio:[0.66091718]\n"
          ]
        }
      ],
      "source": [
        "#0.8 0.8 correct direction\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff1 = 0.8\n",
        "ar_coeff2 = 0.8\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "Hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
        "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445af9f4-8ba0-4402-9d77-9ed7e9b7af18",
      "metadata": {
        "id": "445af9f4-8ba0-4402-9d77-9ed7e9b7af18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "942563b1-936e-4e15-a629-aca601f35022",
      "metadata": {
        "id": "942563b1-936e-4e15-a629-aca601f35022"
      },
      "source": [
        "## SIR for model\n",
        "\\begin{align}\n",
        "   & y_t = 2z_{1,t} + 3z_{2,t} +\\epsilon_t\n",
        "\\end{align}\n",
        "with four components $z_i \\sim \\text{AR}(1)$ with $\\phi_i, i = 1, \\ldots, 4$. I denote the model as NO(0.2, 0.2, 0.2, 0.2) if $\\phi_i = 0.2, i = 1, \\ldots, 4$. $K = 1$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33cb3733-ccb5-4644-9e09-18dabd0bd00e",
      "metadata": {
        "id": "33cb3733-ccb5-4644-9e09-18dabd0bd00e"
      },
      "source": [
        "### ar_coeff = [0.2, 0.2, 0.2, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b249b7-497f-42b6-9d5c-7e29c2134296",
      "metadata": {
        "id": "88b249b7-497f-42b6-9d5c-7e29c2134296",
        "outputId": "68e64756-198c-4970-cd48-cb883fbd2006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 5.55096135e-01]\n",
            " [ 8.31595927e-01]\n",
            " [ 9.87298312e-04]\n",
            " [-1.54833445e-04]]\n",
            "Equal slice ratio:[0.66750704]\n",
            "Equal number in each slice direction:[[1.10950932e+00]\n",
            " [1.66323899e+00]\n",
            " [1.83722916e-03]\n",
            " [3.52549362e-04]]\n",
            "Equal number in each slice ratio:[0.66707751]\n"
          ]
        }
      ],
      "source": [
        "#ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H=H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e1fd9d-7cc7-49ff-8ad0-0ed0a917140b",
      "metadata": {
        "id": "b3e1fd9d-7cc7-49ff-8ad0-0ed0a917140b"
      },
      "source": [
        "### ar_coeff = [0.2, 0.2, 0.8, 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0575e46a-dd35-4670-a94b-f42f371b805c",
      "metadata": {
        "id": "0575e46a-dd35-4670-a94b-f42f371b805c",
        "outputId": "b4f83909-9b56-4eab-c148-ad5fb569ae7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 5.54614799e-01]\n",
            " [ 8.31551840e-01]\n",
            " [ 2.93844972e-03]\n",
            " [-3.30158714e-04]]\n",
            "Equal slice ratio:[0.66696359]\n",
            "Equal number in each slice direction:[[ 1.66417676e+00]\n",
            " [ 2.49475284e+00]\n",
            " [ 4.59979919e-03]\n",
            " [-1.02698341e-04]]\n",
            "Equal number in each slice ratio:[0.6670708]\n"
          ]
        }
      ],
      "source": [
        "#ar_coeff = [0.2, 0.2, 0.8, 0.8]\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff = [0.2, 0.2, 0.8, 0.8]\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H=H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb3d9d71-bf2d-4b87-b00b-b3f136e28657",
      "metadata": {
        "id": "bb3d9d71-bf2d-4b87-b00b-b3f136e28657"
      },
      "source": [
        "### ar_coeff = [0.2, 0.5, 0.8, 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e943dc2-46c5-4611-8590-00a9fdccd9ff",
      "metadata": {
        "id": "7e943dc2-46c5-4611-8590-00a9fdccd9ff",
        "outputId": "cd2a7d12-0bc5-48db-f38c-f97ce11dd32b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[0.46189184]\n",
            " [0.88630596]\n",
            " [0.0042448 ]\n",
            " [0.00288614]]\n",
            "Equal slice ratio:[0.52114266]\n",
            "Equal number in each slice direction:[[1.01290085]\n",
            " [1.7202301 ]\n",
            " [0.00497268]\n",
            " [0.00291084]]\n",
            "Equal number in each slice ratio:[0.58881707]\n"
          ]
        }
      ],
      "source": [
        "#ar_coeff = [0.2, 0.5, 0.8, 0.8]\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff = [0.2, 0.5, 0.8, 0.8]\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H=H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b17c969-d1f8-44bd-9133-0074acd0821d",
      "metadata": {
        "id": "2b17c969-d1f8-44bd-9133-0074acd0821d"
      },
      "source": [
        "### ar_coeff = [0.2, 0.5, 0.5, 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39205120-cd13-4d56-8f43-b00659c148d0",
      "metadata": {
        "id": "39205120-cd13-4d56-8f43-b00659c148d0",
        "outputId": "b91a017f-b477-400e-d9f0-351d4c7eb69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equal slice direction:[[ 4.63183556e-01]\n",
            " [ 8.85775180e-01]\n",
            " [ 1.06089700e-04]\n",
            " [-9.76717593e-04]]\n",
            "Equal slice ratio:[0.52291323]\n",
            "Equal number in each slice direction:[[1.47604378e+00]\n",
            " [2.60602530e+00]\n",
            " [5.14360204e-03]\n",
            " [1.92624909e-03]]\n",
            "Equal number in each slice ratio:[0.56639656]\n"
          ]
        }
      ],
      "source": [
        "#ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
        "num_N = 5\n",
        "n_obs = 10000\n",
        "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
        "noise = np.zeros((num_N, n_obs))\n",
        "n = 100\n",
        "H = 50\n",
        "K = 1\n",
        "hat = 0\n",
        "for a in range(n):\n",
        "    for h in range(num_N):\n",
        "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "    ar_series = np.zeros((num_N, n_obs))\n",
        "    for t in range(0, n_obs):\n",
        "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "    y = ar_series[4]\n",
        "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "    sir_1_result = sir_1(X, y, H=H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_1_result[0]<0:\n",
        "        sir_1_result = -sir_1_result\n",
        "    sir_1_result = sir_1_result/np.linalg.norm(sir_1_result)\n",
        "    hat = hat + sir_1_result\n",
        "    sir_11_result = sir_11(X, y, H, K=K)\n",
        "    #after adding normalization and modifying the first coefficient\n",
        "    if sir_11_result[0]<0:\n",
        "        sir_11_result = -sir_11_result\n",
        "    sir_11_result = sir_11_result/np.linalg.norm(sir_11_result)\n",
        "    Hat = Hat + sir_11_result\n",
        "print(f\"Equal slice direction:{hat/n}\")\n",
        "hat1 = hat/n\n",
        "print(f\"Equal slice ratio:{hat1[0]/hat1[1]}\")\n",
        "print(f\"Equal number in each slice direction:{Hat/n}\")\n",
        "Hat1 = Hat/n\n",
        "print(f\"Equal number in each slice ratio:{Hat1[0]/Hat1[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10bc6db-15bd-4e53-814e-48e4f1a65722",
      "metadata": {
        "id": "c10bc6db-15bd-4e53-814e-48e4f1a65722"
      },
      "source": [
        "# SIR for Time series new objective(Double sum)\n",
        "## The results are shown by 1. directions 2. ratio between first two coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce111cb1-4683-49ec-9252-6f492e557ea6",
      "metadata": {
        "id": "ce111cb1-4683-49ec-9252-6f492e557ea6"
      },
      "source": [
        "Code below is for this derivation. When taking the sum across all $q$, it is easily seen that\n",
        "$$\n",
        "\\sum_q diag\\left[ (\\mathbf{W} \\circ \\Phi^{\\circ q})^T Cov(\\mathbb{E}(\\mathbf{X}_{t-q}|y) (\\mathbf{W} \\circ\\Phi^{\\circ q})\\right]=diag(\\mathbf{W}^T\\sum_q \\mathbf{V}^{[1:q]}\\mathbf{W}),\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\\mathbf{V}^{[1:Q]}_{jk}=\\sum_{q=1}^Q\\mathbf{V}^q_{jk}\\cdot \\phi_j^q\\cdot \\phi_k^q.\n",
        "$$\n",
        "I'm wondering, is it $\\text{diag}(W^T V^{[1: q]} W)$, not $\\text{diag}(\\mathbf{W}^T\\sum_q \\mathbf{V}^{[1:q]}\\mathbf{W}).$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898f8a47-9100-4bed-af1a-7c650cc53261",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "898f8a47-9100-4bed-af1a-7c650cc53261"
      },
      "source": [
        "## Use equal slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8836a587-541f-424a-abbb-87c79d6c9da1",
      "metadata": {
        "id": "8836a587-541f-424a-abbb-87c79d6c9da1"
      },
      "outputs": [],
      "source": [
        "#from 0 to Q double sum\n",
        "from tabulate import tabulate\n",
        "def NEWSIR(ar_coeff, T, n_obs, S):\n",
        "    num_N = 5\n",
        "    # n_obs = 10000\n",
        "    noise = np.zeros((num_N, n_obs))\n",
        "    n = 100\n",
        "    H = 50\n",
        "    P = 4\n",
        "    K = 1\n",
        "    # S = 20\n",
        "    hat = [np.zeros((P, 1)) for i in range(S)]\n",
        "    # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "    g = np.zeros((S, 1))\n",
        "    for w in range(n):\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "        ar_series = np.zeros((num_N, n_obs))\n",
        "        for t in range(0, n_obs):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "            ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "        y = ar_series[4]\n",
        "        X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "        V = []\n",
        "        for a in range(0,S+1):\n",
        "            M, edr, lam1 = T(X, y, a, H, K)\n",
        "            V.append(M)\n",
        "        for q in range(1, S+1):\n",
        "            Q = np.zeros((P, P))\n",
        "            phi = ar_coeff\n",
        "            for j in range(P):\n",
        "                for k in range(P):\n",
        "                    Q[j,k] = sum(sum(phi[j]**a * V[a][j,k] * phi[k]**a for a in range(0,l)) for l in range(1, q+1)) #double sum\n",
        "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "            K_index = np.argpartition(np.abs(eigenvalues1), P-K) >= P-K\n",
        "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "            edr_est =  K_largest_eigenvectors\n",
        "            if edr_est[0]<0:\n",
        "                edr_est = -edr_est\n",
        "            edr_est = edr_est/np.linalg.norm(edr_est)\n",
        "            hat[q-1] += edr_est\n",
        "    for i in range(S):\n",
        "        hat[i] = hat[i]/n\n",
        "        g[i] = hat[i][0] / hat[i][1]\n",
        "    array = np.array(hat)\n",
        "    print(tabulate(array, tablefmt='latex'))\n",
        "    print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5d8fa4-5009-4664-882b-ee9f1518ada9",
      "metadata": {
        "id": "fd5d8fa4-5009-4664-882b-ee9f1518ada9"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.2,0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a433cdab-9e0b-4379-80ae-10a77f501d3f",
      "metadata": {
        "id": "a433cdab-9e0b-4379-80ae-10a77f501d3f",
        "outputId": "1083dcb2-c0eb-406b-af2c-ca05acf2965b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.554585 & 0.831906 & -0.00187916 &  0.000159399 \\\\\n",
            " 0.553301 & 0.831914 &  0.00227951 & -0.00094284  \\\\\n",
            " 0.552559 & 0.831664 &  0.00359749 & -0.00122537  \\\\\n",
            " 0.55212  & 0.83149  &  0.00421676 & -0.00134183  \\\\\n",
            " 0.551832 & 0.831369 &  0.00457534 & -0.00140373  \\\\\n",
            " 0.551629 & 0.831283 &  0.00480933 & -0.00144168  \\\\\n",
            " 0.551478 & 0.831218 &  0.00497417 & -0.00146715  \\\\\n",
            " 0.551362 & 0.831167 &  0.00509663 & -0.00148537  \\\\\n",
            " 0.55127  & 0.831127 &  0.00519122 & -0.001499    \\\\\n",
            " 0.551194 & 0.831094 &  0.00526651 & -0.00150956  \\\\\n",
            " 0.551132 & 0.831067 &  0.00532787 & -0.00151797  \\\\\n",
            " 0.551079 & 0.831044 &  0.00537885 & -0.00152483  \\\\\n",
            " 0.551034 & 0.831024 &  0.00542188 & -0.00153052  \\\\\n",
            " 0.550996 & 0.831007 &  0.00545869 & -0.00153531  \\\\\n",
            " 0.550962 & 0.830992 &  0.00549053 & -0.0015394   \\\\\n",
            " 0.550932 & 0.830979 &  0.00551836 & -0.00154293  \\\\\n",
            " 0.550905 & 0.830967 &  0.00554289 & -0.00154601  \\\\\n",
            " 0.550882 & 0.830957 &  0.00556467 & -0.00154872  \\\\\n",
            " 0.55086  & 0.830947 &  0.00558413 & -0.00155112  \\\\\n",
            " 0.550841 & 0.830939 &  0.00560164 & -0.00155326  \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.66664388]\n",
            " [0.66509358]\n",
            " [0.66440213]\n",
            " [0.66401318]\n",
            " [0.66376278]\n",
            " [0.66358773]\n",
            " [0.66345834]\n",
            " [0.66335876]\n",
            " [0.66327972]\n",
            " [0.66321545]\n",
            " [0.66316216]\n",
            " [0.66311726]\n",
            " [0.6630789 ]\n",
            " [0.66304575]\n",
            " [0.66301682]\n",
            " [0.66299135]\n",
            " [0.66296876]\n",
            " [0.66294857]\n",
            " [0.66293043]\n",
            " [0.66291404]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.2,0.2]\n",
        "NEWSIR(ar_coeff, sir_1_time_series, 10000, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec92aba1-8f7c-4d01-bdd4-7bc68f317b6d",
      "metadata": {
        "id": "ec92aba1-8f7c-4d01-bdd4-7bc68f317b6d"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1edfd1-fa21-4136-83fc-170249526cda",
      "metadata": {
        "id": "0e1edfd1-fa21-4136-83fc-170249526cda",
        "outputId": "d6ccbc46-35a4-478b-99f3-716446c9adcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.556049 & 0.830562 & -0.000267665 &  0.00171431 \\\\\n",
            " 0.438066 & 0.636593 &  0.0359006   &  0.0236571  \\\\\n",
            " 0.358612 & 0.494733 &  0.0704215   &  0.0450812  \\\\\n",
            " 0.314949 & 0.417433 &  0.0534683   &  0.0482798  \\\\\n",
            " 0.288643 & 0.375582 &  0.0478755   &  0.00580257 \\\\\n",
            " 0.26829  & 0.335881 &  0.0445573   &  0.00342528 \\\\\n",
            " 0.254685 & 0.317757 &  0.0499964   &  0.00205482 \\\\\n",
            " 0.244467 & 0.300952 &  0.0536248   &  0.00287382 \\\\\n",
            " 0.236596 & 0.287178 &  0.0750268   & -0.00512007 \\\\\n",
            " 0.230491 & 0.279271 &  0.0767333   & -0.00679534 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.66948495]\n",
            " [0.68814155]\n",
            " [0.72485901]\n",
            " [0.75448867]\n",
            " [0.76852045]\n",
            " [0.79876349]\n",
            " [0.80150804]\n",
            " [0.81231039]\n",
            " [0.82386804]\n",
            " [0.82533116]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.8,0.8]\n",
        "NEWSIR(ar_coeff,sir_1_time_series, 10000, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6778b5e0-1b39-4c6a-ba14-e2afac18c1bd",
      "metadata": {
        "id": "6778b5e0-1b39-4c6a-ba14-e2afac18c1bd"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6704685-bb34-43d3-b866-5b41168ed49a",
      "metadata": {
        "id": "d6704685-bb34-43d3-b866-5b41168ed49a",
        "outputId": "ae7fa754-1466-4dbf-8666-6788681472be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.461232 & 0.886648 &  0.00185602 & -0.000684399 \\\\\n",
            " 0.367788 & 0.790847 & -0.0118667  &  0.00408115  \\\\\n",
            " 0.284692 & 0.609771 &  0.00277821 & -0.0236595   \\\\\n",
            " 0.25131  & 0.523449 & -0.00225777 & -0.0700011   \\\\\n",
            " 0.233338 & 0.481689 &  0.0145163  & -0.0859569   \\\\\n",
            " 0.221394 & 0.465216 &  0.0157676  & -0.0873892   \\\\\n",
            " 0.212442 & 0.435712 &  0.0292717  & -0.0684612   \\\\\n",
            " 0.205988 & 0.416691 &  0.049366   & -0.0684726   \\\\\n",
            " 0.201292 & 0.410014 &  0.05121    & -0.0679493   \\\\\n",
            " 0.1977   & 0.40493  &  0.0525372  & -0.0677423   \\\\\n",
            " 0.194837 & 0.400871 &  0.0535773  & -0.0676911   \\\\\n",
            " 0.192482 & 0.397517 &  0.0544213  & -0.0677207   \\\\\n",
            " 0.190503 & 0.394682 &  0.0551135  & -0.067789    \\\\\n",
            " 0.188813 & 0.392251 &  0.0556808  & -0.0678707   \\\\\n",
            " 0.187353 & 0.390146 &  0.0561444  & -0.0679515   \\\\\n",
            " 0.186094 & 0.381477 &  0.0528152  & -0.0495969   \\\\\n",
            " 0.185007 & 0.379947 &  0.0531147  & -0.0496304   \\\\\n",
            " 0.184051 & 0.37484  &  0.071263   & -0.0415754   \\\\\n",
            " 0.18321  & 0.368474 &  0.0878328  & -0.0313389   \\\\\n",
            " 0.182466 & 0.367473 &  0.0880108  & -0.0313472   \\\\\n",
            " 0.181798 & 0.366573 &  0.088158   & -0.0313522   \\\\\n",
            " 0.181194 & 0.365761 &  0.0882804  & -0.0313544   \\\\\n",
            " 0.180646 & 0.365025 &  0.0883828  & -0.0313546   \\\\\n",
            " 0.180146 & 0.364355 &  0.0884688  & -0.0313531   \\\\\n",
            " 0.17969  & 0.363743 &  0.0885415  & -0.0313505   \\\\\n",
            " 0.179271 & 0.363182 &  0.0886031  & -0.0313469   \\\\\n",
            " 0.178885 & 0.362666 &  0.0886557  & -0.0313428   \\\\\n",
            " 0.178528 & 0.36219  &  0.0887006  & -0.0313381   \\\\\n",
            " 0.178198 & 0.361749 &  0.0887392  & -0.0313332   \\\\\n",
            " 0.17789  & 0.36134  &  0.0887724  & -0.0313281   \\\\\n",
            " 0.177605 & 0.360959 &  0.0888012  & -0.031323    \\\\\n",
            " 0.177338 & 0.360603 &  0.088826   & -0.0313178   \\\\\n",
            " 0.177088 & 0.360271 &  0.0888476  & -0.0313126   \\\\\n",
            " 0.176853 & 0.359959 &  0.0888664  & -0.0313075   \\\\\n",
            " 0.176633 & 0.359667 &  0.0888828  & -0.0313024   \\\\\n",
            " 0.176426 & 0.359392 &  0.088897   & -0.0312975   \\\\\n",
            " 0.176231 & 0.359132 &  0.0889095  & -0.0312927   \\\\\n",
            " 0.176046 & 0.358887 &  0.0889204  & -0.031288    \\\\\n",
            " 0.175871 & 0.358656 &  0.0889299  & -0.0312835   \\\\\n",
            " 0.175706 & 0.358436 &  0.0889383  & -0.031279    \\\\\n",
            " 0.175549 & 0.358228 &  0.0889455  & -0.0312748   \\\\\n",
            " 0.1754   & 0.358031 &  0.0889519  & -0.0312706   \\\\\n",
            " 0.175258 & 0.357843 &  0.0889574  & -0.0312666   \\\\\n",
            " 0.175122 & 0.357664 &  0.0889622  & -0.0312627   \\\\\n",
            " 0.174993 & 0.357493 &  0.0889664  & -0.031259    \\\\\n",
            " 0.17487  & 0.35733  &  0.0889701  & -0.0312554   \\\\\n",
            " 0.174753 & 0.357175 &  0.0889732  & -0.0312518   \\\\\n",
            " 0.17464  & 0.357026 &  0.0889759  & -0.0312485   \\\\\n",
            " 0.174533 & 0.356884 &  0.0889782  & -0.0312452   \\\\\n",
            " 0.174429 & 0.356747 &  0.0889801  & -0.031242    \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.52019733]\n",
            " [0.46505512]\n",
            " [0.46688365]\n",
            " [0.48010298]\n",
            " [0.48441676]\n",
            " [0.47589389]\n",
            " [0.48757284]\n",
            " [0.49434136]\n",
            " [0.4909382 ]\n",
            " [0.48823241]\n",
            " [0.48603411]\n",
            " [0.48421163]\n",
            " [0.48267371]\n",
            " [0.48135611]\n",
            " [0.48021296]\n",
            " [0.4878267 ]\n",
            " [0.48692872]\n",
            " [0.49101093]\n",
            " [0.49721282]\n",
            " [0.4965443 ]\n",
            " [0.49593905]\n",
            " [0.49538862]\n",
            " [0.49488597]\n",
            " [0.49442523]\n",
            " [0.49400143]\n",
            " [0.49361036]\n",
            " [0.4932484 ]\n",
            " [0.49291247]\n",
            " [0.49259987]\n",
            " [0.49230828]\n",
            " [0.49203566]\n",
            " [0.49178025]\n",
            " [0.49154047]\n",
            " [0.49131493]\n",
            " [0.49110243]\n",
            " [0.49090185]\n",
            " [0.49071224]\n",
            " [0.49053272]\n",
            " [0.49036251]\n",
            " [0.49020091]\n",
            " [0.49004729]\n",
            " [0.48990106]\n",
            " [0.48976171]\n",
            " [0.48962878]\n",
            " [0.48950182]\n",
            " [0.48938044]\n",
            " [0.48926429]\n",
            " [0.48915303]\n",
            " [0.48904637]\n",
            " [0.48894402]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.8,0.8]\n",
        "NEWSIR(ar_coeff,sir_1_time_series, 10000, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606a7c02-0a9d-4414-8fb1-dfa7f6f28614",
      "metadata": {
        "id": "606a7c02-0a9d-4414-8fb1-dfa7f6f28614"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.5,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a487bf9-77d2-48d6-ac5b-1881af1296cf",
      "metadata": {
        "id": "4a487bf9-77d2-48d6-ac5b-1881af1296cf",
        "outputId": "3209aef8-16bf-4c60-d994-1becb338bac5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'NEWSIR' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ar_coeff \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.8\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mNEWSIR\u001b[49m(ar_coeff,sir_1_time_series, \u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'NEWSIR' is not defined"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.5,0.8]\n",
        "NEWSIR(ar_coeff,sir_1_time_series, 10000, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d29ff5-2b04-41f0-9bbc-e471ca595231",
      "metadata": {
        "id": "09d29ff5-2b04-41f0-9bbc-e471ca595231"
      },
      "source": [
        "## Use equal number in each slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73049324-b848-473f-a5a2-a12157f40143",
      "metadata": {
        "id": "73049324-b848-473f-a5a2-a12157f40143"
      },
      "outputs": [],
      "source": [
        "# #from 0 to Q double sum\n",
        "# from tabulate import tabulate\n",
        "# import numpy as np\n",
        "\n",
        "# def uu2(ar_coeff):\n",
        "#     import numpy as np\n",
        "#     from tabulate import tabulate\n",
        "\n",
        "#     def sir_1_time_series1(X, y, s, num_slices, K):\n",
        "#         n_samples, n_features = X.shape\n",
        "#         V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "#         # Step 1: Sort the data by the response variable\n",
        "#         sorted_indices = np.argsort(y)\n",
        "#         X_sorted = X[sorted_indices]\n",
        "#         y_sorted = y[sorted_indices]\n",
        "#         # Step 2: Divide the data into slices\n",
        "#         slice_size = n_samples // num_slices\n",
        "#         ph_hat = slice_size / n_samples\n",
        "#         slices = []\n",
        "\n",
        "#         for i in range(num_slices):\n",
        "#             start_idx = i * slice_size\n",
        "#             if i < num_slices - 1:\n",
        "#                 end_idx = (i + 1) * slice_size\n",
        "#             else:  # Last slice includes any remaining samples\n",
        "#                 end_idx = n_samples\n",
        "#             if start_idx - s > 0:\n",
        "#                 slices.append((X[[x - s for x in sorted_indices[start_idx:end_idx]]], y_sorted[start_idx:end_idx]))\n",
        "#             else:\n",
        "#                 slices.append((X[sorted_indices[0:end_idx - s]], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "#         # Step 3: Compute the means of the predictors within each slice\n",
        "#         X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "#         # Step 4: Center the predictor means\n",
        "#         X_centered = X_means - np.mean(X_means, axis=0)\n",
        "\n",
        "#         V_hat = np.add(V_hat, ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "\n",
        "#         # Check for NaN or inf values in V_hat\n",
        "#         if np.isnan(V_hat).any() or np.isinf(V_hat).any():\n",
        "#             # Handle NaN or inf values appropriately\n",
        "#             # For example, replace NaN values with 0 and inf values with a large number\n",
        "#             V_hat[np.isnan(V_hat)] = 0\n",
        "#             V_hat[np.isinf(V_hat)] = np.nanmax(np.abs(V_hat))  # Replace inf with maximum absolute value in V_hat\n",
        "\n",
        "#     # Compute eigenvalues and eigenvectors\n",
        "#         eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "#         eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "#         K_index = np.argpartition(np.abs(eigenvalues), X.shape[1] - K) >= X.shape[1] - K\n",
        "#         K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "#         edr_est = K_largest_eigenvectors\n",
        "\n",
        "#         return V_hat, edr_est, eigenvalues ** 2\n",
        "\n",
        "#     num_N = 5\n",
        "#     n_obs = 1000\n",
        "#     noise = np.zeros((num_N, n_obs))\n",
        "#     n = 100\n",
        "#     H = 50\n",
        "#     P = 4\n",
        "#     K = 1\n",
        "#     S = 20\n",
        "#     hat = [np.zeros((P, 1)) for _ in range(S)]\n",
        "#     g = np.zeros((S, 1))\n",
        "#     # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "#     n1 = 0\n",
        "#     l = 1  # Initialize `l` outside the loop\n",
        "#     while n1 < 100:\n",
        "#         for h in range(num_N):\n",
        "#             noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "#         ar_series = np.zeros((num_N, n_obs))\n",
        "#         for t in range(0, n_obs):\n",
        "#             ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
        "#             ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
        "#             ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
        "#             ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
        "#             ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
        "#         y = ar_series[4]\n",
        "#         X = np.concatenate([ar_series[i].reshape(-1, 1) for i in range(4)], axis=1)\n",
        "#         V = []\n",
        "#         for a in range(0, S + 1):\n",
        "#             M, _, _ = sir_1_time_series1(X, y, a, H, K)\n",
        "#             V.append(M)\n",
        "#         for q in range(1, S + 1):\n",
        "#             Q = np.zeros((P, P))\n",
        "#             phi = ar_coeff\n",
        "#             for j in range(P):\n",
        "#                 for k in range(P):\n",
        "#                     Q[j, k] = sum(sum(phi[j] ** a * V[a][j, k] * phi[k] ** a for a in range(0, l)) for l in range(1, q + 1))\n",
        "#             eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "#             K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
        "#             K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "#             edr_est = K_largest_eigenvectors\n",
        "#             if edr_est[0] < 0:\n",
        "#                 edr_est = -edr_est\n",
        "#             edr_est = edr_est / np.linalg.norm(edr_est)\n",
        "#             hat[q - 1] += edr_est\n",
        "#             n1 += 1\n",
        "\n",
        "#     for i in range(S):\n",
        "#         hat[i] = hat[i] / n\n",
        "#         g[i] = hat[i][0] / hat[i][1]\n",
        "#     array = np.array(hat)\n",
        "#     print(tabulate(array, tablefmt='latex'))\n",
        "#     print(g)\n",
        "\n",
        "# # Example usage\n",
        "# ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "# uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9bbe26-e68d-4044-a07c-ab63ad3a6087",
      "metadata": {
        "id": "5e9bbe26-e68d-4044-a07c-ab63ad3a6087",
        "outputId": "8171aa43-3083-48d1-e900-a0c93e0d3c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            " 0.0187047 & 0.0101912 & 0.0106083 & 0.000418829 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]\n",
            " [1.83537209]]\n"
          ]
        }
      ],
      "source": [
        "#from 0 to Q double sum\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "def uu2(ar_coeff):\n",
        "    import numpy as np\n",
        "    from tabulate import tabulate\n",
        "\n",
        "    def sir_1_time_series2(X, y, num_slices, K):\n",
        "        n_samples, n_features = X.shape\n",
        "        V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "        # Step 1: Sort the data by the response variable\n",
        "        sorted_indices = np.argsort(y)\n",
        "        X_sorted = X[sorted_indices]\n",
        "        y_sorted = y[sorted_indices]\n",
        "\n",
        "        # Step 2: Divide the data into slices\n",
        "        slice_size = n_samples // num_slices\n",
        "        ph_hat = slice_size/n_samples\n",
        "        slices = []\n",
        "\n",
        "        for i in range(num_slices):\n",
        "            start_idx = i * slice_size\n",
        "            if i < num_slices - 1:\n",
        "                end_idx = (i + 1) * slice_size\n",
        "            else:  # Last slice includes any remaining samples\n",
        "                end_idx = n_samples\n",
        "            slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "        # Step 3: Compute the means of the predictors within each slice\n",
        "        X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "        # Step 4: Center the predictor means\n",
        "        X_centered = X_means - np.mean(X_means, axis=0)\n",
        "\n",
        "        V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "        K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "        K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "        edr_est =  K_largest_eigenvectors\n",
        "\n",
        "        return V_hat, edr_est, eigenvalues ** 2\n",
        "\n",
        "    num_N = 5\n",
        "    n_obs = 1000\n",
        "    S = 20\n",
        "    noise = np.zeros((num_N, n_obs+S))\n",
        "    n = 100\n",
        "    H = 50\n",
        "    P = 4\n",
        "    K = 1\n",
        "\n",
        "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
        "    g = np.zeros((S, 1))\n",
        "    # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "    n1 = 0\n",
        "    l = 1  # Initialize `l` outside the loop\n",
        "    while n1 < 100:\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
        "        ar_series = np.zeros((num_N, n_obs+S))\n",
        "        for t in range(0, n_obs+S):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
        "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
        "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
        "            ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
        "        y = ar_series[4][S:n_obs+S]\n",
        "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
        "        V = []\n",
        "        for a in range(0, S + 1):\n",
        "            M, _, _ = sir_1_time_series2(X, y, H, K)\n",
        "            V.append(M)\n",
        "        for q in range(1, S + 1):\n",
        "            Q = np.zeros((P, P))\n",
        "            phi = ar_coeff\n",
        "            for j in range(P):\n",
        "                for k in range(P):\n",
        "                    Q[j, k] = sum(sum(phi[j] ** a * V[a][j, k] * phi[k] ** a for a in range(0, l)) for l in range(1, q + 1))\n",
        "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
        "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "            edr_est = K_largest_eigenvectors\n",
        "            if edr_est[0] < 0:\n",
        "                edr_est = -edr_est\n",
        "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
        "            hat[q - 1] += edr_est\n",
        "            n1 += 1\n",
        "\n",
        "    for i in range(S):\n",
        "        hat[i] = hat[i] / n\n",
        "        g[i] = hat[i][0] / hat[i][1]\n",
        "    array = np.array(hat)\n",
        "    print(tabulate(array, tablefmt='latex'))\n",
        "    print(g)\n",
        "\n",
        "# Example usage\n",
        "ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176a8992-406d-4b0f-a171-62321ef90b5d",
      "metadata": {
        "id": "176a8992-406d-4b0f-a171-62321ef90b5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48400f23-f40f-4575-b7e8-ad167e425724",
      "metadata": {
        "id": "48400f23-f40f-4575-b7e8-ad167e425724",
        "outputId": "566eaffd-65db-4818-d69c-04744fa641e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0273562 & 0.0418388 & -0.000515076 & -0.00010586  \\\\\n",
            " 0.0273562 & 0.0418387 & -0.000514755 & -0.000106752 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514634 & -0.000107049 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514574 & -0.000107197 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514537 & -0.000107286 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514513 & -0.000107345 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514496 & -0.000107388 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514483 & -0.000107419 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514473 & -0.000107444 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514465 & -0.000107464 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514458 & -0.00010748  \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514453 & -0.000107493 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514448 & -0.000107505 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514444 & -0.000107514 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514441 & -0.000107523 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514438 & -0.00010753  \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514435 & -0.000107537 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514433 & -0.000107543 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.00051443  & -0.000107548 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514429 & -0.000107552 \\\\\n",
            " 0.0273563 & 0.0418387 & -0.000514427 & -0.000107557 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.653848  ]\n",
            " [0.65384977]\n",
            " [0.65385015]\n",
            " [0.65385034]\n",
            " [0.65385046]\n",
            " [0.65385054]\n",
            " [0.65385059]\n",
            " [0.65385063]\n",
            " [0.65385066]\n",
            " [0.65385069]\n",
            " [0.65385071]\n",
            " [0.65385073]\n",
            " [0.65385074]\n",
            " [0.65385076]\n",
            " [0.65385077]\n",
            " [0.65385078]\n",
            " [0.65385079]\n",
            " [0.65385079]\n",
            " [0.6538508 ]\n",
            " [0.65385081]\n",
            " [0.65385081]]\n"
          ]
        }
      ],
      "source": [
        "#from 0 to Q double sum\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "def uu2(ar_coeff):\n",
        "    import numpy as np\n",
        "    from tabulate import tabulate\n",
        "\n",
        "    def sir_1_time_series2(X, y, num_slices, K):\n",
        "        n_samples, n_features = X.shape\n",
        "        V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "        # Step 1: Sort the data by the response variable\n",
        "        sorted_indices = np.argsort(y)\n",
        "        X_sorted = X[sorted_indices]\n",
        "        y_sorted = y[sorted_indices]\n",
        "\n",
        "        # Step 2: Divide the data into slices\n",
        "        slice_size = n_samples // num_slices\n",
        "        ph_hat = slice_size/n_samples\n",
        "        slices = []\n",
        "\n",
        "        for i in range(num_slices):\n",
        "            start_idx = i * slice_size\n",
        "            if i < num_slices - 1:\n",
        "                end_idx = (i + 1) * slice_size\n",
        "            else:  # Last slice includes any remaining samples\n",
        "                end_idx = n_samples\n",
        "            slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "        # Step 3: Compute the means of the predictors within each slice\n",
        "        X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "        # Step 4: Center the predictor means\n",
        "        X_centered = X_means - np.mean(X_means, axis=0)\n",
        "\n",
        "        V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "        K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
        "        K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "        edr_est =  K_largest_eigenvectors\n",
        "\n",
        "        return V_hat, edr_est, eigenvalues ** 2\n",
        "\n",
        "    num_N = 5\n",
        "    n_obs = 10000\n",
        "    S = 21\n",
        "    noise = np.zeros((num_N, n_obs+S))\n",
        "    n = 100\n",
        "    H = 50\n",
        "    P = 4\n",
        "    K = 1\n",
        "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
        "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
        "    g = np.zeros((S, 1))\n",
        "    # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "    n1 = 0\n",
        "    l = 1  # Initialize `l` outside the loop\n",
        "    while n1 < 100:\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
        "        ar_series = np.zeros((num_N, n_obs+S))\n",
        "        for t in range(0, n_obs+S):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
        "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
        "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
        "            ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
        "        for a in range(0, S+1):\n",
        "            y[a] = ar_series[4][a:n_obs+a]\n",
        "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
        "        V = []\n",
        "        for a in range(0, S + 1):\n",
        "            M, _, _ = sir_1_time_series2(X, y[a], H, K)\n",
        "            V.append(M)\n",
        "        for q in range(1, S + 1):\n",
        "            Q = np.zeros((P, P))\n",
        "            phi = ar_coeff\n",
        "            for j in range(P):\n",
        "                for k in range(P):\n",
        "                    Q[j, k] = sum(sum(phi[j] ** a * V[a][j, k] * phi[k] ** a for a in range(0, l)) for l in range(1, q + 1))\n",
        "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
        "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "            edr_est = K_largest_eigenvectors\n",
        "            if edr_est[0] < 0:\n",
        "                edr_est = -edr_est\n",
        "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
        "            hat[q - 1] += edr_est\n",
        "            n1 += 1\n",
        "\n",
        "    for i in range(S):\n",
        "        hat[i] = hat[i] / n\n",
        "        g[i] = hat[i][0] / hat[i][1]\n",
        "    array = np.array(hat)\n",
        "    print(tabulate(array, tablefmt='latex'))\n",
        "    print(g)\n",
        "\n",
        "# Example usage\n",
        "ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c7fd04-2d6b-4dd9-8e9f-4ee1c8833321",
      "metadata": {
        "id": "e5c7fd04-2d6b-4dd9-8e9f-4ee1c8833321",
        "outputId": "f4854d90-4a4a-4751-a195-8496c861f6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.027449  & 0.0417737 & -0.000453235 & -0.000342125 \\\\\n",
            " 0.0274497 & 0.0417728 & -0.000463653 & -0.000339915 \\\\\n",
            " 0.0274499 & 0.0417725 & -0.000467409 & -0.000339694 \\\\\n",
            " 0.0274499 & 0.0417724 & -0.000469634 & -0.000339755 \\\\\n",
            " 0.02745   & 0.0417722 & -0.000471234 & -0.000339896 \\\\\n",
            " 0.02745   & 0.0417721 & -0.000472444 & -0.000340047 \\\\\n",
            " 0.02745   & 0.0417721 & -0.000473371 & -0.000340192 \\\\\n",
            " 0.02745   & 0.041772  & -0.000474106 & -0.000340328 \\\\\n",
            " 0.02745   & 0.041772  & -0.000474703 & -0.000340449 \\\\\n",
            " 0.02745   & 0.041772  & -0.000475196 & -0.000340555 \\\\\n",
            " 0.02745   & 0.0417719 & -0.000475607 & -0.000340645 \\\\\n",
            " 0.02745   & 0.0417719 & -0.000475955 & -0.000340722 \\\\\n",
            " 0.02745   & 0.0417719 & -0.000476252 & -0.000340789 \\\\\n",
            " 0.0274501 & 0.0417719 & -0.000476508 & -0.000340847 \\\\\n",
            " 0.0274501 & 0.0417719 & -0.000476731 & -0.000340897 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000476927 & -0.000340941 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000477101 & -0.000340981 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000477255 & -0.000341015 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000477394 & -0.000341047 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000477519 & -0.000341075 \\\\\n",
            " 0.0274501 & 0.0417718 & -0.000477632 & -0.0003411   \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.6570877 ]\n",
            " [0.65711806]\n",
            " [0.65712735]\n",
            " [0.65713201]\n",
            " [0.65713479]\n",
            " [0.65713665]\n",
            " [0.65713797]\n",
            " [0.65713896]\n",
            " [0.65713973]\n",
            " [0.65714034]\n",
            " [0.65714085]\n",
            " [0.65714127]\n",
            " [0.65714162]\n",
            " [0.65714192]\n",
            " [0.65714219]\n",
            " [0.65714242]\n",
            " [0.65714262]\n",
            " [0.6571428 ]\n",
            " [0.65714296]\n",
            " [0.65714311]\n",
            " [0.65714324]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2, 0.2, 0.8, 0.8]\n",
        "uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e0651c-1fc1-4c2b-b69b-340361b25106",
      "metadata": {
        "id": "76e0651c-1fc1-4c2b-b69b-340361b25106",
        "outputId": "cb67e47c-0e78-4951-86df-da2e617d58f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0234576 & 0.0441193 & 0.000726897 & 0.000598505 \\\\\n",
            " 0.0230671 & 0.0443212 & 0.000767077 & 0.000634939 \\\\\n",
            " 0.0229203 & 0.0443954 & 0.000787399 & 0.000653782 \\\\\n",
            " 0.0228462 & 0.0444324 & 0.000798911 & 0.000664151 \\\\\n",
            " 0.0228018 & 0.0444545 & 0.000806466 & 0.000670612 \\\\\n",
            " 0.0227723 & 0.0444691 & 0.000811727 & 0.000675134 \\\\\n",
            " 0.0227512 & 0.0444796 & 0.000815587 & 0.000678459 \\\\\n",
            " 0.0227355 & 0.0444873 & 0.000818536 & 0.000681016 \\\\\n",
            " 0.0227232 & 0.0444934 & 0.000820859 & 0.000683036 \\\\\n",
            " 0.0227134 & 0.0444982 & 0.000822734 & 0.000684668 \\\\\n",
            " 0.0227054 & 0.0445021 & 0.00082428  & 0.000686014 \\\\\n",
            " 0.0226987 & 0.0445054 & 0.000825577 & 0.000687142 \\\\\n",
            " 0.022693  & 0.0445082 & 0.000826679 & 0.0006881   \\\\\n",
            " 0.0226882 & 0.0445106 & 0.000827625 & 0.000688923 \\\\\n",
            " 0.022684  & 0.0445126 & 0.000828448 & 0.000689638 \\\\\n",
            " 0.0226803 & 0.0445144 & 0.000829168 & 0.000690263 \\\\\n",
            " 0.0226771 & 0.044516  & 0.000829805 & 0.000690816 \\\\\n",
            " 0.0226742 & 0.0445174 & 0.000830371 & 0.000691307 \\\\\n",
            " 0.0226717 & 0.0445187 & 0.000830877 & 0.000691747 \\\\\n",
            " 0.0226693 & 0.0445198 & 0.000831334 & 0.000692143 \\\\\n",
            " 0.0226672 & 0.0445208 & 0.000831747 & 0.000692502 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.53168553]\n",
            " [0.52045234]\n",
            " [0.51627565]\n",
            " [0.5141789 ]\n",
            " [0.51292534]\n",
            " [0.51209236]\n",
            " [0.51149886]\n",
            " [0.51105459]\n",
            " [0.51070955]\n",
            " [0.51043384]\n",
            " [0.51020847]\n",
            " [0.5100208 ]\n",
            " [0.50986212]\n",
            " [0.50972618]\n",
            " [0.50960842]\n",
            " [0.50950542]\n",
            " [0.50941458]\n",
            " [0.50933385]\n",
            " [0.50926165]\n",
            " [0.50919668]\n",
            " [0.50913791]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2, 0.5, 0.8, 0.8]\n",
        "uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e978181-2845-402c-83e4-73ea399a6893",
      "metadata": {
        "id": "5e978181-2845-402c-83e4-73ea399a6893",
        "outputId": "cf62ca95-6a45-44e5-f938-be8515db47fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.00904701 & 0.0178282 & -0.000129318 & -0.000399291 \\\\\n",
            " 0.00888127 & 0.0179103 & -0.00012743  & -0.000431598 \\\\\n",
            " 0.00881848 & 0.0179406 & -0.000126918 & -0.000450806 \\\\\n",
            " 0.00878687 & 0.0179558 & -0.000126609 & -0.00046164  \\\\\n",
            " 0.00876795 & 0.0179648 & -0.000126413 & -0.000468342 \\\\\n",
            " 0.00875537 & 0.0179707 & -0.000126283 & -0.000472882 \\\\\n",
            " 0.00874641 & 0.017975  & -0.00012619  & -0.000476162 \\\\\n",
            " 0.00873969 & 0.0179782 & -0.000126121 & -0.00047865  \\\\\n",
            " 0.00873447 & 0.0179806 & -0.000126067 & -0.000480597 \\\\\n",
            " 0.0087303  & 0.0179826 & -0.000126024 & -0.000482164 \\\\\n",
            " 0.00872689 & 0.0179842 & -0.000125988 & -0.000483451 \\\\\n",
            " 0.00872405 & 0.0179856 & -0.000125959 & -0.000484528 \\\\\n",
            " 0.00872165 & 0.0179867 & -0.000125934 & -0.000485441 \\\\\n",
            " 0.00871959 & 0.0179877 & -0.000125913 & -0.000486225 \\\\\n",
            " 0.00871781 & 0.0179885 & -0.000125894 & -0.000486906 \\\\\n",
            " 0.00871625 & 0.0179892 & -0.000125878 & -0.000487502 \\\\\n",
            " 0.00871487 & 0.0179899 & -0.000125864 & -0.000488028 \\\\\n",
            " 0.00871365 & 0.0179904 & -0.000125851 & -0.000488496 \\\\\n",
            " 0.00871256 & 0.017991  & -0.00012584  & -0.000488914 \\\\\n",
            " 0.00871157 & 0.0179914 & -0.00012583  & -0.000489291 \\\\\n",
            " 0.00871068 & 0.0179918 & -0.00012582  & -0.000489633 \\\\\n",
            " 0.00870987 & 0.0179922 & -0.000125812 & -0.000489943 \\\\\n",
            " 0.00870914 & 0.0179926 & -0.000125804 & -0.000490226 \\\\\n",
            " 0.00870846 & 0.0179929 & -0.000125797 & -0.000490486 \\\\\n",
            " 0.00870784 & 0.0179932 & -0.000125791 & -0.000490725 \\\\\n",
            " 0.00870726 & 0.0179935 & -0.000125785 & -0.000490945 \\\\\n",
            " 0.00870673 & 0.0179937 & -0.000125779 & -0.000491149 \\\\\n",
            " 0.00870624 & 0.0179939 & -0.000125774 & -0.000491339 \\\\\n",
            " 0.00870578 & 0.0179942 & -0.00012577  & -0.000491515 \\\\\n",
            " 0.00870535 & 0.0179944 & -0.000125765 & -0.00049168  \\\\\n",
            " 0.00870494 & 0.0179945 & -0.000125761 & -0.000491834 \\\\\n",
            " 0.00870457 & 0.0179947 & -0.000125757 & -0.000491979 \\\\\n",
            " 0.00870421 & 0.0179949 & -0.000125753 & -0.000492115 \\\\\n",
            " 0.00870388 & 0.017995  & -0.00012575  & -0.000492243 \\\\\n",
            " 0.00870357 & 0.0179952 & -0.000125747 & -0.000492363 \\\\\n",
            " 0.00870327 & 0.0179953 & -0.000125744 & -0.000492477 \\\\\n",
            " 0.00870299 & 0.0179955 & -0.000125741 & -0.000492585 \\\\\n",
            " 0.00870273 & 0.0179956 & -0.000125738 & -0.000492687 \\\\\n",
            " 0.00870247 & 0.0179957 & -0.000125735 & -0.000492783 \\\\\n",
            " 0.00870223 & 0.0179958 & -0.000125733 & -0.000492875 \\\\\n",
            " 0.00870201 & 0.0179959 & -0.00012573  & -0.000492963 \\\\\n",
            " 0.00870179 & 0.017996  & -0.000125728 & -0.000493046 \\\\\n",
            " 0.00870158 & 0.0179961 & -0.000125726 & -0.000493125 \\\\\n",
            " 0.00870139 & 0.0179962 & -0.000125724 & -0.000493201 \\\\\n",
            " 0.0087012  & 0.0179963 & -0.000125722 & -0.000493274 \\\\\n",
            " 0.00870102 & 0.0179964 & -0.00012572  & -0.000493343 \\\\\n",
            " 0.00870085 & 0.0179965 & -0.000125718 & -0.000493409 \\\\\n",
            " 0.00870068 & 0.0179965 & -0.000125717 & -0.000493473 \\\\\n",
            " 0.00870052 & 0.0179966 & -0.000125715 & -0.000493534 \\\\\n",
            " 0.00870037 & 0.0179967 & -0.000125713 & -0.000493592 \\\\\n",
            " 0.00870022 & 0.0179968 & -0.000125712 & -0.000493649 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.50745421]\n",
            " [0.49587565]\n",
            " [0.49153676]\n",
            " [0.4893621 ]\n",
            " [0.48806381]\n",
            " [0.48720162]\n",
            " [0.48658753]\n",
            " [0.48612794]\n",
            " [0.48577107]\n",
            " [0.48548594]\n",
            " [0.4852529 ]\n",
            " [0.48505887]\n",
            " [0.4848948 ]\n",
            " [0.48475427]\n",
            " [0.48463253]\n",
            " [0.48452606]\n",
            " [0.48443216]\n",
            " [0.48434872]\n",
            " [0.48427409]\n",
            " [0.48420694]\n",
            " [0.4841462 ]\n",
            " [0.48409099]\n",
            " [0.4840406 ]\n",
            " [0.48399442]\n",
            " [0.48395193]\n",
            " [0.48391273]\n",
            " [0.48387643]\n",
            " [0.48384273]\n",
            " [0.48381136]\n",
            " [0.48378208]\n",
            " [0.48375469]\n",
            " [0.48372902]\n",
            " [0.48370491]\n",
            " [0.48368222]\n",
            " [0.48366083]\n",
            " [0.48364062]\n",
            " [0.48362151]\n",
            " [0.48360341]\n",
            " [0.48358624]\n",
            " [0.48356992]\n",
            " [0.48355441]\n",
            " [0.48353963]\n",
            " [0.48352554]\n",
            " [0.4835121 ]\n",
            " [0.48349925]\n",
            " [0.48348696]\n",
            " [0.48347519]\n",
            " [0.48346392]\n",
            " [0.4834531 ]\n",
            " [0.48344272]\n",
            " [0.48343275]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
        "uu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6bda10b-08cd-4783-8084-eee86ba16ab9",
      "metadata": {
        "id": "b6bda10b-08cd-4783-8084-eee86ba16ab9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e705b4f3-8176-4c2b-84ac-e2748a95522f",
      "metadata": {
        "id": "e705b4f3-8176-4c2b-84ac-e2748a95522f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7bdd60-4420-4f4b-b3d7-e1e8c07772fc",
      "metadata": {
        "id": "fd7bdd60-4420-4f4b-b3d7-e1e8c07772fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26cf4657-2ce9-416d-972e-6dd0970aef77",
      "metadata": {
        "id": "26cf4657-2ce9-416d-972e-6dd0970aef77"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "51095720-5640-4dd2-a047-84097494b1ec",
      "metadata": {
        "id": "51095720-5640-4dd2-a047-84097494b1ec"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.2,0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62a2d60-4ea5-4bd2-aea1-c9dca23ecfd1",
      "metadata": {
        "id": "d62a2d60-4ea5-4bd2-aea1-c9dca23ecfd1",
        "outputId": "9828540f-8f1f-4039-b277-2f00705a0eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.553517 & 0.832631 & 0.00104219 & 0.000139102 \\\\\n",
            " 0.553509 & 0.832636 & 0.00104897 & 0.00013629  \\\\\n",
            " 0.553506 & 0.832637 & 0.00105138 & 0.000135233 \\\\\n",
            " 0.553505 & 0.832638 & 0.00105258 & 0.000134698 \\\\\n",
            " 0.553504 & 0.832639 & 0.00105331 & 0.000134378 \\\\\n",
            " 0.553504 & 0.832639 & 0.00105379 & 0.000134164 \\\\\n",
            " 0.553503 & 0.832639 & 0.00105413 & 0.000134011 \\\\\n",
            " 0.553503 & 0.83264  & 0.00105439 & 0.000133897 \\\\\n",
            " 0.553503 & 0.83264  & 0.00105459 & 0.000133808 \\\\\n",
            " 0.553503 & 0.83264  & 0.00105475 & 0.000133737 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105488 & 0.000133679 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105499 & 0.00013363  \\\\\n",
            " 0.553502 & 0.83264  & 0.00105509 & 0.000133589 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105516 & 0.000133554 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105523 & 0.000133524 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105529 & 0.000133497 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105535 & 0.000133474 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105539 & 0.000133453 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105544 & 0.000133434 \\\\\n",
            " 0.553502 & 0.83264  & 0.00105547 & 0.000133417 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.66478036]\n",
            " [0.66476728]\n",
            " [0.66476266]\n",
            " [0.66476035]\n",
            " [0.66475896]\n",
            " [0.66475804]\n",
            " [0.66475738]\n",
            " [0.66475689]\n",
            " [0.6647565 ]\n",
            " [0.6647562 ]\n",
            " [0.66475594]\n",
            " [0.66475573]\n",
            " [0.66475556]\n",
            " [0.6647554 ]\n",
            " [0.66475527]\n",
            " [0.66475516]\n",
            " [0.66475506]\n",
            " [0.66475497]\n",
            " [0.66475488]\n",
            " [0.66475481]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.2,0.2]\n",
        "NEWSIR(ar_coeff, sir_1_time_series1, 10000, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b351fef0-e7b6-4e7a-bbeb-f1c37ac84d7e",
      "metadata": {
        "id": "b351fef0-e7b6-4e7a-bbeb-f1c37ac84d7e"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823ee4e3-d2e4-4536-9053-aa218671a448",
      "metadata": {
        "id": "823ee4e3-d2e4-4536-9053-aa218671a448",
        "outputId": "1edc37ec-1f16-4eb7-e2db-b6b56594bdfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.555403 & 0.830972 & -0.00119026 & 0.00466392 \\\\\n",
            " 0.555396 & 0.83095  & -0.00118676 & 0.0047071  \\\\\n",
            " 0.555392 & 0.83094  & -0.00118428 & 0.00473366 \\\\\n",
            " 0.555389 & 0.830934 & -0.00118354 & 0.00475167 \\\\\n",
            " 0.555387 & 0.83093  & -0.00118326 & 0.00476499 \\\\\n",
            " 0.555386 & 0.830927 & -0.00118336 & 0.00477535 \\\\\n",
            " 0.555385 & 0.830925 & -0.00118363 & 0.00478352 \\\\\n",
            " 0.555384 & 0.830923 & -0.00118395 & 0.00478999 \\\\\n",
            " 0.555383 & 0.830922 & -0.00118427 & 0.00479526 \\\\\n",
            " 0.555383 & 0.83092  & -0.00118455 & 0.0047996  \\\\\n",
            " 0.555382 & 0.830919 & -0.00118479 & 0.00480323 \\\\\n",
            " 0.555382 & 0.830919 & -0.001185   & 0.0048063  \\\\\n",
            " 0.555381 & 0.830918 & -0.00118518 & 0.00480893 \\\\\n",
            " 0.555381 & 0.830917 & -0.00118534 & 0.00481121 \\\\\n",
            " 0.555381 & 0.830917 & -0.00118548 & 0.00481319 \\\\\n",
            " 0.55538  & 0.830916 & -0.0011856  & 0.00481494 \\\\\n",
            " 0.55538  & 0.830916 & -0.0011857  & 0.00481648 \\\\\n",
            " 0.55538  & 0.830916 & -0.0011858  & 0.00481785 \\\\\n",
            " 0.55538  & 0.830915 & -0.00118589 & 0.00481908 \\\\\n",
            " 0.55538  & 0.830915 & -0.00118596 & 0.00482019 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.6683774 ]\n",
            " [0.66838691]\n",
            " [0.66839005]\n",
            " [0.66839162]\n",
            " [0.66839255]\n",
            " [0.66839318]\n",
            " [0.66839363]\n",
            " [0.66839396]\n",
            " [0.66839422]\n",
            " [0.66839443]\n",
            " [0.6683946 ]\n",
            " [0.66839474]\n",
            " [0.66839487]\n",
            " [0.66839497]\n",
            " [0.66839506]\n",
            " [0.66839514]\n",
            " [0.66839521]\n",
            " [0.66839527]\n",
            " [0.66839532]\n",
            " [0.66839537]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.8,0.8]\n",
        "NEWSIR(ar_coeff, sir_1_time_series1, 10000, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "506fe52e-3be9-4674-9ab2-7f2f473b55f1",
      "metadata": {
        "id": "506fe52e-3be9-4674-9ab2-7f2f473b55f1"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e458a68-7b29-453b-80be-0966839c9280",
      "metadata": {
        "id": "7e458a68-7b29-453b-80be-0966839c9280",
        "outputId": "4a83197b-c3ee-40f9-ebf0-129f661c69f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.460693 & 0.886914 & -0.000132539 & 0.000892078 \\\\\n",
            " 0.450926 & 0.891848 & -0.000215107 & 0.000951643 \\\\\n",
            " 0.446836 & 0.893864 & -0.000274556 & 0.000975757 \\\\\n",
            " 0.444678 & 0.894915 & -0.000313526 & 0.000986374 \\\\\n",
            " 0.443366 & 0.89555  & -0.000339783 & 0.000992    \\\\\n",
            " 0.442491 & 0.895971 & -0.000358299 & 0.000995843 \\\\\n",
            " 0.441866 & 0.896271 & -0.000371721 & 0.00099858  \\\\\n",
            " 0.441398 & 0.896495 & -0.000381876 & 0.00100075  \\\\\n",
            " 0.441035 & 0.896669 & -0.000389784 & 0.00100248  \\\\\n",
            " 0.440745 & 0.896807 & -0.00039614  & 0.00100391  \\\\\n",
            " 0.440508 & 0.89692  & -0.00040136  & 0.00100509  \\\\\n",
            " 0.44031  & 0.897014 & -0.000405714 & 0.00100608  \\\\\n",
            " 0.440143 & 0.897094 & -0.0004094   & 0.00100692  \\\\\n",
            " 0.44     & 0.897162 & -0.000412562 & 0.00100765  \\\\\n",
            " 0.439877 & 0.897221 & -0.000415302 & 0.00100829  \\\\\n",
            " 0.439768 & 0.897272 & -0.000417701 & 0.00100885  \\\\\n",
            " 0.439673 & 0.897318 & -0.000419818 & 0.00100934  \\\\\n",
            " 0.439588 & 0.897358 & -0.0004217   & 0.00100978  \\\\\n",
            " 0.439512 & 0.897394 & -0.000423384 & 0.00101018  \\\\\n",
            " 0.439444 & 0.897427 & -0.0004249   & 0.00101053  \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.51943387]\n",
            " [0.50560858]\n",
            " [0.49989211]\n",
            " [0.49689379]\n",
            " [0.49507729]\n",
            " [0.49386687]\n",
            " [0.49300465]\n",
            " [0.49235979]\n",
            " [0.49185944]\n",
            " [0.49145995]\n",
            " [0.49113362]\n",
            " [0.49086205]\n",
            " [0.49063251]\n",
            " [0.49043596]\n",
            " [0.49026575]\n",
            " [0.49011693]\n",
            " [0.48998569]\n",
            " [0.48986911]\n",
            " [0.48976485]\n",
            " [0.48967105]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.8,0.8]\n",
        "NEWSIR(ar_coeff, sir_1_time_series1, 10000, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c39aecd-ab82-4c3d-bf0c-e0fe47713e6b",
      "metadata": {
        "id": "0c39aecd-ab82-4c3d-bf0c-e0fe47713e6b"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.5,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0ea3c2-9819-4dfc-81c1-bafd0a49bf7e",
      "metadata": {
        "id": "4c0ea3c2-9819-4dfc-81c1-bafd0a49bf7e",
        "outputId": "82cf453b-93df-433b-b209-b92911fb3ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.461182 & 0.886941 & -0.000348751 & -0.000559072 \\\\\n",
            " 0.451528 & 0.891867 & -0.000304097 & -0.000635605 \\\\\n",
            " 0.44749  & 0.893885 & -0.000279163 & -0.000672299 \\\\\n",
            " 0.44536  & 0.894939 & -0.000265587 & -0.000692759 \\\\\n",
            " 0.444067 & 0.895576 & -0.000257224 & -0.000705709 \\\\\n",
            " 0.443203 & 0.895999 & -0.000251622 & -0.000714455 \\\\\n",
            " 0.442587 & 0.8963   & -0.000247625 & -0.000720833 \\\\\n",
            " 0.442126 & 0.896526 & -0.000244632 & -0.000725688 \\\\\n",
            " 0.441768 & 0.8967   & -0.000242307 & -0.000729496 \\\\\n",
            " 0.441482 & 0.89684  & -0.000240449 & -0.000732561 \\\\\n",
            " 0.441249 & 0.896953 & -0.000238931 & -0.000735085 \\\\\n",
            " 0.441054 & 0.897048 & -0.000237667 & -0.000737199 \\\\\n",
            " 0.44089  & 0.897128 & -0.000236599 & -0.000738995 \\\\\n",
            " 0.440749 & 0.897196 & -0.000235683 & -0.000740539 \\\\\n",
            " 0.440627 & 0.897256 & -0.00023489  & -0.000741878 \\\\\n",
            " 0.44052  & 0.897308 & -0.000234197 & -0.00074305  \\\\\n",
            " 0.440426 & 0.897353 & -0.000233585 & -0.000744086 \\\\\n",
            " 0.440342 & 0.897394 & -0.000233042 & -0.000745007 \\\\\n",
            " 0.440267 & 0.89743  & -0.000232556 & -0.000745831 \\\\\n",
            " 0.4402   & 0.897463 & -0.000232119 & -0.000746573 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.51996893]\n",
            " [0.50627289]\n",
            " [0.50061191]\n",
            " [0.49764343]\n",
            " [0.49584518]\n",
            " [0.49464698]\n",
            " [0.49379349]\n",
            " [0.49315519]\n",
            " [0.49265993]\n",
            " [0.49226451]\n",
            " [0.49194151]\n",
            " [0.4916727 ]\n",
            " [0.49144551]\n",
            " [0.49125096]\n",
            " [0.49108249]\n",
            " [0.49093518]\n",
            " [0.49080529]\n",
            " [0.4906899 ]\n",
            " [0.4905867 ]\n",
            " [0.49049387]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.5,0.8]\n",
        "NEWSIR(ar_coeff, sir_1_time_series1, 10000, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feeab50c-64b8-4f0c-9b8f-70c1a47fddd1",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "feeab50c-64b8-4f0c-9b8f-70c1a47fddd1"
      },
      "source": [
        "# SIR for Time series new objective(Single sum)\n",
        "## The results are shown by 1. directions 2. ratio between first two coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a906ed-f527-471c-a8aa-e64222d5d1ea",
      "metadata": {
        "id": "e9a906ed-f527-471c-a8aa-e64222d5d1ea"
      },
      "source": [
        "If the objective is $$\\text{diag}(W^T V^{[1: Q]} W)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "937da798-62b9-45b9-b3a2-13d283705e49",
      "metadata": {
        "id": "937da798-62b9-45b9-b3a2-13d283705e49"
      },
      "source": [
        "## Use equal slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba56d3b-5959-490b-abe3-1afea5abc562",
      "metadata": {
        "id": "eba56d3b-5959-490b-abe3-1afea5abc562"
      },
      "outputs": [],
      "source": [
        "#from 0 to Q single sum\n",
        "from tabulate import tabulate\n",
        "def NEWSIRsingle(ar_coeff):\n",
        "    num_N = 5\n",
        "    n_obs = 1000\n",
        "    noise = np.zeros((num_N, n_obs))\n",
        "    n = 100\n",
        "    H = 50\n",
        "    P = 4\n",
        "    K = 1\n",
        "    S = 20\n",
        "    hat = [np.zeros((P, 1)) for i in range(S)]\n",
        "    # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "    g = np.zeros((S, 1))\n",
        "    for w in range(n):\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "        ar_series = np.zeros((num_N, n_obs))\n",
        "        for t in range(0, n_obs):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
        "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
        "            ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
        "        y = ar_series[4]\n",
        "        X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "        V = []\n",
        "        for a in range(0,S+1):\n",
        "            M, edr, lam1 = sir_1_time_series(X, y, a, H, K)\n",
        "            V.append(M)\n",
        "        for q in range(1, S+1):\n",
        "            Q = np.zeros((P, P))\n",
        "            phi = ar_coeff\n",
        "            for j in range(P):\n",
        "                for k in range(P):\n",
        "                    Q[j,k] = sum(phi[j]**a * V[a][j,k] * phi[k]**a for a in range(0,q)) #single sum\n",
        "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "            K_index = np.argpartition(np.abs(eigenvalues1), P-K) >= P-K\n",
        "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "            edr_est =  K_largest_eigenvectors\n",
        "            if edr_est[0]<0:\n",
        "                edr_est = -edr_est\n",
        "            edr_est = edr_est/np.linalg.norm(edr_est)\n",
        "            hat[q-1] += edr_est\n",
        "    for i in range(S):\n",
        "        hat[i] = hat[i]/n\n",
        "        g[i] = hat[i][0] / hat[i][1]\n",
        "    array = np.array(hat)\n",
        "    print(tabulate(array, tablefmt='latex'))\n",
        "    print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2fea24d-689b-4ec5-bbbc-d8536eeaea5a",
      "metadata": {
        "id": "f2fea24d-689b-4ec5-bbbc-d8536eeaea5a"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.2,0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311b845e-296b-4b11-b01c-fcc74c015f40",
      "metadata": {
        "id": "311b845e-296b-4b11-b01c-fcc74c015f40",
        "outputId": "6ef84a60-011d-446a-9871-5818c1ce8b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.55235  & 0.831289 & -0.00652422 &  0.00176025 \\\\\n",
            " 0.554268 & 0.825945 & -0.0128939  & -0.00945419 \\\\\n",
            " 0.554282 & 0.825614 & -0.0131315  & -0.00992433 \\\\\n",
            " 0.554283 & 0.825601 & -0.0131409  & -0.00994309 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994384 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            " 0.554283 & 0.8256   & -0.0131413  & -0.00994387 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.6644504 ]\n",
            " [0.67107161]\n",
            " [0.67135713]\n",
            " [0.6713686 ]\n",
            " [0.67136905]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]\n",
            " [0.67136907]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.2,0.2]\n",
        "NEWSIRsingle(ar_coeff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567500d2-b296-468b-8068-9973be61ab32",
      "metadata": {
        "id": "567500d2-b296-468b-8068-9973be61ab32"
      },
      "source": [
        "### ar_coeff = [0.2,0.2,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40504e31-5645-4b76-84f1-aaec87a624fe",
      "metadata": {
        "id": "40504e31-5645-4b76-84f1-aaec87a624fe"
      },
      "outputs": [],
      "source": [
        "ar_coeff = [0.2,0.2,0.8,0.8]\n",
        "NEWSIRsingle(ar_coeff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81a4293-f6b6-4830-9910-ca66487a1979",
      "metadata": {
        "id": "f81a4293-f6b6-4830-9910-ca66487a1979"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.5,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb08a0a-96d2-4a41-8819-382f66d8c6dc",
      "metadata": {
        "id": "5bb08a0a-96d2-4a41-8819-382f66d8c6dc"
      },
      "outputs": [],
      "source": [
        "ar_coeff = [0.2,0.5,0.5,0.8]\n",
        "NEWSIRsingle(ar_coeff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe39416f-461f-45a4-92c2-64bdd2d6bf45",
      "metadata": {
        "id": "fe39416f-461f-45a4-92c2-64bdd2d6bf45"
      },
      "source": [
        "### ar_coeff = [0.2,0.5,0.8,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8450ba-bc0b-49ef-a576-00481704bb0b",
      "metadata": {
        "id": "dd8450ba-bc0b-49ef-a576-00481704bb0b"
      },
      "outputs": [],
      "source": [
        "ar_coeff = [0.2,0.5,0.8,0.8]\n",
        "NEWSIRsingle(ar_coeff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c1aed6-a689-46d6-a553-34ed9288b38e",
      "metadata": {
        "id": "e3c1aed6-a689-46d6-a553-34ed9288b38e"
      },
      "source": [
        "## Use equal number in each slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739897d3-fd39-4517-9dcc-2ed44ea96b36",
      "metadata": {
        "id": "739897d3-fd39-4517-9dcc-2ed44ea96b36"
      },
      "outputs": [],
      "source": [
        "#from 0 to Q single sum\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "def uuu2(ar_coeff):\n",
        "    import numpy as np\n",
        "    from tabulate import tabulate\n",
        "\n",
        "    def sir_1_time_series1(X, y, s, num_slices, K):\n",
        "        n_samples, n_features = X.shape\n",
        "        V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
        "        # Step 1: Sort the data by the response variable\n",
        "        sorted_indices = np.argsort(y)\n",
        "        X_sorted = X[sorted_indices]\n",
        "        y_sorted = y[sorted_indices]\n",
        "        # Step 2: Divide the data into slices\n",
        "        slice_size = n_samples // num_slices\n",
        "        ph_hat = slice_size / n_samples\n",
        "        slices = []\n",
        "\n",
        "        for i in range(num_slices):\n",
        "            start_idx = i * slice_size\n",
        "            if i < num_slices - 1:\n",
        "                end_idx = (i + 1) * slice_size\n",
        "            else:  # Last slice includes any remaining samples\n",
        "                end_idx = n_samples\n",
        "            if start_idx - s > 0:\n",
        "                slices.append((X[[x - s for x in sorted_indices[start_idx:end_idx]]], y_sorted[start_idx:end_idx]))\n",
        "            else:\n",
        "                slices.append((X[sorted_indices[0:end_idx - s]], y_sorted[start_idx:end_idx]))\n",
        "\n",
        "        # Step 3: Compute the means of the predictors within each slice\n",
        "        X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
        "\n",
        "        # Step 4: Center the predictor means\n",
        "        X_centered = X_means - np.mean(X_means, axis=0)\n",
        "\n",
        "        V_hat = np.add(V_hat, ph_hat * np.matmul(X_centered.T, X_centered))\n",
        "\n",
        "        #report wrong, there's  NaN or inf value in V_hat, so add this\n",
        "        # Check for NaN or inf values in V_hat\n",
        "        if np.isnan(V_hat).any() or np.isinf(V_hat).any():\n",
        "            # Handle NaN or inf values appropriately\n",
        "            # For example, replace NaN values with 0 and inf values with a large number\n",
        "            V_hat[np.isnan(V_hat)] = 0\n",
        "            V_hat[np.isinf(V_hat)] = np.nanmax(np.abs(V_hat))  # Replace inf with maximum absolute value in V_hat\n",
        "\n",
        "    # Compute eigenvalues and eigenvectors\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
        "        K_index = np.argpartition(np.abs(eigenvalues), X.shape[1] - K) >= X.shape[1] - K\n",
        "        K_largest_eigenvectors = eigenvectors[:, K_index]\n",
        "        edr_est = K_largest_eigenvectors\n",
        "\n",
        "        return V_hat, edr_est, eigenvalues ** 2\n",
        "\n",
        "    num_N = 5\n",
        "    n_obs = 1000\n",
        "    noise = np.zeros((num_N, n_obs))\n",
        "    n = 100\n",
        "    H = 50\n",
        "    P = 4\n",
        "    K = 1\n",
        "    S = 20\n",
        "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
        "    g = np.zeros((S, 1))\n",
        "    # ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "    n1 = 0\n",
        "    while n1 < 100:\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "        ar_series = np.zeros((num_N, n_obs))\n",
        "        for t in range(0, n_obs):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
        "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
        "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
        "            ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
        "        y = ar_series[4]\n",
        "        X = np.concatenate([ar_series[i].reshape(-1, 1) for i in range(4)], axis=1)\n",
        "        V = []\n",
        "        for a in range(0, S + 1):\n",
        "            M, _, _ = sir_1_time_series1(X, y, a, H, K)\n",
        "            V.append(M)\n",
        "        for q in range(1, S + 1):\n",
        "            Q = np.zeros((P, P))\n",
        "            phi = ar_coeff\n",
        "            for j in range(P):\n",
        "                for k in range(P):\n",
        "                    Q[j, k] = sum(phi[j] ** a * V[a][j, k] * phi[k] ** a for a in range(0, q))\n",
        "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
        "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
        "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
        "            edr_est = K_largest_eigenvectors\n",
        "            if edr_est[0] < 0:\n",
        "                edr_est = -edr_est\n",
        "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
        "            hat[q - 1] += edr_est\n",
        "            n1 += 1\n",
        "\n",
        "    for i in range(S):\n",
        "        hat[i] = hat[i] / n\n",
        "        g[i] = hat[i][0] / hat[i][1]\n",
        "    array = np.array(hat)\n",
        "    print(tabulate(array, tablefmt='latex'))\n",
        "    print(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39a93f1-9daa-49fc-b390-c22972870a23",
      "metadata": {
        "id": "f39a93f1-9daa-49fc-b390-c22972870a23"
      },
      "outputs": [],
      "source": [
        "ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
        "uuu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19356add-f290-484b-89ba-a770e8cd6e9d",
      "metadata": {
        "id": "19356add-f290-484b-89ba-a770e8cd6e9d",
        "outputId": "17d7c008-ccbd-42ee-be43-cc82ccceec90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0233308 & 0.0439774 & 0.00148481 & -0.000284376 \\\\\n",
            " 0.0221942 & 0.0444542 & 0.00192512 & -0.000589303 \\\\\n",
            " 0.0219856 & 0.0444877 & 0.00210631 & -0.000800864 \\\\\n",
            " 0.0219211 & 0.0444724 & 0.0022261  & -0.00096454  \\\\\n",
            " 0.0219007 & 0.0444587 & 0.00228155 & -0.00103267  \\\\\n",
            " 0.0218916 & 0.0444483 & 0.00231401 & -0.00105981  \\\\\n",
            " 0.0218865 & 0.0444405 & 0.00233926 & -0.00107817  \\\\\n",
            " 0.0218835 & 0.0444349 & 0.00235877 & -0.00108906  \\\\\n",
            " 0.0218817 & 0.0444316 & 0.00236771 & -0.00109702  \\\\\n",
            " 0.0218806 & 0.0444295 & 0.00237299 & -0.00110342  \\\\\n",
            " 0.0218799 & 0.0444281 & 0.0023764  & -0.00110694  \\\\\n",
            " 0.0218794 & 0.0444272 & 0.00237852 & -0.00110875  \\\\\n",
            " 0.0218791 & 0.0444266 & 0.00238001 & -0.00111006  \\\\\n",
            " 0.0218789 & 0.0444262 & 0.00238104 & -0.00111085  \\\\\n",
            " 0.0218788 & 0.044426  & 0.00238187 & -0.00111133  \\\\\n",
            " 0.0218787 & 0.0444259 & 0.00238226 & -0.00111153  \\\\\n",
            " 0.0218787 & 0.0444258 & 0.0023826  & -0.00111165  \\\\\n",
            " 0.0218786 & 0.0444257 & 0.00238281 & -0.00111177  \\\\\n",
            " 0.0218786 & 0.0444256 & 0.00238299 & -0.00111189  \\\\\n",
            " 0.0218786 & 0.0444256 & 0.00238312 & -0.0011121   \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.53051831]\n",
            " [0.49925978]\n",
            " [0.49419655]\n",
            " [0.49291432]\n",
            " [0.49260783]\n",
            " [0.4925187 ]\n",
            " [0.4924912 ]\n",
            " [0.49248342]\n",
            " [0.4924806 ]\n",
            " [0.4924795 ]\n",
            " [0.49247878]\n",
            " [0.49247807]\n",
            " [0.49247767]\n",
            " [0.49247749]\n",
            " [0.4924774 ]\n",
            " [0.49247735]\n",
            " [0.49247728]\n",
            " [0.49247726]\n",
            " [0.49247725]\n",
            " [0.49247729]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.8,0.8]\n",
        "uuu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd0b89e-e1d5-45eb-912b-b62d90d07d7e",
      "metadata": {
        "id": "3cd0b89e-e1d5-45eb-912b-b62d90d07d7e",
        "outputId": "2804d1dd-5e2f-43e4-a592-0b067ccc1649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0281901 & 0.0407746 & 0.000983024 & -0.00229931 \\\\\n",
            " 0.0281302 & 0.0406785 & 0.00108717  & -0.00267873 \\\\\n",
            " 0.0280782 & 0.0405959 & 0.00119454  & -0.00292771 \\\\\n",
            " 0.0280312 & 0.0405244 & 0.00132309  & -0.00306977 \\\\\n",
            " 0.0279983 & 0.0404748 & 0.00143155  & -0.00316628 \\\\\n",
            " 0.0279731 & 0.0404372 & 0.00151865  & -0.00323207 \\\\\n",
            " 0.0279567 & 0.0404124 & 0.00156755  & -0.0032817  \\\\\n",
            " 0.0279465 & 0.0403974 & 0.00160851  & -0.0033108  \\\\\n",
            " 0.0279403 & 0.0403882 & 0.00163071  & -0.00332418 \\\\\n",
            " 0.0279365 & 0.0403826 & 0.00164288  & -0.00333221 \\\\\n",
            " 0.0279336 & 0.0403781 & 0.00165054  & -0.00333886 \\\\\n",
            " 0.0279319 & 0.0403755 & 0.00165522  & -0.00334191 \\\\\n",
            " 0.0279309 & 0.040374  & 0.0016585   & -0.0033438  \\\\\n",
            " 0.0279302 & 0.040373  & 0.0016607   & -0.00334503 \\\\\n",
            " 0.0279297 & 0.0403722 & 0.00166182  & -0.00334607 \\\\\n",
            " 0.0279294 & 0.0403718 & 0.00166244  & -0.00334668 \\\\\n",
            " 0.0279292 & 0.0403715 & 0.00166287  & -0.00334692 \\\\\n",
            " 0.0279291 & 0.0403713 & 0.0016633   & -0.00334719 \\\\\n",
            " 0.027929  & 0.0403712 & 0.00166347  & -0.0033474  \\\\\n",
            " 0.027929  & 0.0403711 & 0.00166347  & -0.00334765 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.69136287]\n",
            " [0.69152651]\n",
            " [0.69165107]\n",
            " [0.6917126 ]\n",
            " [0.6917463 ]\n",
            " [0.69176655]\n",
            " [0.69178432]\n",
            " [0.69178827]\n",
            " [0.69179286]\n",
            " [0.69179625]\n",
            " [0.69180003]\n",
            " [0.6918021 ]\n",
            " [0.69180302]\n",
            " [0.69180371]\n",
            " [0.69180441]\n",
            " [0.69180486]\n",
            " [0.6918051 ]\n",
            " [0.6918052 ]\n",
            " [0.69180528]\n",
            " [0.69180545]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.8,0.8]\n",
        "uuu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9728db29-71f3-4702-899b-0aa2b0a09a0d",
      "metadata": {
        "id": "9728db29-71f3-4702-899b-0aa2b0a09a0d",
        "outputId": "15609f7b-0297-4309-aa0e-7be765d1cb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0219593 & 0.04474   & -0.000577489 & -0.00238238 \\\\\n",
            " 0.0207578 & 0.0452431 & -0.000575591 & -0.00293161 \\\\\n",
            " 0.0205502 & 0.0453095 & -0.00058722  & -0.00322293 \\\\\n",
            " 0.0204969 & 0.0453141 & -0.000588143 & -0.00338837 \\\\\n",
            " 0.0204803 & 0.0453096 & -0.000589038 & -0.00347471 \\\\\n",
            " 0.0204743 & 0.0453051 & -0.000588676 & -0.00352741 \\\\\n",
            " 0.0204716 & 0.0453019 & -0.000588435 & -0.00355672 \\\\\n",
            " 0.0204698 & 0.0452991 & -0.000588162 & -0.00358144 \\\\\n",
            " 0.0204685 & 0.0452969 & -0.000587925 & -0.00359898 \\\\\n",
            " 0.0204677 & 0.0452956 & -0.000587791 & -0.00361018 \\\\\n",
            " 0.0204672 & 0.0452947 & -0.000587693 & -0.00361719 \\\\\n",
            " 0.020467  & 0.0452942 & -0.000587637 & -0.00362133 \\\\\n",
            " 0.0204668 & 0.0452938 & -0.000587589 & -0.00362406 \\\\\n",
            " 0.0204666 & 0.0452936 & -0.000587557 & -0.00362584 \\\\\n",
            " 0.0204666 & 0.0452935 & -0.000587538 & -0.00362686 \\\\\n",
            " 0.0204665 & 0.0452934 & -0.000587528 & -0.00362753 \\\\\n",
            " 0.0204665 & 0.0452933 & -0.000587521 & -0.00362791 \\\\\n",
            " 0.0204665 & 0.0452933 & -0.000587516 & -0.00362817 \\\\\n",
            " 0.0204665 & 0.0452933 & -0.000587514 & -0.00362834 \\\\\n",
            " 0.0204665 & 0.0452933 & -0.000587511 & -0.00362845 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.4908212 ]\n",
            " [0.45880658]\n",
            " [0.45355127]\n",
            " [0.45232988]\n",
            " [0.45200722]\n",
            " [0.45192081]\n",
            " [0.45189272]\n",
            " [0.45188019]\n",
            " [0.45187404]\n",
            " [0.4518703 ]\n",
            " [0.45186831]\n",
            " [0.45186715]\n",
            " [0.45186659]\n",
            " [0.45186622]\n",
            " [0.45186599]\n",
            " [0.45186581]\n",
            " [0.45186573]\n",
            " [0.45186567]\n",
            " [0.45186562]\n",
            " [0.45186559]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.5,0.5,0.8]\n",
        "uuu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28abb88-0412-4ce5-a92a-ba726ae7a362",
      "metadata": {
        "id": "d28abb88-0412-4ce5-a92a-ba726ae7a362",
        "outputId": "4aa59d9f-a0b4-473d-e8ef-12b4fd4fac1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrr}\n",
            "\\hline\n",
            " 0.0276621 & 0.0415087 & -0.00187225 & 0.00016349  \\\\\n",
            " 0.0276669 & 0.0415049 & -0.00186133 & 0.000174439 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174786 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174795 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            " 0.0276667 & 0.041505  & -0.0018606  & 0.000174796 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "[[0.66641746]\n",
            " [0.66659372]\n",
            " [0.66658635]\n",
            " [0.66658555]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]\n",
            " [0.66658554]]\n"
          ]
        }
      ],
      "source": [
        "ar_coeff = [0.2,0.2,0.2,0.2]\n",
        "uuu2(ar_coeff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d01bc003-7818-4752-b1bf-eaafa4801c3a",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "d01bc003-7818-4752-b1bf-eaafa4801c3a"
      },
      "source": [
        "# TSIR\n",
        "## The results are shown by 1. directions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b67efc8-575d-4731-b2b9-6d9cf260fc16",
      "metadata": {
        "id": "9b67efc8-575d-4731-b2b9-6d9cf260fc16"
      },
      "outputs": [],
      "source": [
        "#0.2 0.2 can find edr direction\n",
        "def TSIR(ar_coeff, T):\n",
        "    n = 100\n",
        "    S = 12\n",
        "    H = 50\n",
        "    K = 1\n",
        "    P = 4\n",
        "    num_N = 5\n",
        "    n_x = 2\n",
        "    n_obs = 1000\n",
        "    QW = np.zeros((P,4))\n",
        "    for w in range(n):\n",
        "        noise = np.zeros((num_N, n_obs))\n",
        "        ar_series = np.zeros((num_N, n_obs))\n",
        "        Newar_series = np.zeros((n_obs, num_N - 1))\n",
        "        M = np.zeros((num_N, n_obs))\n",
        "        X = []\n",
        "        num_dataframes = S\n",
        "        y = []\n",
        "        ar_seriesT1 = pd.DataFrame({})\n",
        "        ar_seriesT = pd.DataFrame({})\n",
        "        X1 = np.zeros((P,P))\n",
        "        for l in range(num_dataframes):\n",
        "            dg = pd.DataFrame({})\n",
        "            X.append(dg)\n",
        "        scaler = StandardScaler()\n",
        "        lam = pd.DataFrame({})\n",
        "        # ar_coeff1 = 0.3  # Autoregressive coefficient\n",
        "        # ar_coeff2 = 0.7\n",
        "        B = []\n",
        "        edr1 = []\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "        # Generate the additive AR time series\n",
        "        for t in range(0, n_obs):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "            ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
        "            ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
        "            ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
        "        y = ar_series[4]\n",
        "        X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "        X = scaler.fit_transform(X)\n",
        "        # for t in range(0, n_obs):\n",
        "        #     ar_seriesT1 = pd.concat([ar_seriesT1, pd.DataFrame([[ar_series[0][t], ar_series[1][t], ar_series[2][t], ar_series[3][t]]])], axis = 0, ignore_index=True)\n",
        "        #     X1 = X1 + ar_seriesT1.values[t].reshape(-1, 1) @ ar_seriesT1.values[t].reshape(-1, 1).T\n",
        "        # X1 = 1/n_obs*X1\n",
        "        # eigenvalues, eigenvectors = np.linalg.eig(X1)\n",
        "        # # Compute reciprocal square root of eigenvalues\n",
        "        # recip_sqrt_eigenvalues = np.diag(1 / np.sqrt(eigenvalues))\n",
        "        # # Reconstruct the matrix\n",
        "        # A_neg_half = eigenvectors @ recip_sqrt_eigenvalues @ np.linalg.inv(eigenvectors)\n",
        "        # for t in range(0, n_obs):\n",
        "        #     # M = np.array([Newar_series[i][t] for i in range(num_N - 1)])\n",
        "        #     Newar_series[t] = A_neg_half @ ar_seriesT1.values[t]\n",
        "        for j in range(1,S + 1):\n",
        "            # for T in range(1,n_obs + 1):\n",
        "            #     if T + j >= (n_obs):\n",
        "            #         break\n",
        "            #     else:\n",
        "                    # y[j-1] = pd.concat([y[j-1], pd.Series([ar_series[4][T+j]])], ignore_index=True)\n",
        "                    # M = pd.DataFrame({})\n",
        "                    # for i in range(0,5):\n",
        "                    #     M[i] = ar_series[i][T]\n",
        "            # ar_seriesT = pd.DataFrame([[Newar_series[T][0], Newar_series[T][1], Newar_series[T][2], Newar_series[T][3]]])\n",
        "            V, edr, lam1 = T(X, y, j, H, K=K)\n",
        "            B.append(V)\n",
        "            edr1.append(edr)\n",
        "        from scipy.stats import ortho_group\n",
        "        def create_random_orthogonal_matrix(rows, cols):\n",
        "            # Create a random matrix\n",
        "            random_matrix = np.random.rand(rows, cols)\n",
        "            # Perform QR decomposition\n",
        "            q, r = np.linalg.qr(random_matrix)\n",
        "            return q\n",
        "        rows = 4\n",
        "        cols = 4\n",
        "        P1 = create_random_orthogonal_matrix(rows, cols)\n",
        "        #W_i\n",
        "        Gam = np.zeros((4,4))\n",
        "        r = np.zeros((4,4))\n",
        "        n1 = 0\n",
        "        while n1<=10000:\n",
        "            for i in range(K):\n",
        "                for k in range(S):\n",
        "                    Gam[i] += (P1[i] @ B[k] @ P1[i]) * B[k] @ P1[i]\n",
        "            U, S1, VT = np.linalg.svd(Gam)\n",
        "            QQ = U @ VT\n",
        "            P1 = QQ\n",
        "            n1 = n1 + 1\n",
        "        for i in range(len(QQ)):\n",
        "            if QQ[i][0]<0:\n",
        "                QQ[i] = -QQ[i]\n",
        "        QQ = QQ/np.linalg.norm(QQ)\n",
        "        # sum(lam.apply(find_largest, axis=1).values[i]*edr1[i] for i in range(len(edr1)))\n",
        "        QW += QQ\n",
        "\n",
        "        # LAM = pd.DataFrame({})\n",
        "        # for j in range(1, S + 1):\n",
        "        #     for i in range(4):\n",
        "        #         LAM1= (QQ[i] @ B[j-1] @ QQ[i].T)**2\n",
        "        #         LAM = pd.concat([LAM, pd.DataFrame([LAM1])], ignore_index=True)\n",
        "        # total_sum = LAM.sum().sum()\n",
        "        # LAM = LAM/total_sum\n",
        "        # reshaped_data = LAM.values.reshape(S, 4)\n",
        "        # # Convert reshaped data back to DataFrame\n",
        "        # LAM = pd.DataFrame(reshaped_data)\n",
        "        # sorted_columns = LAM.sum().sort_values().index\n",
        "        # Reorder DataFrame columns based on sorted column names\n",
        "        # LAM = LAM[sorted_columns]\n",
        "\n",
        "    QW = QW/n\n",
        "\n",
        "    return QW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e7f7c7-0218-463c-bb7a-14cccbdc34e7",
      "metadata": {
        "id": "b9e7f7c7-0218-463c-bb7a-14cccbdc34e7",
        "outputId": "1774213d-a02f-4949-9286-860fa3d7b0f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.74463098e-01,  4.16778804e-01, -3.52710953e-04,\n",
              "         2.12060850e-03],\n",
              "       [ 4.17685428e-01, -2.73863926e-01,  3.77812782e-04,\n",
              "        -1.52171407e-03],\n",
              "       [ 0.00000000e+00,  5.02152914e-04,  4.99345206e-01,\n",
              "         2.06553633e-05],\n",
              "       [ 0.00000000e+00, -2.61130959e-03,  2.06553633e-05,\n",
              "         4.99567541e-01]])"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TSIR([0.2,0.2], sir_1_time_series1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4280d19-b917-4846-aeec-146c9ad6fea9",
      "metadata": {
        "id": "d4280d19-b917-4846-aeec-146c9ad6fea9",
        "outputId": "0bcdbdf3-ab99-459b-cff6-034ca68e2023"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.22438364e-01,  4.82752552e-01,  3.08550664e-03,\n",
              "        -2.66403375e-03],\n",
              "       [ 4.84052887e-01, -1.22117915e-01, -8.74153785e-04,\n",
              "         7.29552118e-04],\n",
              "       [ 0.00000000e+00, -3.21321710e-03,  4.98983577e-01,\n",
              "         2.85369021e-05],\n",
              "       [ 0.00000000e+00,  2.76436169e-03,  2.85369021e-05,\n",
              "         4.99675328e-01]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TSIR([0.2,0.8], sir_1_time_series1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923e4b78-d262-4e7f-ab99-0e1d8b60287b",
      "metadata": {
        "id": "923e4b78-d262-4e7f-ab99-0e1d8b60287b",
        "outputId": "ff5aa892-aaf8-450e-ee62-86a762e042ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.21742315, -0.00966039,  0.01254573,  0.03445188],\n",
              "       [ 0.42838298, -0.00425975, -0.00105679, -0.0245955 ],\n",
              "       [ 0.        ,  0.03597271,  0.4086829 ,  0.0046153 ],\n",
              "       [ 0.        ,  0.02906866,  0.0046153 ,  0.36736469]])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TSIR([0.2,0.2], sir_1_time_series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6180dc2e-7bc9-4119-95b3-2f8908aee8f3",
      "metadata": {
        "id": "6180dc2e-7bc9-4119-95b3-2f8908aee8f3",
        "outputId": "9ce71e3f-17cf-4d7e-9e51-24a40b8cec12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.33343568e-01, -2.49433031e-03, -6.40901368e-03,\n",
              "         3.76527795e-02],\n",
              "       [ 4.12871385e-01, -3.52583083e-03,  4.42063147e-03,\n",
              "        -7.69900231e-04],\n",
              "       [ 0.00000000e+00, -4.12862559e-02,  3.69667869e-01,\n",
              "         2.30828716e-03],\n",
              "       [ 0.00000000e+00,  7.89737522e-05,  2.30828716e-03,\n",
              "         3.42968195e-01]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TSIR([0.2,0.8], sir_1_time_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1b07e9-5c67-4eeb-bdc2-6dd9723cc482",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "6c1b07e9-5c67-4eeb-bdc2-6dd9723cc482"
      },
      "source": [
        "# My idea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a46651-8c52-4638-9d09-f5276ae68e53",
      "metadata": {
        "id": "11a46651-8c52-4638-9d09-f5276ae68e53"
      },
      "outputs": [],
      "source": [
        "#0.2 0.2 can find edr direction\n",
        "def find_largest(row):\n",
        "        return max(row)\n",
        "def IDEA(ar_coeff, T):\n",
        "    n = 100\n",
        "    S = 12\n",
        "    H = 50\n",
        "    K = 1\n",
        "    P = 4\n",
        "    num_N = 5\n",
        "    n_x = 2\n",
        "    n_obs = 10000\n",
        "    QW = np.zeros((P,4))\n",
        "    W1 = np.zeros((P, 1))\n",
        "    W2 = np.zeros((P, 1))\n",
        "    for w in range(n):\n",
        "        noise = np.zeros((num_N, n_obs))\n",
        "        ar_series = np.zeros((num_N, n_obs))\n",
        "        Newar_series = np.zeros((n_obs, num_N - 1))\n",
        "        M = np.zeros((num_N, n_obs))\n",
        "        X = []\n",
        "        num_dataframes = S\n",
        "        y = []\n",
        "        ar_seriesT1 = pd.DataFrame({})\n",
        "        ar_seriesT = pd.DataFrame({})\n",
        "        X1 = np.zeros((P,P))\n",
        "        for l in range(num_dataframes):\n",
        "            dg = pd.DataFrame({})\n",
        "            X.append(dg)\n",
        "        scaler = StandardScaler()\n",
        "        lam = pd.DataFrame({})\n",
        "        # ar_coeff1 = 0.3  # Autoregressive coefficient\n",
        "        # ar_coeff2 = 0.7\n",
        "        B = []\n",
        "        edr1 = []\n",
        "        for h in range(num_N):\n",
        "            noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
        "        # Generate the additive AR time series\n",
        "        for t in range(0, n_obs):\n",
        "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
        "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
        "            ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
        "            ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
        "            ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
        "        y = ar_series[4]\n",
        "        X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
        "        X = scaler.fit_transform(X)\n",
        "        # for t in range(0, n_obs):\n",
        "        #     ar_seriesT1 = pd.concat([ar_seriesT1, pd.DataFrame([[ar_series[0][t], ar_series[1][t], ar_series[2][t], ar_series[3][t]]])], axis = 0, ignore_index=True)\n",
        "        #     X1 = X1 + ar_seriesT1.values[t].reshape(-1, 1) @ ar_seriesT1.values[t].reshape(-1, 1).T\n",
        "        # X1 = 1/n_obs*X1\n",
        "        # eigenvalues, eigenvectors = np.linalg.eig(X1)\n",
        "        # # Compute reciprocal square root of eigenvalues\n",
        "        # recip_sqrt_eigenvalues = np.diag(1 / np.sqrt(eigenvalues))\n",
        "        # # Reconstruct the matrix\n",
        "        # A_neg_half = eigenvectors @ recip_sqrt_eigenvalues @ np.linalg.inv(eigenvectors)\n",
        "        # for t in range(0, n_obs):\n",
        "        #     # M = np.array([Newar_series[i][t] for i in range(num_N - 1)])\n",
        "        #     Newar_series[t] = A_neg_half @ ar_seriesT1.values[t]\n",
        "        for j in range(0,S + 1):\n",
        "            # for T in range(1,n_obs + 1):\n",
        "            #     if T + j >= (n_obs):\n",
        "            #         break\n",
        "            #     else:\n",
        "                    # y[j-1] = pd.concat([y[j-1], pd.Series([ar_series[4][T+j]])], ignore_index=True)\n",
        "                    # M = pd.DataFrame({})\n",
        "                    # for i in range(0,5):\n",
        "                    #     M[i] = ar_series[i][T]\n",
        "            # ar_seriesT = pd.DataFrame([[Newar_series[T][0], Newar_series[T][1], Newar_series[T][2], Newar_series[T][3]]])\n",
        "            V, edr, lam1 = T(X, y, j, H, K=K)\n",
        "            B.append(V)\n",
        "            edr1.append(edr)\n",
        "            lam = pd.concat([lam, pd.DataFrame([lam1])], ignore_index=True)\n",
        "            total_sum = lam.sum().sum()\n",
        "            lam = lam/total_sum\n",
        "            sorted_columns = lam.sum().sort_values().index\n",
        "            lam = lam[sorted_columns]\n",
        "\n",
        "    #add weights for each lag?\n",
        "        W1 += sum(lam.apply(find_largest, axis=1).values[i]*edr1[i] for i in range(len(edr1)))\n",
        "        W2 += sum(edr1[i] for i in range(len(edr1)))\n",
        "\n",
        "    W1 = W1/n\n",
        "    W2 = W2/n\n",
        "\n",
        "    return W1, W2, lam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a849642-d0d2-420d-b273-aaa757f4da09",
      "metadata": {
        "id": "7a849642-d0d2-420d-b273-aaa757f4da09",
        "outputId": "362e5d7b-6ea0-4982-a50d-93ed372bb3fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0.14199556],\n",
              "        [ 0.21071697],\n",
              "        [-0.00119924],\n",
              "        [ 0.00485361]]),\n",
              " array([[ 2.78978284],\n",
              "        [ 3.72508242],\n",
              "        [-0.02227834],\n",
              "        [ 0.0352592 ]]),\n",
              "            1         2         3         0\n",
              " 0   0.001262  0.006521  0.010868  0.574571\n",
              " 1   0.000041  0.000013  0.000011  0.402316\n",
              " 2   0.000010  0.000027  0.000054  0.002410\n",
              " 3   0.000011  0.000018  0.000032  0.000173\n",
              " 4   0.000009  0.000029  0.000051  0.000116\n",
              " 5   0.000042  0.000014  0.000024  0.000118\n",
              " 6   0.000008  0.000021  0.000014  0.000099\n",
              " 7   0.000008  0.000032  0.000025  0.000111\n",
              " 8   0.000008  0.000033  0.000044  0.000110\n",
              " 9   0.000023  0.000012  0.000015  0.000148\n",
              " 10  0.000015  0.000026  0.000030  0.000142\n",
              " 11  0.000022  0.000015  0.000009  0.000117\n",
              " 12  0.000034  0.000009  0.000014  0.000114)"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#add s=0?\n",
        "ar_coeff = [0.2, 0.2]\n",
        "IDEA(ar_coeff, sir_1_time_series1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd3d5e6-6d78-43dc-a85d-3b1a275a7459",
      "metadata": {
        "id": "1cd3d5e6-6d78-43dc-a85d-3b1a275a7459",
        "outputId": "156724d4-1552-4c5f-d27b-b0a363749864"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 1.22006264e-01],\n",
              "        [ 7.36171451e-01],\n",
              "        [-3.04964495e-03],\n",
              "        [-5.41659550e-04]]),\n",
              " array([[ 0.7085896 ],\n",
              "        [ 6.04233114],\n",
              "        [-0.01717659],\n",
              "        [ 0.01058967]]),\n",
              "            2         3         1         0\n",
              " 0   0.000016  0.000023  0.000054  0.316986\n",
              " 1   0.000004  0.000007  0.000030  0.267329\n",
              " 2   0.000007  0.000012  0.000020  0.160367\n",
              " 3   0.000024  0.000040  0.000008  0.097039\n",
              " 4   0.000006  0.000009  0.000031  0.054261\n",
              " 5   0.000010  0.000017  0.000052  0.031691\n",
              " 6   0.000028  0.000015  0.000053  0.020322\n",
              " 7   0.000027  0.000032  0.000046  0.014128\n",
              " 8   0.000028  0.000044  0.000074  0.010252\n",
              " 9   0.000026  0.000021  0.000009  0.008068\n",
              " 10  0.000045  0.000039  0.000011  0.007074\n",
              " 11  0.000037  0.000041  0.000009  0.005991\n",
              " 12  0.000017  0.000011  0.000029  0.005477)"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ar_coeff = [0.2, 0.8]\n",
        "IDEA(ar_coeff, sir_1_time_series1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe722b1-b0ae-4930-840b-1d35e1d983bd",
      "metadata": {
        "id": "5fe722b1-b0ae-4930-840b-1d35e1d983bd",
        "outputId": "83109566-8bec-4088-b2b9-6bbf2ae67abb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 5.49373512e-01],\n",
              "        [ 1.72398312e-01],\n",
              "        [ 1.19854428e-03],\n",
              "        [-5.44625445e-05]]),\n",
              " array([[ 6.87318977],\n",
              "        [ 1.23273416],\n",
              "        [ 0.0537869 ],\n",
              "        [-0.01108501]]),\n",
              "            3         2         1         0\n",
              " 0   0.000080  0.000119  0.000023  0.437500\n",
              " 1   0.000009  0.000006  0.000094  0.332962\n",
              " 2   0.000011  0.000014  0.000028  0.103827\n",
              " 3   0.000009  0.000014  0.000041  0.051413\n",
              " 4   0.000029  0.000037  0.000012  0.026473\n",
              " 5   0.000020  0.000014  0.000044  0.014612\n",
              " 6   0.000010  0.000009  0.000028  0.008355\n",
              " 7   0.000023  0.000011  0.000057  0.006085\n",
              " 8   0.000019  0.000010  0.000028  0.004677\n",
              " 9   0.000020  0.000024  0.000045  0.003891\n",
              " 10  0.000009  0.000017  0.000065  0.003200\n",
              " 11  0.000021  0.000020  0.000007  0.002960\n",
              " 12  0.000019  0.000013  0.000027  0.002958)"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ar_coeff = [0.8, 0.2]\n",
        "IDEA(ar_coeff, sir_1_time_series1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}