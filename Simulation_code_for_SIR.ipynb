{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ee3cc16-c854-4087-8238-b1aeda6575b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equal number in each slice for SIR\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_triangular\n",
    "def sir_modified(X, y, num_slices, K):\n",
    "    #\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    Q, R = np.linalg.qr(X)\n",
    "    n_samples, n_features = X.shape\n",
    "    Z = np.sqrt(n_samples) * Q\n",
    "    \n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    Z_sorted = Z[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((Z_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "\n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "\n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means - np.mean(X_means, axis=0)\n",
    "\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    \n",
    "    idx = eigenvalues.argsort()[::-1]  # Get indices that would sort eigenvalues in descending order\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    edr_est = solve_triangular(np.sqrt(n_samples) * R, eigenvectors)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    edr_est = edr_est[:, K_index]\n",
    "    # edr_est = edr_est.flatten()\n",
    "    if edr_est[0][0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    \n",
    "    return edr_est.T, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d16951-2841-4ffd-9763-7f5f07ffe2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c834725-f806-49ec-a162-a5d6c770f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001657901876191"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir_modified test on 2*z1t + 3*z2t\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t] + 4*ar_series[1][t] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    edr, _ = sir_modified(X, y, H, K=K)\n",
    "    hat += edr\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035fbbb-0545-440d-8b8d-e05e56117bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38d9dca-35ad-435d-a4fb-33f72ef753ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7496967032855786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir_modified test on 2*z1t + 3*z2t\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
    "        ar_series[4][t] = 3*ar_series[0][t] + 4*ar_series[1][t] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    \n",
    "    sir = SlicedInverseRegression(n_directions=1)\n",
    "    \n",
    "    sir.fit(X, y)\n",
    "    if sir.directions_[0][0] < 0:\n",
    "        sir.directions_ = -sir.directions_\n",
    "    hat += sir.directions_\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f83c0-716d-4274-8704-ff3f08640f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab18736-cc3e-48ec-8828-600c355c4596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16616637671152745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir package on 2*z1(t-1) + 3*z2(t-1): TSIR's model\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff1 = 0.2\n",
    "ar_coeff2 = 0.8\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
    "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    \n",
    "    sir = SlicedInverseRegression(n_directions=1)\n",
    "    \n",
    "    sir.fit(X, y)\n",
    "    if sir.directions_[0][0] < 0:\n",
    "        sir.directions_ = -sir.directions_\n",
    "    hat += sir.directions_\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793eef80-462d-43a6-a62d-6ef6bd2af9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f773d1-4f6e-4c42-afe8-b9101b5687f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrr}\n",
      "\\hline\n",
      " 0.0279931 & 0.00805542 & 3.82269e-06 & 8.43091e-05 \\\\\n",
      " 0.0279921 & 0.00805542 & 4.6094e-06  & 8.35304e-05 \\\\\n",
      " 0.0279917 & 0.00805542 & 4.854e-06   & 8.32811e-05 \\\\\n",
      " 0.0279916 & 0.00805541 & 4.97621e-06 & 8.31564e-05 \\\\\n",
      " 0.0279915 & 0.00805541 & 5.04952e-06 & 8.30816e-05 \\\\\n",
      " 0.0279914 & 0.00805541 & 5.09838e-06 & 8.30318e-05 \\\\\n",
      " 0.0279914 & 0.00805541 & 5.13328e-06 & 8.29962e-05 \\\\\n",
      " 0.0279913 & 0.00805541 & 5.15945e-06 & 8.29695e-05 \\\\\n",
      " 0.0279913 & 0.00805541 & 5.17981e-06 & 8.29487e-05 \\\\\n",
      " 0.0279913 & 0.00805541 & 5.19609e-06 & 8.29321e-05 \\\\\n",
      " 0.0279913 & 0.00805541 & 5.20941e-06 & 8.29185e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.22051e-06 & 8.29072e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.22991e-06 & 8.28976e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.23796e-06 & 8.28894e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.24494e-06 & 8.28822e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.25104e-06 & 8.2876e-05  \\\\\n",
      " 0.0279912 & 0.00805541 & 5.25643e-06 & 8.28705e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.26122e-06 & 8.28656e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.2655e-06  & 8.28613e-05 \\\\\n",
      " 0.0279912 & 0.00805541 & 5.26936e-06 & 8.28573e-05 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "[[3.4750615 ]\n",
      " [3.47493806]\n",
      " [3.47489694]\n",
      " [3.4748766 ]\n",
      " [3.4748644 ]\n",
      " [3.47485626]\n",
      " [3.47485045]\n",
      " [3.4748461 ]\n",
      " [3.47484271]\n",
      " [3.47484   ]\n",
      " [3.47483778]\n",
      " [3.47483593]\n",
      " [3.47483437]\n",
      " [3.47483303]\n",
      " [3.47483186]\n",
      " [3.47483085]\n",
      " [3.47482995]\n",
      " [3.47482915]\n",
      " [3.47482844]\n",
      " [3.4748278 ]]\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test(ar_coeff):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    n_obs = 10000\n",
    "    S = 20\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    n = 100\n",
    "    H = 50\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  # Initialize `l` outside the loop\n",
    "    while n1 < 100:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V = []\n",
    "        for a in range(0, S + 1):\n",
    "            _ , M = sir_modified(X, y[a], H, K)\n",
    "            V.append(M)\n",
    "        for q in range(1, S + 1):\n",
    "            Q = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    Q[j, k] = sum(sum(phi[j] ** a * V[a][j, k] * phi[k] ** a for a in range(0, l)) for l in range(1, q + 1))\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            n1 += 1\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = hat[i][0] / hat[i][1]\n",
    "    array = np.array(hat)\n",
    "    print(tabulate(array, tablefmt='latex'))\n",
    "    print(g)\n",
    "\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.2, 0.2, 0.2]\n",
    "test(ar_coeff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
