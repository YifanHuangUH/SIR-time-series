{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ee3cc16-c854-4087-8238-b1aeda6575b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equal number in each slice for SIR\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_triangular\n",
    "def sir_modified(X, y, num_slices, K):\n",
    "    #\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    Q, R = np.linalg.qr(X)\n",
    "    n_samples, n_features = X.shape\n",
    "    Z = np.sqrt(n_samples) * Q\n",
    "    \n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    Z_sorted = Z[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((Z_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "\n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "\n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means\n",
    "\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    \n",
    "    idx = eigenvalues.argsort()[::-1]  # Get indices that would sort eigenvalues in descending order\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    edr_est = solve_triangular(np.sqrt(n_samples) * R, eigenvectors)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    edr_est = edr_est[:, K_index]\n",
    "    # edr_est = edr_est.flatten()\n",
    "    if edr_est[0][0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    \n",
    "    return edr_est.T, V_hat, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d16951-2841-4ffd-9763-7f5f07ffe2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c834725-f806-49ec-a162-a5d6c770f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662564864720498"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir_modified test on 2*z1t + 3*z2t\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t] + 3*ar_series[1][t] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    edr, _, _ = sir_modified(X, y, H, K=K)\n",
    "    hat += edr\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035fbbb-0545-440d-8b8d-e05e56117bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e38d9dca-35ad-435d-a4fb-33f72ef753ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7506503614914589"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir_modified test on 2*z1t + 3*z2t\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1]  + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1]  + noise[3][t]\n",
    "        ar_series[4][t] = 3*ar_series[0][t] + 4*ar_series[1][t] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    \n",
    "    sir = SlicedInverseRegression(n_directions=1)\n",
    "    \n",
    "    sir.fit(X, y)\n",
    "    if sir.directions_[0][0] < 0:\n",
    "        sir.directions_ = -sir.directions_\n",
    "    hat += sir.directions_\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f83c0-716d-4274-8704-ff3f08640f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ab18736-cc3e-48ec-8828-600c355c4596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1670911494967946"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir package on 2*z1(t-1) + 3*z2(t-1): TSIR's model\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "scaler = StandardScaler() \n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff1 = 0.2\n",
    "ar_coeff2 = 0.8\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
    "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    # X = scaler.fit_transform(X) \n",
    "    \n",
    "    sir = SlicedInverseRegression(n_directions=1)\n",
    "    \n",
    "    sir.fit(X, y)\n",
    "    if sir.directions_[0][0] < 0:\n",
    "        sir.directions_ = -sir.directions_\n",
    "    hat += sir.directions_\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd600b27-968a-45bf-bf69-d2a58551c30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15629419424540117"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sir package on 2*z1(t-1) + 3*z2(t-1): TSIR's model\n",
    "import sliced\n",
    "from sliced import SlicedInverseRegression\n",
    "num_N = 5\n",
    "n_obs = 10000\n",
    "ar_coeff1 = 0.2\n",
    "ar_coeff2 = 0.8\n",
    "noise = np.zeros((num_N, n_obs))\n",
    "n = 100\n",
    "H = 50\n",
    "K = 1\n",
    "hat = 0\n",
    "Hat = 0\n",
    "for a in range(n):\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=n_obs)  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs))\n",
    "    for t in range(0, n_obs):\n",
    "        ar_series[0][t] = ar_coeff1 * ar_series[0][t - 1]  + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff2 * ar_series[1][t - 1]  + noise[1][t]\n",
    "        ar_series[2][t] = 0.3 * ar_series[2][t - 1] + 0.4 * noise[2][t-1] + noise[2][t]\n",
    "        ar_series[3][t] = -0.4 * noise[3][t-1] + noise[3][t]\n",
    "        ar_series[4][t] = 2*ar_series[0][t - 1] + 3*ar_series[1][t - 1] + noise[4][t]\n",
    "    y = ar_series[4]\n",
    "    X = np.concatenate([ar_series[i].reshape(-1,1) for i in range(4)], axis = 1)\n",
    "    \n",
    "    sir = SlicedInverseRegression(n_directions=1)\n",
    "    \n",
    "    sir.fit(X, y)\n",
    "    # if sir.directions_[0][0] < 0:\n",
    "    #     sir.directions_ = -sir.directions_\n",
    "    hat += sir.directions_\n",
    "\n",
    "hat = hat/n\n",
    "g = hat[0][0]/hat[0][1]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a09cb-d95c-42bd-b108-6d346e14d96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793eef80-462d-43a6-a62d-6ef6bd2af9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34f773d1-4f6e-4c42-afe8-b9101b5687f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 102.53175793,    1.79626685,   -0.25926656,    0.46033616],\n",
       "       [   0.        , -105.08524009,    2.34070239,    2.50607743],\n",
       "       [   0.        ,    0.        , -114.79734017,    0.97353762],\n",
       "       [   0.        ,    0.        ,    0.        ,  163.01688685]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test(ar_coeff):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    n_obs = 10000\n",
    "    S = 20\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    n = 100\n",
    "    H = 50\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1 \n",
    "    while n1 < 100:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V = []\n",
    "        R = []\n",
    "        for a in range(0, S + 1):\n",
    "            _ , M, R1 = sir_modified(X, y[a], H, K)\n",
    "            V.append(M)\n",
    "            R.append(R1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    Q[j, k] = sum(sum(phi[j] ** a * (R[a].T @ V[a] @ R[a])[j, k] * phi[k] ** a for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #QR? np.linalg.inv(R[a])\n",
    "            \n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            n1 += 1\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = hat[i][0] / hat[i][1]\n",
    "    array = np.array(hat)\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "    # print(g)\n",
    "    return R1\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "test(ar_coeff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adc81c4f-b55d-4e2f-b253-37c1cf1731be",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = test(ar_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19c66bc0-435a-4855-a0b2-cf000a47c827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 103.37009498,    0.        ,    0.        ,    0.        ],\n",
       "       [  -0.19420828,  104.546839  ,    0.        ,    0.        ],\n",
       "       [  -1.98998688,    0.6730509 , -116.50466764,    0.        ],\n",
       "       [  -3.32105343,   -2.26403529,    3.38789745, -164.89603734]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1f31434-1f64-4f01-98ee-43d6c2049788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 103.37009498,   -0.19420828,   -1.98998688,   -3.32105343],\n",
       "       [   0.        ,  104.546839  ,    0.6730509 ,   -2.26403529],\n",
       "       [   0.        ,    0.        , -116.50466764,    3.38789745],\n",
       "       [   0.        ,    0.        ,    0.        , -164.89603734]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b65038f-5d9a-46df-9fc9-7ecc0ccafacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07004037e+00, -1.41242423e-03,  2.20591371e-02,\n",
       "         5.47628551e-02],\n",
       "       [-1.41242423e-03,  1.09356204e+00, -8.60838902e-03,\n",
       "         3.73330447e-02],\n",
       "       [ 2.20591371e-02, -8.60838902e-03,  1.35848154e+00,\n",
       "        -5.58650864e-02],\n",
       "       [ 5.47628551e-02,  3.73330447e-02, -5.58650864e-02,\n",
       "         2.71907031e+00]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M @ M.T/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ac945-4bb1-465b-be3c-3c66f0e4621e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "346e6def-d3b0-40ee-8bd7-315e038b6fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.67397776e-03,  1.79705730e-05, -1.65134960e-04,\n",
       "        -1.98476227e-04],\n",
       "       [ 0.00000000e+00,  9.56509072e-03,  5.52578108e-05,\n",
       "        -1.30194124e-04],\n",
       "       [-0.00000000e+00, -0.00000000e+00, -8.58334709e-03,\n",
       "        -1.76350506e-04],\n",
       "       [-0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -6.06442711e-03]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
