{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9202e598-ba91-40e9-be49-b95075098898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = (X_means - np.mean(X, axis=0))\n",
    "    # X_centered = (X_means - np.mean(X, axis=0))/np.linalg.norm(X_means - np.mean(X, axis=0))\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5dde3d71-cbac-4093-8d94-99a8bd6fbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "\n",
    "def ave(arr, N):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i]/N \n",
    "    return arr \n",
    "def compute_eigen(Q4, P, K):\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(Q4)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues2), P - K) >= P - K\n",
    "    K_largest_eigenvectors = eigenvectors2[:, K_index]\n",
    "    edr_est = K_largest_eigenvectors  \n",
    "    if edr_est[0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    return edr_est    \n",
    "def proj(edr_est): \n",
    "    E = edr_est @ np.linalg.inv(edr_est.T @ edr_est) @ edr_est.T\n",
    "    return E\n",
    "def exhi(obj1):        \n",
    "    array1 = np.vectorize(lambda x: f\"{x:.6f}\")(obj1)\n",
    "    table = tabulate(array1, tablefmt='latex_raw')\n",
    "    lines = table.split('\\n')\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    print(latex_table)    \n",
    "\n",
    "def MSE(X, y):\n",
    "    Mse = 0\n",
    "    # Split using time series cross-validation (e.g., 5 splits)\n",
    "    train_window = int(np.round(0.75 * len(X),0))  # Fixed size of training set (e.g., 75 time steps)\n",
    "    test_window = 1   # Fixed size of test set (e.g., 25 time steps)\n",
    "    # Sliding window cross-validation\n",
    "    for i in range(0, len(X) - train_window - test_window + 1):\n",
    "        X_train = X[i:i + train_window]\n",
    "        y_train = y[i:i + train_window]\n",
    "        X_test = X[i + train_window:i + train_window + test_window]\n",
    "        y_test = y[i + train_window:i + train_window + test_window]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate errors\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        Mse += mse \n",
    "    Mse = Mse/(len(X) - train_window - test_window)\n",
    "    return np.sqrt(Mse)\n",
    "    \n",
    "def optimal_values(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    return smallest   \n",
    "def optimal_Q(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == smallest:\n",
    "            return i # Return the first matched index\n",
    "    return -1\n",
    "def plotyy(x, li1, li2, li3,label1 ,label2 ,label3, title, xlabel, ylabel):\n",
    "    # plt.plot(x, obj1_optimal_values, label= label_variable, color='blue', marker='o')\n",
    "    plt.plot(x, li1, label = label1, color='blue', marker='o')\n",
    "    plt.plot(x, li2, label = label2, color='red', marker='^')\n",
    "    plt.plot(x, li3, label = label3, color='black', marker='s')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep):\n",
    "    num_N = 5;P = 4;K = 1;l = 1 \n",
    "    noise1 = np.zeros((num_N, n_gene))\n",
    "    noise2 = np.zeros((num_N, n_obs+10*n_rep+S))\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S)]\n",
    "    X1 = [[np.zeros((num_N, n_obs)) for i in range(P)] for i in range(S)]\n",
    "    obj_1 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    obj_2 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    M = [np.zeros((P, 1)) for _ in range(S)] \n",
    "    proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "    proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "    error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "    error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    g1 = np.zeros((S, 1))\n",
    "    g2 = np.zeros((S, 1))\n",
    "    projection_1_norm = np.zeros((S, 1))\n",
    "    projection_2_norm = np.zeros((S, 1))\n",
    "    True_projection = np.array([[2],[3],[0],[0]])/((np.linalg.norm(np.array([[2],[3],[0],[0]]))))\n",
    "    obj_2_avevec = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    obj2_ave = np.zeros((P, 1))\n",
    "    Exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    Exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    error_11 = 0\n",
    "    prediction_mse_11 = 0\n",
    "    proj_error_11 = 0\n",
    "    n = 0\n",
    "    \n",
    "    for h in range(num_N):\n",
    "        noise1[h] = np.random.normal(0, sigma, size=(n_gene)) \n",
    "        noise2[h] = np.random.normal(0, sigma, size=(n_obs+10*n_rep+S))\n",
    "    ar_series = np.zeros((num_N, n_obs+10*n_rep+S+1))\n",
    "    for i in range(num_N):\n",
    "        ar_series[i][0] = initial_value  \n",
    "    AR1 = initial_value\n",
    "    AR2 = initial_value\n",
    "    AR3 = initial_value\n",
    "    AR4 = initial_value\n",
    "    for t in range(1, n_gene + 1):\n",
    "        AR1 = ar_coeff[0] * AR1 + noise1[0][t-1]\n",
    "        AR2 = ar_coeff[1] * AR2 + noise1[1][t-1]\n",
    "        AR3 = ar_coeff[2] * AR3 + noise1[2][t-1]\n",
    "        AR4 = ar_coeff[3] * AR4 + noise1[3][t-1]\n",
    "    ar_series[0][0] = AR1 \n",
    "    ar_series[1][0] = AR2 \n",
    "    ar_series[2][0] = AR3 \n",
    "    ar_series[3][0] = AR4 \n",
    "    \n",
    "    while n < n_rep:  \n",
    "        # pause every 10 time points and compute (number of samples = n_obs) time points\n",
    "        for t in range(10*n, n_obs+10*n+S+1): \n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise2[0][t - 1]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise2[1][t - 1]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise2[2][t - 1]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise2[3][t - 1]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise2[4][t - 1]\n",
    "        df = pd.DataFrame(ar_series)\n",
    "        df.to_excel(fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\datafile_1\\array_data_replicas_{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx', index=False, header=False)\n",
    "        # np.savetxt(fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\datafile\\array_data_replicas_{n1}_AR1_{ar_coeff}.txt', ar_series)\n",
    "        n += 1\n",
    "        \n",
    "def Calculation(ar_series_xlsx, ar_coeff, H, S, n):\n",
    "    num_N = 5;P = 4;K = 1;l = 1 \n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S)]\n",
    "    X1 = [[np.zeros((num_N, n_obs)) for i in range(P)] for i in range(S)]\n",
    "    obj_1 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    obj_2 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    M = [np.zeros((P, 1)) for _ in range(S)] \n",
    "    proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "    proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "    error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "    error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    g1 = np.zeros((S, 1))\n",
    "    g2 = np.zeros((S, 1))\n",
    "    projection_1_norm = np.zeros((S, 1))\n",
    "    projection_2_norm = np.zeros((S, 1))\n",
    "    True_projection = np.array([[2],[3],[0],[0]])/((np.linalg.norm(np.array([[2],[3],[0],[0]]))))\n",
    "    obj_2_avevec = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    obj2_ave = np.zeros((P, 1))\n",
    "    Exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    Exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    error_11 = 0\n",
    "    prediction_mse_11 = 0\n",
    "    proj_error_11 = 0\n",
    "    \n",
    "    df = pd.read_excel(ar_series_xlsx, header=None)\n",
    "    ar_series = df.to_numpy()\n",
    "    \n",
    "    for a in range(0, S):\n",
    "        y[a] = ar_series[4][a:n_obs+a]\n",
    "        X1[a] = np.concatenate([ar_series[i][a:n_obs+a].reshape(-1, 1) for i in range(P)], axis = 1)\n",
    "    X = X1[0]\n",
    "    edr_est1, M1 = sir_11(X, y[0], H, K)\n",
    "    edr_est1 = compute_eigen(np.linalg.inv(np.cov(X.T)) @ M1 @ np.linalg.inv(np.cov(X.T)), P, K)\n",
    "    if edr_est1[0] < 0:\n",
    "        edr_est1 = -edr_est1\n",
    "    edr_est1 = np.real(edr_est1 / np.linalg.norm(edr_est1))\n",
    "    error_11 += abs(edr_est1[0] / edr_est1[1] - a1/a2)\n",
    "    prediction_mse_11 += MSE(X @ edr_est1, y[0]) \n",
    "    proj_error_11 += np.linalg.norm((proj(edr_est1) - proj(True_projection)), 'fro')**2\n",
    "    V1 = []\n",
    "    for a in range(0, S):\n",
    "        _, M = sir_11(X, y[a], H, K)\n",
    "        V1.append(M)\n",
    "    # objective 1: experiment\n",
    "    for q in range(0, S):\n",
    "        phi = ar_coeff\n",
    "        Q3 = np.zeros((P, P))\n",
    "        for j in range(P):\n",
    "            for k in range(P):\n",
    "                Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(np.cov(X.T)) @ V1[a] @ np.linalg.inv(np.cov(X.T)))[j, k] * (phi[k] ** a) for a in range(0, q + 1))\n",
    "        edr_est = compute_eigen(Q3, P, K)\n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        error_1[q] += abs(edr_est[0] / edr_est[1] - a1/a2)\n",
    "        prediction_mse_1[q] += MSE(X @ edr_est, y[0]) \n",
    "        proj_error_1[q] += np.linalg.norm((proj(edr_est) - proj(True_projection)), 'fro')**2      \n",
    "    # objective 2: experiment\n",
    "    for q in range(0, S):\n",
    "        Q4 = np.linalg.inv(np.cov(X1[q].T)) @ V1[q] @ np.linalg.inv(np.cov(X1[q].T))   # multiply np.linalg.inv(np.cov(X1[q].T)), by stationarity, it should cause no influence.\n",
    "        # Q3 = np.linalg.inv(np.cov(X.T)) @ V1[q] @ np.linalg.inv(np.cov(X.T)), if we multiply np.linalg.inv(np.cov(X.T)) like this line, result for q = 0 should be the same.   \n",
    "        K_largest_eigenvectors = compute_eigen(Q4, P, K)\n",
    "        edr_est = np.multiply(np.power(ar_coeff, -q), K_largest_eigenvectors.flatten())   \n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        obj_2[q] += edr_est.reshape(-1, 1)       \n",
    "    # Average among lags Q\n",
    "    for j in range(S):\n",
    "        for i in range(j, S, 1):\n",
    "            obj_2_avevec[i] += obj_2[j]\n",
    "    for j in range(S):\n",
    "        obj_2_avevec[j] = ave(obj_2_avevec[j], j + 1)\n",
    "    for q in range(0, S):\n",
    "        error_2[q] += abs(obj_2_avevec[q][0] / obj_2_avevec[q][1] - a1/a2)\n",
    "        prediction_mse_2[q] += MSE(X @ obj_2_avevec[q], y[0])\n",
    "        proj_error_2[q] += np.linalg.norm((proj(obj_2_avevec[q]) - proj(True_projection)), 'fro')**2    \n",
    "    return error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2\n",
    "    \n",
    "def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "    num_N = 5;P = 4;K = 1;l = 1\n",
    "    Exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    Exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    error_1 = ave(error_1, n_rep)    \n",
    "    error_2 = ave(error_2, n_rep)\n",
    "    prediction_mse_1 = ave(prediction_mse_1, n_rep)\n",
    "    prediction_mse_2 = ave(prediction_mse_2, n_rep)\n",
    "    proj_error_1 = ave(proj_error_1, n_rep)\n",
    "    proj_error_2 = ave(proj_error_2, n_rep)\n",
    "    index_array = list(range(S))\n",
    "    SIR_values = [error_1[0], prediction_mse_1[0], proj_error_1[0]]\n",
    "    Obj1_optimal_values = [optimal_values(error_1), optimal_values(prediction_mse_1), optimal_values(proj_error_1)]\n",
    "    Obj2_optimal_values = [optimal_values(error_2), optimal_values(prediction_mse_2), optimal_values(proj_error_2)]\n",
    "    Obj1_optimal_Q = [optimal_Q(error_1),optimal_Q(prediction_mse_1),optimal_Q(proj_error_1)]\n",
    "    Obj2_optimal_Q = [optimal_Q(error_2),optimal_Q(prediction_mse_2),optimal_Q(proj_error_2)]\n",
    "    # for i in range(S):\n",
    "    #     exhi_1[i] = error_1[i]\n",
    "    #     exhi_1[i] = np.vstack((exhi_1[i], proj_error_1[i]))\n",
    "    #     exhi_1[i] = np.vstack((exhi_1[i], prediction_mse_1[i]))\n",
    "    #     exhi_1[i] = np.vstack((np.array([[index_array[i]]]), exhi_1[i]))\n",
    "    # for i in range(S):\n",
    "    #     exhi_2[i] = error_2[i]\n",
    "    #     exhi_2[i] = np.vstack((exhi_2[i], proj_error_2[i]))\n",
    "    #     exhi_2[i] = np.vstack((exhi_2[i], prediction_mse_2[i]))\n",
    "    #     exhi_2[i] = np.vstack((np.array([[index_array[i]]]), exhi_2[i]))\n",
    "    return SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q\n",
    "\n",
    "def Graph(n, H, S, n_rep):\n",
    "    sir_values = [[], [], []]\n",
    "    obj1_optimal_values = [[], [], []]\n",
    "    obj2_optimal_values = [[], [], []]\n",
    "    obj1_optimal_Q = [[],[],[]]\n",
    "    obj2_optimal_Q = [[],[],[]]\n",
    "    for i in np.arange(0.1, 1.0, 0.1):\n",
    "        ar_coeff = [i,0.5,0.2,0.2]\n",
    "        filepath = fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\datafile_1\\array_data_replicas_{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx'\n",
    "        error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 = Calculation(filepath, ar_coeff, H, S, n)\n",
    "        SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q = Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep)\n",
    "        for j in range(3):\n",
    "            sir_values[j].append(SIR_values[j])\n",
    "            obj1_optimal_values[j].append(Obj1_optimal_values[j])\n",
    "            obj2_optimal_values[j].append(Obj2_optimal_values[j])\n",
    "            obj1_optimal_Q[j].append(Obj1_optimal_Q[j])\n",
    "            obj2_optimal_Q[j].append(Obj2_optimal_Q[j])\n",
    "            if j == 1:\n",
    "                sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "            if j == 2:\n",
    "                sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "    for j in range(3):\n",
    "        if j ==0:\n",
    "            plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j],'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Absolute error')\n",
    "            plt.savefig(fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\figurefile_1\\plot_round{n}_arcoeff{\"_\".join(map(str, [0.5,0.2,0.2]))}_Optimal_Absolute_Error.png', format='png')\n",
    "            plt.close()\n",
    "        if j ==1:\n",
    "            plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j], 'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Mse')\n",
    "            plt.savefig(fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\figurefile_1\\_plot_round{n}_arcoeff{\"_\".join(map(str, [0.5,0.2,0.2]))}_Optimal_MSE.png', format='png')\n",
    "            plt.close()\n",
    "        if j ==2:\n",
    "            plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j], 'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Risk')\n",
    "            plt.savefig(fr'C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\Scripts\\SIR_experiment\\figurefile_1\\_plot_round{n}_arcoeff{\"_\".join(map(str, [0.5,0.2,0.2]))}_Optimal_Risk.png', format='png')\n",
    "            plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdd18dce-f82d-450e-972b-e381d66ee76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = []\n",
    "# for i in np.arange(0.1, 1.0, 0.1):\n",
    "#     arr.append([i,0.5,0.2,0.2])\n",
    "# for index in range(len(arr)):\n",
    "#     arr[index] = [round(val, 1) for val in arr[index]]\n",
    "# a1=2; a2=3; initial_value = 0; n_gene = 10000; n_obs = 1000; H = 5; S=10; sigma = 5; n_rep = 2\n",
    "# for n in range(n_rep):\n",
    "#     for ar_coeff in arr:\n",
    "#         Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep)\n",
    "#     # def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, n_rep):\n",
    "#     # def Calculation(ar_series_xlsx, H, S, n):\n",
    "#     # def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "#     # def Graph(ar_series_xlsx, SIR_values, obj1_optimal_values, obj2_optimal_values, obj1_optimal_Q, obj2_optimal_Q):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d39a9d1-a140-4483-bfe7-f376078ab848",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=2; a2=3; initial_value = 0; n_gene = 10000; n_obs = 1000; H = 5; S=10; sigma = 5; n_rep = 2\n",
    "for n in range(n_rep):\n",
    "    Graph(n, H, S, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b01f8-b39e-4cba-aa74-e24b8684ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86c587-c4d7-4290-8d06-c2bb2938be8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd245ab5-3ad6-4b01-90cd-35cfa3384516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a121b-605a-4379-a9e5-da620da44ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bbc9f-b9a5-4cd5-a2c4-5c77efa76f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0528d66-c437-4b60-94dd-f06517eac80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910e7ee-33dc-48c0-a878-1533066fcf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade7812-d92c-4601-8380-9b3015aebee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f118e-2fca-4acb-a468-2a5049c40979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7362e-05a6-4c2c-afc7-df8138d4bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
