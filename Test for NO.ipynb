{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829f92a0-f0d8-4ed6-b68b-6c0f4df1f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#equal number in each slice for SIR\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_triangular\n",
    "def sir_modified1(X, y, num_slices, K):\n",
    "    X1 = X - np.mean(X, axis=0)\n",
    "    #reduced QR decomposition\n",
    "    Q, R = np.linalg.qr(X1)\n",
    "    n_samples, n_features = X.shape\n",
    "    Z = np.sqrt(n_samples) * Q\n",
    "    \n",
    "    V_hat1 = np.zeros([X.shape[1], X.shape[1]])\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    Z_sorted = Z[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    X_sorted = X[sorted_indices]\n",
    "    # X_sorted = X1[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    slices1 = []\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((Z_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    for j in range(num_slices):\n",
    "        start_idx1 = j * slice_size\n",
    "        if j < num_slices - 1:\n",
    "            end_idx1 = (j + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx1 = n_samples\n",
    "        slices1.append((X_sorted[start_idx1:end_idx1], y_sorted[start_idx1:end_idx1]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    Z_means = np.array([np.mean(slice_Z, axis=0) for slice_Z, _ in slices])\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices1])\n",
    "    # Step 4: Center the predictor means\n",
    "    Z_centered = Z_means - np.mean(Z_means, axis=0)\n",
    "    X_centered = X_means - np.mean(X_means, axis=0)\n",
    "    \n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(Z_centered.T, Z_centered))\n",
    "    V_hat1 = np.add(V_hat1,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    \n",
    "    idx = eigenvalues.argsort()[::-1]  # Get indices that would sort eigenvalues in descending order\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    edr_est = solve_triangular(R, eigenvectors)\n",
    "    # edr_est = solve_triangular(np.sqrt(n_samples) * R, eigenvectors)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    edr_est = edr_est[:, K_index]\n",
    "    # edr_est = edr_est.flatten()\n",
    "    if edr_est[0][0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    return edr_est.T, V_hat1, V_hat, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8938141-e232-483c-8f32-25099bf5d847",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# With whitening for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4653ab0-de26-47cf-bb1c-3f911e09bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = np.linalg.inv(np.cov(X)) @ (X - np.mean(X, axis = 0))\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "        \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    # Step 4: Center the predictor means\n",
    "    # X_centered = X_means - np.mean(X, axis=0)\n",
    "    X_centered = (X_means - np.mean(X_means, axis=0)) - np.mean(X, axis=0)\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e171c7-4a19-4b0e-a1c8-10ab824ec56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb67027-0ece-4e87-b9d2-c7d9796e5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.533996 & 0.845069 & -0.000320675 & -5.29097e-05 & 0.0347705 \\\\ \\hline\n",
      " 1 & 0.53244  & 0.846015 & -0.000347259 & -8.24337e-06 & 0.0373165 \\\\ \\hline\n",
      " 2 & 0.532407 & 0.846031 & -0.00035203  & -1.54633e-05 & 0.0373667 \\\\ \\hline\n",
      " 3 & 0.532404 & 0.84603  & -0.000351838 & -1.56404e-05 & 0.0373694 \\\\ \\hline\n",
      " 4 & 0.532404 & 0.846029 & -0.000351769 & -1.48809e-05 & 0.0373696 \\\\ \\hline\n",
      " 5 & 0.532403 & 0.846029 & -0.000351811 & -1.42437e-05 & 0.0373697 \\\\ \\hline\n",
      " 6 & 0.532403 & 0.846028 & -0.000351814 & -1.42899e-05 & 0.0373697 \\\\ \\hline\n",
      " 7 & 0.532403 & 0.846028 & -0.000351815 & -1.44554e-05 & 0.0373697 \\\\ \\hline\n",
      " 8 & 0.532403 & 0.846028 & -0.000351815 & -1.44587e-05 & 0.0373697 \\\\ \\hline\n",
      " 9 & 0.532403 & 0.846028 & -0.000351816 & -1.44645e-05 & 0.0373697 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.03477050583893748\n",
      "[ 5.33995813e-01  8.45068930e-01 -3.20674659e-04 -5.29097416e-05]\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        # X = X -np.mean(X, axis = 0)\n",
    "        # covariance_matrix = np.cov(X, rowvar=False)\n",
    "        # eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    #     eigenvectors = np.real(eigenvectors)\n",
    "    # # Construct the transformation matrix with eigenvalues adjusted\n",
    "    #     transform_matrix = eigenvectors @ np.diag(1 / np.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "    # # Apply the transformation to X\n",
    "    #     X_transformed = X @ transform_matrix\n",
    "        # _, V_hat = sir_11(X, y[0], H, K)\n",
    "        # A = np.power(V_hat, -1/2)\n",
    "        # X = X @ (V_hat)**(-1/2)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_11(X, y[a], H, K)\n",
    "            # edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            edr[a] = edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                # EDR += np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "            # Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (V1[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            \n",
    "            ## For Q>0, I don't know if it's appopriate to multiply np.linalg.inv(np.cov(X.T)) to transform back.\n",
    "            # edr_est = np.linalg.inv(np.cov(X.T)) @ K_largest_eigenvectors\n",
    "            # edr_est = np.linalg.inv(V1[0]) @ K_largest_eigenvectors\n",
    "            edr_est = K_largest_eigenvectors \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            # hat[q - 1] += edr_est\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test(ar_coeff, 2, 3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b29845c4-9d15-4fa4-bc43-3fc0f33564b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.271226  & 0.376368  & 0.0189957  & 0.0462102 & 0.0539737 \\\\ \\hline\n",
      " 1 & 0.124987  & 0.146142  & 0.00127151 & 0.0914678 & 0.188581  \\\\ \\hline\n",
      " 2 & 0.0848913 & 0.0802231 & 0.00602097 & 0.0633546 & 0.391523  \\\\ \\hline\n",
      " 3 & 0.0700162 & 0.0637908 & 0.00691467 & 0.0399233 & 0.430924  \\\\ \\hline\n",
      " 4 & 0.0617555 & 0.0537751 & 0.00582309 & 0.0373718 & 0.481737  \\\\ \\hline\n",
      " 5 & 0.0572372 & 0.0485935 & 0.00512652 & 0.0370178 & 0.511211  \\\\ \\hline\n",
      " 6 & 0.0547724 & 0.0458259 & 0.0048593  & 0.0370341 & 0.528562  \\\\ \\hline\n",
      " 7 & 0.0532974 & 0.0442334 & 0.00466845 & 0.0371053 & 0.538245  \\\\ \\hline\n",
      " 8 & 0.0524323 & 0.0433275 & 0.00454858 & 0.0371775 & 0.543472  \\\\ \\hline\n",
      " 9 & 0.0518909 & 0.0427873 & 0.00444713 & 0.0372337 & 0.546098  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.053973701319496414\n",
      "[0.27122589 0.37636788 0.01899574 0.04621019]\n"
     ]
    }
   ],
   "source": [
    "Test(ar_coeff, 2, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4f89-0b60-4db3-8547-0cd312b27739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe54c2d-9aec-4eda-a224-9cc894d95163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ccbfe0-8e39-4ad4-962c-283420da9a99",
   "metadata": {},
   "source": [
    "# Without whitening: multiplying uniform $\\Sigma_{xx}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dad9beef-2b86-4672-9820-90d7f46efeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means - np.mean(X, axis=0)\n",
    "    \n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d84df185-09d0-4f57-94a9-0cfcdbdf9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test(ar_coeff, S, a1, a2, n_obs):   #S, n_rep\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    # S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1 \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        # X = X -np.mean(X, axis = 0)\n",
    "        # covariance_matrix = np.cov(X, rowvar=False)\n",
    "        # eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    #     eigenvectors = np.real(eigenvectors)\n",
    "    # # Construct the transformation matrix with eigenvalues adjusted\n",
    "    #     transform_matrix = eigenvectors @ np.diag(1 / np.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "    \n",
    "    # # Apply the transformation to X\n",
    "    #     X_transformed = X @ transform_matrix\n",
    "        # _, V_hat = sir_11(X, y[0], H, K)\n",
    "        # A = np.power(V_hat, -1/2)\n",
    "        # X = X @ (V_hat)**(-1/2)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_11(X, y[a], H, K)\n",
    "            edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            # edr[a] = np.power(np.linalg.inv(np.cov(X.T)), 1/2) @ edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                # EDR += np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "            # Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (V1[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            ## For Q>0, I don't know if it's appopriate to multiply np.linalg.inv(np.cov(X.T)) to transform back.\n",
    "\n",
    "            edr_est = np.linalg.inv(np.cov(X.T)) @ K_largest_eigenvectors\n",
    "            \n",
    "            # edr_est = np.linalg.inv(V1[0]) @ K_largest_eigenvectors\n",
    "            # edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            # hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    # array = np.array(hat)\n",
    "    array = np.vectorize(lambda x: f\"{x:.4f}\")(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    # print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # print(L)\n",
    "    # print(EDR[0])\n",
    "    return g\n",
    "    \n",
    "def EXperi(ar_coeff, S, n_samples, n_end, n_interval):\n",
    "    # S = 10\n",
    "    V = []\n",
    "    # ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "    nn = n_samples\n",
    "    \n",
    "    g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    for i in range(S):\n",
    "        g[i] = Test(ar_coeff, S, 2, 3, nn)[i]\n",
    "    \n",
    "    for n in range(nn, n_end, n_interval):\n",
    "        h = Test(ar_coeff, S, 2, 3, nn)\n",
    "        for i in range(S):\n",
    "            g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "    index_array = list(range(len(g)))\n",
    "    for i in range(S):\n",
    "        g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))          \n",
    "    for j in range(1, len(g[1])):    \n",
    "        sorted_indices = np.argsort([g[i][j] for i in range(S)], axis = 0)\n",
    "        min_sorted_indices = sorted_indices[0][0]\n",
    "        V.append(min_sorted_indices)\n",
    "            \n",
    "    g = np.concatenate((g, [np.array([[0] + V]).T]), axis = 0)\n",
    "    \n",
    "    # g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    # for i in range(S):\n",
    "    #     g[i] = Test(ar_coeff, S, 2, 3, nn)[i]\n",
    "    # index_array = list(range(len(g)))\n",
    "    # for i in range(S):\n",
    "    #     g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))\n",
    "    # for n in range(nn, nn+n_end, n_interval):\n",
    "    #     h = Test(ar_coeff, S, 2, 3, nn)\n",
    "    #     for i in range(S):\n",
    "    #         g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "\n",
    "            \n",
    "            # g[i] = np.hstack((g[i], [np.max(np.argsort([g[i][j] for i in range(S)])) for j in range(len(g[1]))] ))\n",
    "            \n",
    "    formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "    # array = np.array(g)\n",
    "    table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "# formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "# # array = np.array(g)\n",
    "# table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "\n",
    "# # Split the table into lines\n",
    "# lines = table.split('\\n')\n",
    "\n",
    "# # Insert \\hline after each row\n",
    "# latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "44d3e4a1-f3ae-462a-82fe-073f444e7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "# ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "nn = 10\n",
    "\n",
    "g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "for i in range(S):\n",
    "    g[i] = Test(ar_coeff, S, 2, 3, nn)[i]\n",
    "\n",
    "for n in range(nn, nn+10, 2):\n",
    "    h = Test(ar_coeff, S, 2, 3, nn)\n",
    "    for i in range(S):\n",
    "        g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "index_array = list(range(len(g)))\n",
    "for i in range(S):\n",
    "    g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))          \n",
    "for j in range(1, len(g[1])):    \n",
    "    sorted_indices = np.argsort([g[i][j] for i in range(S)], axis = 0)\n",
    "    min_sorted_indices = sorted_indices[0][0]\n",
    "    V.append(min_sorted_indices)\n",
    "        \n",
    "g = np.concatenate((g, [np.array([[0] + V]).T]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eef0ae98-7611-4621-a7a7-437ec8e6f972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.59624592]),\n",
       " array([0.48616811]),\n",
       " array([1.18246793]),\n",
       " array([2.90494606]),\n",
       " array([2.9751451]),\n",
       " array([3.15473019]),\n",
       " array([4.24782505]),\n",
       " array([3.91007996]),\n",
       " array([3.98200932]),\n",
       " array([4.03918018])]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[g[i][2] for i in range(S)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "0f5d99cf-8e34-43be-ba71-c63913ce48e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0df97-27cb-4df9-8300-43dd645a1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EXperi(ar_coeff, S, n_samples, n_end, n_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c682207b-519b-49ea-b7c5-250405216c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrr}\n",
      "\\hline\n",
      "  0 &  0.0177 & 0.0021 &  0.0141 & 0.0035 & 0.0119 & 0.0163 \\\\ \\hline\n",
      "  1 &  0.0106 & 0.0016 &  0.0104 & 0.0017 & 0.0175 & 0.0175 \\\\ \\hline\n",
      "  2 &  0.0082 & 0.008  &  0.0078 & 0.0007 & 0.0213 & 0.0186 \\\\ \\hline\n",
      "  3 &  0.0119 & 0.0123 &  0.0072 & 0.0021 & 0.0231 & 0.0203 \\\\ \\hline\n",
      "  4 &  0.0007 & 0.0059 &  0.0071 & 0.0034 & 0.0246 & 0.0209 \\\\ \\hline\n",
      "  5 &  0.0114 & 0.0063 &  0.0069 & 0.0207 & 0.0278 & 0.0214 \\\\ \\hline\n",
      "  6 &  0.0259 & 0.0081 &  0.0063 & 0.0243 & 0.0278 & 0.0217 \\\\ \\hline\n",
      "  7 &  0.0246 & 0.01   &  0.0062 & 0.0249 & 0.0277 & 0.0218 \\\\ \\hline\n",
      "  8 &  0.0073 & 0.0001 &  0.0061 & 0.025  & 0.0276 & 0.0219 \\\\ \\hline\n",
      "  9 &  0.0171 & 0.0001 &  0.0061 & 0.0248 & 0.0276 & 0.0219 \\\\ \\hline\n",
      " 10 &  0.005  & 0.0002 &  0.0061 & 0.0248 & 0.0275 & 0.022  \\\\ \\hline\n",
      " 11 &  0.0152 & 0.0002 &  0.0061 & 0.0248 & 0.0274 & 0.022  \\\\ \\hline\n",
      " 12 &  0.0099 & 0.0003 &  0.0061 & 0.0248 & 0.0274 & 0.022  \\\\ \\hline\n",
      " 13 &  0.0001 & 0.0003 &  0.0061 & 0.0248 & 0.0274 & 0.022  \\\\ \\hline\n",
      " 14 &  0.0311 & 0.0003 &  0.0061 & 0.0248 & 0.0274 & 0.0221 \\\\ \\hline\n",
      " 15 &  0.0006 & 0.0003 &  0.0061 & 0.0248 & 0.0274 & 0.0221 \\\\ \\hline\n",
      " 16 &  0.007  & 0.0003 &  0.0061 & 0.0248 & 0.0273 & 0.0221 \\\\ \\hline\n",
      " 17 &  0.001  & 0.0003 &  0.0061 & 0.0248 & 0.0273 & 0.0221 \\\\ \\hline\n",
      " 18 &  0.0067 & 0.0003 &  0.0061 & 0.0248 & 0.0273 & 0.0221 \\\\ \\hline\n",
      " 19 &  0.004  & 0.0003 &  0.0061 & 0.0248 & 0.0273 & 0.0221 \\\\ \\hline\n",
      "  0 & 13      & 8      & 13      & 2      & 0      & 0      \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.1, 0.1, 0.5, 0.8]\n",
    "EXperi(ar_coeff, 20, 50, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "037deae9-393a-492f-97a4-53ac1ea23432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.0027 & 0.0085 & 0.0027 & 0.0034 & 0.0096 & 0.0136 \\\\ \\hline\n",
      " 1 & 0.0161 & 0.0072 & 0.0042 & 0.0012 & 0.0069 & 0.0151 \\\\ \\hline\n",
      " 2 & 0.019  & 0.0066 & 0.0087 & 0.0001 & 0.0044 & 0.0152 \\\\ \\hline\n",
      " 3 & 0.0216 & 0.0086 & 0.01   & 0.0006 & 0.0036 & 0.0164 \\\\ \\hline\n",
      " 4 & 0.0234 & 0.0013 & 0.0106 & 0.0048 & 0.0035 & 0.0176 \\\\ \\hline\n",
      " 5 & 0.013  & 0.0014 & 0.0105 & 0.0051 & 0.0032 & 0.0182 \\\\ \\hline\n",
      " 6 & 0.0121 & 0.0013 & 0.0103 & 0.0051 & 0.0033 & 0.0186 \\\\ \\hline\n",
      " 7 & 0.003  & 0.0013 & 0.0103 & 0.0051 & 0.0033 & 0.0189 \\\\ \\hline\n",
      " 8 & 0.0158 & 0.0013 & 0.0103 & 0.005  & 0.0032 & 0.019  \\\\ \\hline\n",
      " 9 & 0.0135 & 0.0012 & 0.0103 & 0.005  & 0.0032 & 0.0191 \\\\ \\hline\n",
      " 0 & 0      & 8      & 0      & 3      & 9      & 0      \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.1, 0.1, 0.5, 0.8]\n",
    "EXperi(ar_coeff, 10, 50, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "df77cfed-120c-4735-8bf9-9ee9c74bc6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.005  & 0.0036 & 0.004  & 0.0057 & 0.0022 & 0.0023 & 0.0032 \\\\ \\hline\n",
      " 1 & 0.0291 & 0.029  & 0.0284 & 0.0383 & 0.0344 & 0.0304 & 0.0361 \\\\ \\hline\n",
      " 2 & 0.0364 & 0.0315 & 0.0309 & 0.0406 & 0.0367 & 0.0327 & 0.0386 \\\\ \\hline\n",
      " 3 & 0.0374 & 0.0317 & 0.0312 & 0.0408 & 0.037  & 0.0329 & 0.0389 \\\\ \\hline\n",
      " 4 & 0.0403 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      " 5 & 0.0361 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      " 6 & 0.0392 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      " 7 & 0.0348 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      " 8 & 0.0359 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      " 9 & 0.0396 & 0.0318 & 0.0312 & 0.0409 & 0.037  & 0.033  & 0.0389 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.1, 0.5, 0.5, 0.8]\n",
    "EXperi(ar_coeff, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5ace0ec-49d9-436a-bb65-e390c0c1b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.0236 & 0.0192 & 0.0089 & 0.0109 & 0.0067 & 0.0087 & 0.0184 \\\\ \\hline\n",
      " 1 & 0.0037 & 0.0138 & 0.0122 & 0.0188 & 0.0008 & 0.0114 & 0.0253 \\\\ \\hline\n",
      " 2 & 0.0193 & 0.0139 & 0.0064 & 0.0342 & 0.0312 & 0.0113 & 0.0256 \\\\ \\hline\n",
      " 3 & 0.0229 & 0.0138 & 0.0031 & 0.0427 & 0.0443 & 0.0278 & 0.0195 \\\\ \\hline\n",
      " 4 & 0.0216 & 0.0129 & 0.0083 & 0.0449 & 0.0488 & 0.046  & 0.0191 \\\\ \\hline\n",
      " 5 & 0.0209 & 0.0128 & 0.0086 & 0.0461 & 0.0519 & 0.0504 & 0.0188 \\\\ \\hline\n",
      " 6 & 0.0525 & 0.023  & 0.0085 & 0.0467 & 0.0541 & 0.0519 & 0.0184 \\\\ \\hline\n",
      " 7 & 0.0002 & 0.0222 & 0.0085 & 0.0592 & 0.0556 & 0.053  & 0.0037 \\\\ \\hline\n",
      " 8 & 0.0108 & 0.0218 & 0.0083 & 0.0592 & 0.0567 & 0.0542 & 0.003  \\\\ \\hline\n",
      " 9 & 0.0394 & 0.0213 & 0.0083 & 0.0594 & 0.0572 & 0.0559 & 0.0026 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.1, 0.2, 0.8, 0.8]\n",
    "EXperi(ar_coeff, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bffda863-0c31-4421-bca4-62b581974573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.0225 & 0.0233 & 0.003  & 0.0251 & 0.0173 & 0.0009 & 0.0194 \\\\ \\hline\n",
      " 1 & 0.1029 & 0.0965 & 0.0766 & 0.107  & 0.076  & 0.0904 & 0.0967 \\\\ \\hline\n",
      " 2 & 0.1185 & 0.1119 & 0.0945 & 0.1226 & 0.081  & 0.1038 & 0.1068 \\\\ \\hline\n",
      " 3 & 0.1156 & 0.1158 & 0.1007 & 0.1188 & 0.0814 & 0.1055 & 0.1082 \\\\ \\hline\n",
      " 4 & 0.1287 & 0.1157 & 0.0976 & 0.1192 & 0.0813 & 0.1055 & 0.1105 \\\\ \\hline\n",
      " 5 & 0.0948 & 0.1157 & 0.0984 & 0.1189 & 0.0807 & 0.1055 & 0.1109 \\\\ \\hline\n",
      " 6 & 0.1011 & 0.1158 & 0.0988 & 0.1184 & 0.0807 & 0.1052 & 0.1107 \\\\ \\hline\n",
      " 7 & 0.1254 & 0.1159 & 0.099  & 0.1062 & 0.0798 & 0.1049 & 0.1105 \\\\ \\hline\n",
      " 8 & 0.1364 & 0.1055 & 0.099  & 0.106  & 0.0793 & 0.1044 & 0.1102 \\\\ \\hline\n",
      " 9 & 0.1099 & 0.1053 & 0.099  & 0.1057 & 0.0791 & 0.1042 & 0.1102 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.1, 0.6, 0.8, 0.8]\n",
    "EXperi(ar_coeff, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a2511418-4dbf-4e61-8f92-862418797576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.026  & 0.0261 & 0.0442 & 0.0219 & 0.0087 & 0.0277 & 0.0389 \\\\ \\hline\n",
      " 1 & 0.1468 & 0.1471 & 0.1453 & 0.1308 & 0.112  & 0.1394 & 0.1611 \\\\ \\hline\n",
      " 2 & 0.1715 & 0.1729 & 0.1623 & 0.1559 & 0.1374 & 0.1641 & 0.1907 \\\\ \\hline\n",
      " 3 & 0.1931 & 0.1825 & 0.1667 & 0.1636 & 0.144  & 0.1721 & 0.1905 \\\\ \\hline\n",
      " 4 & 0.1944 & 0.175  & 0.1692 & 0.1673 & 0.1459 & 0.1745 & 0.1945 \\\\ \\hline\n",
      " 5 & 0.1638 & 0.1759 & 0.1717 & 0.1576 & 0.1469 & 0.1749 & 0.1967 \\\\ \\hline\n",
      " 6 & 0.195  & 0.166  & 0.1729 & 0.158  & 0.147  & 0.1748 & 0.1976 \\\\ \\hline\n",
      " 7 & 0.1829 & 0.1661 & 0.1736 & 0.1582 & 0.147  & 0.1749 & 0.1981 \\\\ \\hline\n",
      " 8 & 0.184  & 0.1661 & 0.1738 & 0.1583 & 0.147  & 0.1749 & 0.1983 \\\\ \\hline\n",
      " 9 & 0.2148 & 0.166  & 0.1739 & 0.1584 & 0.147  & 0.1749 & 0.1983 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.2, 0.7, 0.8, 0.8]\n",
    "EXperi(ar_coeff, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c5405-6509-4b8e-95c2-e398441a7b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff9b9b-dfbc-425e-8405-702613796f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d6e2f5-5be3-428a-8767-40355534ad22",
   "metadata": {},
   "source": [
    "# Estimate Cov(E(X|y)), multiply $\\phi^{-1}$ and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7448d5a1-bd0c-4482-aaf4-59dcf6c324fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = X_means - np.mean(X, axis=0)\n",
    "    \n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bd1b48e4-98eb-4bc9-96aa-52d3beb19ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test1(ar_coeff, a1, a2, n_obs, S, n_rep):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    X1 = [[np.zeros((num_N, n_obs)) for i in range(num_N - 1)] for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S + 1)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1 \n",
    "    n = n_rep\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    Hat = np.zeros((P, 1))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "            X1[a] = np.concatenate([ar_series[i][a:n_obs+a].reshape(-1,1) for i in range(num_N - 1)], axis = 1)\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(P)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_11(X, y[a], H, K)\n",
    "            edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                \n",
    "        for q in range(0, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            Q3 = np.linalg.inv(np.cov(X1[q].T)) @ V1[q] @ np.linalg.inv(np.cov(X1[q].T))   #(phi[j] ** a)\n",
    "            # Q3 = np.linalg.inv(np.cov(X.T)) @ V1[q] @ np.linalg.inv(np.cov(X.T))\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            \n",
    "            edr_est = np.multiply(np.power(ar_coeff, -q), K_largest_eigenvectors.flatten())\n",
    "            \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q] += edr_est.reshape(-1, 1)\n",
    "            # hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "        \n",
    "        Hat += sum(hat[i] for i in range(0, S + 1))\n",
    "        \n",
    "    print(Hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73885b98-744c-4b4b-a556-155ba70d0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 183.04482779]\n",
      " [ 232.79206203]\n",
      " [ 444.94668317]\n",
      " [2255.38881703]]\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test1(ar_coeff, 2, 3, 100, 10, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ab664ab9-92b9-40bc-977b-020bdc30241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.31144061e+02]\n",
      " [ 4.72170178e+01]\n",
      " [ 9.27838411e-01]\n",
      " [-2.14612349e-01]]\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test1(ar_coeff, 2, 3, 100, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ee09d771-ea1f-488c-b644-5e0a75e1e3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569496.87765692]\n",
      " [532752.73381324]\n",
      " [  -884.85593776]\n",
      " [  -813.2256108 ]]\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test1(ar_coeff, 2, 3, 100, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e3f55-c4bb-4466-86df-8bd3f3e9dab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "80d06064-329a-4a00-a330-0a2bf700ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "num_N = 5\n",
    "n_obs = 1000\n",
    "S = 10\n",
    "n_rep = 10\n",
    "a1 = 2\n",
    "a2 = 3\n",
    "noise = np.zeros((num_N, n_obs+S))\n",
    "H = 5\n",
    "P = 4\n",
    "K = 1\n",
    "y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "X1 = [[np.zeros((num_N, n_obs)) for i in range(num_N - 1)] for i in range(S+1)]\n",
    "hat = [np.zeros((P, 1)) for _ in range(S + 1)]\n",
    "g = np.zeros((S, 1))\n",
    "n1 = 0\n",
    "l = 1 \n",
    "n = n_rep\n",
    "edr = np.zeros((S+1, P))\n",
    "EDR = np.zeros((1, P))\n",
    "while n1 < n:\n",
    "    for h in range(num_N):\n",
    "        noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "    ar_series = np.zeros((num_N, n_obs+S))\n",
    "    for t in range(0, n_obs+S):\n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "        ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "    for a in range(0, S+1):\n",
    "        y[a] = ar_series[4][a:n_obs+a]\n",
    "        X1[a] = np.concatenate([ar_series[i][a:n_obs+a].reshape(-1,1) for i in range(num_N - 1)], axis = 1)\n",
    "    X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "    V1 = []\n",
    "    Q2 = []\n",
    "    for a in range(0, S + 1):\n",
    "        edr_part, M = sir_11(X, y[a], H, K)\n",
    "        edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "        V1.append(M)\n",
    "        if a == 0:\n",
    "            if edr[0][0]<0:\n",
    "                edr[0] = -edr[0]\n",
    "            edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "            EDR += edr[0]\n",
    "            \n",
    "    for q in range(0, S + 1):\n",
    "        Q3 = np.zeros((P, P))\n",
    "        phi = ar_coeff\n",
    "        Q3 = np.linalg.inv(np.cov(X.T)) @ V1[q] @ np.linalg.inv(np.cov(X.T))   #(phi[j] ** a)\n",
    "        # Q3 = np.linalg.inv(np.cov(X1[q].T)) @ V1[q] @ np.linalg.inv(np.cov(X1[q].T))\n",
    "        eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "        # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "        K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "        # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "        K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "\n",
    "        edr_est = np.multiply(np.power(ar_coeff, -q), K_largest_eigenvectors.flatten())      \n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        hat[q] += edr_est.reshape(-1, 1)\n",
    "        # hat[q - 1] += np.real(edr_est)\n",
    "    n1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "eb2ce38c-35a8-48d8-9fc4-f6633c0d5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((P, P))\n",
    "phi = ar_coeff\n",
    "m = 0\n",
    "Q = np.linalg.inv(np.cov(X.T)) @ V1[m] @ np.linalg.inv(np.cov(X.T))   #(phi[j] ** a)\n",
    "# Q = np.linalg.inv(np.cov(X1[m].T)) @ V1[m] @ np.linalg.inv(np.cov(X1[m].T))\n",
    "eigenvalues, eigenvectors = np.linalg.eig(Q3)\n",
    "# edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "K_index = np.argpartition(np.abs(eigenvalues), P - K) >= P - K\n",
    "# K_largest_eigenvectors = edr_est[:, K_index]\n",
    "K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "\n",
    "edr_est = np.multiply(np.power(ar_coeff, -m), K_largest_eigenvectors.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6d352ccc-5ebd-4ff8-9b3b-fc5c48cabc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3816451 ,  0.06614549,  0.21743479, -0.89593186])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_largest_eigenvectors.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e780f356-881e-4b90-af32-f3f9113efb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3816451 ,  0.06614549,  0.21743479, -0.89593186])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edr_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7593da-eee2-4708-8aa5-28c2d07c76d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Without whitening: multiplying seperate $\\Sigma_{(x-q)(x-q)}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b942620c-59d9-4fd4-a166-b0fc43c7bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.593387 & -0.200007  & 0.0382008 & -0.0312047   & 3.6335  \\\\ \\hline\n",
      " 1 & 0.433993 & -0.167195  & 0.122721  &  0.000265494 & 3.2624  \\\\ \\hline\n",
      " 2 & 0.365873 & -0.0963971 & 0.110853  & -0.0414165   & 4.46214 \\\\ \\hline\n",
      " 3 & 0.330933 & -0.0836644 & 0.129064  & -0.0546248   & 4.62215 \\\\ \\hline\n",
      " 4 & 0.315857 & -0.0742031 & 0.118406  & -0.0346726   & 4.92332 \\\\ \\hline\n",
      " 5 & 0.304829 & -0.0627978 & 0.0697248 & -0.0116148   & 5.5208  \\\\ \\hline\n",
      " 6 & 0.276944 & -0.0377743 & 0.0667104 & -0.0429464   & 7.99822 \\\\ \\hline\n",
      " 7 & 0.268241 & -0.0425712 & 0.089962  &  0.0109939   & 6.96765 \\\\ \\hline\n",
      " 8 & 0.27968  & -0.055209  & 0.0788766 &  0.0017535   & 5.73252 \\\\ \\hline\n",
      " 9 & 0.28359  & -0.045081  & 0.0875949 & -0.00793149  & 6.95734 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "3.9199833423703767\n",
      "[ 0.20436142 -0.06281633 -0.05842166 -0.02172449]\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test1(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 50\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        \n",
    "        # X = X -np.mean(X, axis = 0)\n",
    "        # covariance_matrix = np.cov(X, rowvar=False)\n",
    "        # eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    #     eigenvectors = np.real(eigenvectors)\n",
    "    # # Construct the transformation matrix with eigenvalues adjusted\n",
    "    #     transform_matrix = eigenvectors @ np.diag(1 / np.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "    \n",
    "    # # Apply the transformation to X\n",
    "    #     X_transformed = X @ transform_matrix\n",
    "        # _, V_hat = sir_11(X, y[0], H, K)\n",
    "        # A = np.power(V_hat, -1/2)\n",
    "        # X = X @ (V_hat)**(-1/2)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_11(X, y[a], H, K)\n",
    "            edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                # EDR += np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "            # Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(np.cov(X[ : X.shape[0] - q].T)) @ V1[a] @ np.linalg.inv(np.cov(X[: X.shape[0] - q].T)))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "\n",
    "            ## For Q>0, I don't know if it's appopriate to multiply np.linalg.inv(np.cov(X.T)) to transform back.\n",
    "\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            # edr_est = np.linalg.inv(np.cov(X.T)) @ K_largest_eigenvectors\n",
    "            # edr_est = np.linalg.inv(V1[0]) @ K_largest_eigenvectors\n",
    "            # edr_est = K_largest_eigenvectors \n",
    "            \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            # hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test1(ar_coeff, 2, 3, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c404f08-caa5-4a73-84c9-107dc63ca4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.556099 & 0.831002 & -0.000318917 & 0.000525384 & 0.0025236  \\\\ \\hline\n",
      " 1 & 0.553594 & 0.832668 & -0.000299849 & 0.000443954 & 0.0018238  \\\\ \\hline\n",
      " 2 & 0.553392 & 0.832799 & -0.000321327 & 0.000265707 & 0.0021706  \\\\ \\hline\n",
      " 3 & 0.553518 & 0.832714 & -0.000384392 & 0.000216875 & 0.00195063 \\\\ \\hline\n",
      " 4 & 0.553466 & 0.832748 & -0.000364973 & 0.000210582 & 0.0020399  \\\\ \\hline\n",
      " 5 & 0.553672 & 0.832608 & -0.000386296 & 0.000180199 & 0.00168187 \\\\ \\hline\n",
      " 6 & 0.553628 & 0.832634 & -0.000353458 & 0.00016512  & 0.00175555 \\\\ \\hline\n",
      " 7 & 0.553672 & 0.832604 & -0.000341669 & 0.000104764 & 0.00167743 \\\\ \\hline\n",
      " 8 & 0.553781 & 0.832529 & -0.000430381 & 6.00476e-05 & 0.00148733 \\\\ \\hline\n",
      " 9 & 0.553902 & 0.832444 & -0.000523843 & 0.000169128 & 0.00127447 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.002346436309913491\n",
      "[ 5.53287446e-01  8.32862558e-01 -1.48464863e-04  9.14297656e-05]\n"
     ]
    }
   ],
   "source": [
    "Test1(ar_coeff, 2, 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdfa5e2c-fee9-4e41-9747-1f09dd2549b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.551886 & 0.784502 &  0.00553951  &  0.00661992 & 0.0368188  \\\\ \\hline\n",
      " 1 & 0.522316 & 0.779048 & -0.00098017  &  0.00837238 & 0.00378759 \\\\ \\hline\n",
      " 2 & 0.516206 & 0.749346 &  0.00602649  &  0.0084525  & 0.0222086  \\\\ \\hline\n",
      " 3 & 0.5039   & 0.71601  &  0.0221853   & -0.00436081 & 0.0370952  \\\\ \\hline\n",
      " 4 & 0.489379 & 0.703581 &  0.0206358   & -0.0103419  & 0.0288874  \\\\ \\hline\n",
      " 5 & 0.483794 & 0.685206 &  0.000415459 & -0.010076   & 0.0393893  \\\\ \\hline\n",
      " 6 & 0.470539 & 0.656758 &  0.00292458  &  0.00798477 & 0.049791   \\\\ \\hline\n",
      " 7 & 0.450217 & 0.628528 &  0.0118395   & -0.0362715  & 0.0496371  \\\\ \\hline\n",
      " 8 & 0.455805 & 0.583056 &  0.0353442   &  0.00391622 & 0.115085   \\\\ \\hline\n",
      " 9 & 0.45207  & 0.591922 &  0.0150978   & -0.0203426  & 0.0970654  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.0835884502324854\n",
      "[ 0.38181995  0.50892016 -0.01455863 -0.0018383 ]\n"
     ]
    }
   ],
   "source": [
    "Test1(ar_coeff, 2, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3f8fe7-7c70-4763-b8f5-56dfca59d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\yhuang73\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTest1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar_coeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 51\u001b[0m, in \u001b[0;36mTest1\u001b[1;34m(ar_coeff, a1, a2, n_obs)\u001b[0m\n\u001b[0;32m     49\u001b[0m Q2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, S \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     edr_part, M \u001b[38;5;241m=\u001b[39m \u001b[43msir_11\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     edr[a] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(np\u001b[38;5;241m.\u001b[39mcov(X\u001b[38;5;241m.\u001b[39mT)) \u001b[38;5;241m@\u001b[39m edr_part\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     53\u001b[0m     V1\u001b[38;5;241m.\u001b[39mappend(M)\n",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m, in \u001b[0;36msir_11\u001b[1;34m(X, y, num_slices, K)\u001b[0m\n\u001b[0;32m     27\u001b[0m X_centered \u001b[38;5;241m=\u001b[39m X_means \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m V_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(V_hat,ph_hat \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(X_centered\u001b[38;5;241m.\u001b[39mT, X_centered))\n\u001b[1;32m---> 30\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m K_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(np\u001b[38;5;241m.\u001b[39mabs(eigenvalues), X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mK) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mK\n\u001b[0;32m     32\u001b[0m K_largest_eigenvectors \u001b[38;5;241m=\u001b[39m eigenvectors[:, K_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\linalg.py:1329\u001b[0m, in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1327\u001b[0m _assert_stacked_2d(a)\n\u001b[0;32m   1328\u001b[0m _assert_stacked_square(a)\n\u001b[1;32m-> 1329\u001b[0m \u001b[43m_assert_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[0;32m   1332\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(\n\u001b[0;32m   1333\u001b[0m     _raise_linalgerror_eigenvalues_nonconvergence)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\linalg.py:218\u001b[0m, in \u001b[0;36m_assert_finite\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "Test1(ar_coeff, 2, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ed23e4-7603-4b51-abaa-385e3df0067a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.538026 &  0.0129157  &  0.0579676   &  0.0194087  &   40.9901  \\\\ \\hline\n",
      " 1 & 0.413918 & -0.00538281 &  0.00464111  &  0.0249488  &   77.5629  \\\\ \\hline\n",
      " 2 & 0.382507 & -0.00618278 & -0.00155372  &  0.0696794  &   62.5331  \\\\ \\hline\n",
      " 3 & 0.352734 & -0.0417019  &  0.0145337   &  0.0500557  &    9.12513 \\\\ \\hline\n",
      " 4 & 0.321082 & -0.0264536  &  0.0406214   &  0.0104744  &   12.8042  \\\\ \\hline\n",
      " 5 & 0.327509 & -0.0105641  &  0.00301076  & -0.00200243 &   31.6686  \\\\ \\hline\n",
      " 6 & 0.321886 &  0.0134612  &  0.000872697 &  0.00114963 &   23.2454  \\\\ \\hline\n",
      " 7 & 0.288034 & -0.017865   & -0.0345217   & -0.00628745 &   16.7895  \\\\ \\hline\n",
      " 8 & 0.281621 &  0.00023571 &  0.030861    & -0.0938845  & 1194.11    \\\\ \\hline\n",
      " 9 & 0.271379 & -0.0010959  &  0.0293359   & -0.0545872  &  248.298   \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "8.641277273918536\n",
      "[ 0.18772292  0.02016803 -0.02099418 -0.01092285]\n"
     ]
    }
   ],
   "source": [
    "Test1(ar_coeff, 2, 3, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9940440-cfd2-4240-8161-3fd33ab19a79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Without whitening: Using the remark, multiplying uniform $\\Sigma_{xx}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "830cdbc9-6758-4a6b-9405-452389dd13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_12(X, y, num_slices, K):\n",
    "    # X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = (X_means - np.mean(X_means, axis=0)) - np.mean(X, axis=0)\n",
    "    \n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94ebe435-cc4f-4730-8162-478463e9c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.554682 & 0.832051 & -0.000421317 & 0.000186286 & 2.20273e-05 \\\\ \\hline\n",
      " 1 & 0.553119 & 0.83309  & -0.000439969 & 0.00016243  & 0.00272982  \\\\ \\hline\n",
      " 2 & 0.553089 & 0.83311  & -0.000441105 & 0.000154199 & 0.00278143  \\\\ \\hline\n",
      " 3 & 0.553088 & 0.833111 & -0.000441671 & 0.000153945 & 0.00278405  \\\\ \\hline\n",
      " 4 & 0.553088 & 0.833111 & -0.000441617 & 0.000153888 & 0.00278423  \\\\ \\hline\n",
      " 5 & 0.553088 & 0.833111 & -0.000441578 & 0.000153635 & 0.00278421  \\\\ \\hline\n",
      " 6 & 0.553088 & 0.833111 & -0.000441571 & 0.000153486 & 0.00278419  \\\\ \\hline\n",
      " 7 & 0.553088 & 0.833111 & -0.000441565 & 0.000153339 & 0.00278417  \\\\ \\hline\n",
      " 8 & 0.553088 & 0.833111 & -0.00044156  & 0.000153171 & 0.00278416  \\\\ \\hline\n",
      " 9 & 0.553088 & 0.833111 & -0.000441558 & 0.000153149 & 0.00278415  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "2.202731067624253e-05\n",
      "[ 5.54682402e-01  8.32051094e-01 -4.21316764e-04  1.86285851e-04]\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 50\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        # X = X -np.mean(X, axis = 0)\n",
    "        # covariance_matrix = np.cov(X, rowvar=False)\n",
    "        # eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    #     eigenvectors = np.real(eigenvectors)\n",
    "    # # Construct the transformation matrix with eigenvalues adjusted\n",
    "    #     transform_matrix = eigenvectors @ np.diag(1 / np.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "    \n",
    "    # # Apply the transformation to X\n",
    "    #     X_transformed = X @ transform_matrix\n",
    "        # _, V_hat = sir_11(X, y[0], H, K)\n",
    "        # A = np.power(V_hat, -1/2)\n",
    "        # X = X @ (V_hat)**(-1/2)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_12(X, y[a], H, K)\n",
    "            edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                # EDR += np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "            # Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (V1[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "\n",
    "            \n",
    "            ## For Q>0, I don't know if it's appopriate to multiply np.linalg.inv(np.cov(X.T)) to transform back.\n",
    "\n",
    "            \n",
    "            edr_est = np.linalg.inv(np.cov(X.T)) @ K_largest_eigenvectors\n",
    "            # edr_est = np.linalg.inv(V1[0]) @ K_largest_eigenvectors\n",
    "            # edr_est = K_largest_eigenvectors \n",
    "            \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            # hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test(ar_coeff, 2, 3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea31b7a4-8817-41ca-bbe4-e1b6b5032585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.309112  &  0.411598  & -0.00390617 & -0.0802902  & 0.0843382 \\\\ \\hline\n",
      " 1 & 0.138667  &  0.111118  &  0.046077   &  0.0530215  & 0.581254  \\\\ \\hline\n",
      " 2 & 0.103438  &  0.0156685 &  0.0247304  &  0.0786053  & 5.93502   \\\\ \\hline\n",
      " 3 & 0.0989856 & -0.0170933 &  0.0310242  &  0.00134154 & 6.45758   \\\\ \\hline\n",
      " 4 & 0.098517  & -0.024111  &  0.0213662  &  0.0408205  & 4.75264   \\\\ \\hline\n",
      " 5 & 0.0994216 & -0.031697  &  0.0201814  &  0.0407384  & 3.80329   \\\\ \\hline\n",
      " 6 & 0.100216  & -0.0329793 &  0.0244274  &  0.0803575  & 3.70544   \\\\ \\hline\n",
      " 7 & 0.100757  & -0.0333101 &  0.0244933  &  0.0802991  & 3.6915    \\\\ \\hline\n",
      " 8 & 0.101101  & -0.0353179 &  0.0240775  &  0.120005   & 3.52928   \\\\ \\hline\n",
      " 9 & 0.10139   & -0.0353391 &  0.0240672  &  0.119992   & 3.53571   \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.08433823204715973\n",
      "[ 0.30911181  0.41159759 -0.00390617 -0.08029018]\n"
     ]
    }
   ],
   "source": [
    "Test(ar_coeff, 2, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5dcb17fd-1e70-474e-818c-4148b5fc07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.550501 & 0.83389  & 0.00305112 &  0.00186006 & 0.00650678 \\\\ \\hline\n",
      " 1 & 0.53796  & 0.821928 & 0.0105533  & -0.0166877  & 0.0121569  \\\\ \\hline\n",
      " 2 & 0.51687  & 0.791945 & 0.01045    & -0.0402244  & 0.0140085  \\\\ \\hline\n",
      " 3 & 0.509471 & 0.784104 & 0.0139635  & -0.0437469  & 0.0169175  \\\\ \\hline\n",
      " 4 & 0.489092 & 0.752235 & 0.00639513 & -0.0163641  & 0.0164819  \\\\ \\hline\n",
      " 5 & 0.479128 & 0.735576 & 0.00696986 & -0.00597958 & 0.0153031  \\\\ \\hline\n",
      " 6 & 0.474131 & 0.727604 & 0.00768256 & -0.00087513 & 0.0150338  \\\\ \\hline\n",
      " 7 & 0.47105  & 0.722745 & 0.00814339 &  0.00297938 & 0.0149155  \\\\ \\hline\n",
      " 8 & 0.469051 & 0.719649 & 0.00846258 &  0.00525785 & 0.0148896  \\\\ \\hline\n",
      " 9 & 0.467886 & 0.717947 & 0.00866254 &  0.00659333 & 0.0149668  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.006506781450693722\n",
      "[0.55050052 0.83388969 0.00305112 0.00186006]\n"
     ]
    }
   ],
   "source": [
    "Test(ar_coeff, 2, 3, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53da2b2e-aefb-4bb7-acad-9ee60eb4ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.17341   & -0.0596272  & -0.0142863   &  0.0767942 &  3.57491 \\\\ \\hline\n",
      " 1 & 0.103034  & -0.00214893 & -0.00794909  &  0.0997632 & 48.6132  \\\\ \\hline\n",
      " 2 & 0.0956537 &  0.0257416  &  0.0068056   &  0.0563227 &  3.04925 \\\\ \\hline\n",
      " 3 & 0.0978862 &  0.0376219  &  0.00963144  & -0.0033661 &  1.93517 \\\\ \\hline\n",
      " 4 & 0.101353  &  0.0332455  &  0.00525271  & -0.0239397 &  2.38195 \\\\ \\hline\n",
      " 5 & 0.103515  &  0.0332268  &  0.00316358  & -0.0245252 &  2.44874 \\\\ \\hline\n",
      " 6 & 0.104691  &  0.0332793  &  0.00204471  & -0.0248031 &  2.47915 \\\\ \\hline\n",
      " 7 & 0.105388  &  0.0308755  & -0.000658166 & -0.0447117 &  2.74667 \\\\ \\hline\n",
      " 8 & 0.105831  &  0.0309131  & -0.00106419  & -0.0448128 &  2.75683 \\\\ \\hline\n",
      " 9 & 0.10611   &  0.0309351  & -0.00130859  & -0.0448806 &  2.76342 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "3.5749057348304305\n",
      "[ 0.17341027 -0.05962724 -0.01428628  0.07679424]\n"
     ]
    }
   ],
   "source": [
    "Test(ar_coeff, 2, 3, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4294391d-359d-4a59-ad35-fdf8d06da650",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar_coeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[84], line 50\u001b[0m, in \u001b[0;36mTest\u001b[1;34m(ar_coeff, a1, a2, n_obs)\u001b[0m\n\u001b[0;32m     48\u001b[0m Q2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, S \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 50\u001b[0m     edr_part, M \u001b[38;5;241m=\u001b[39m \u001b[43msir_12\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     edr[a] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(np\u001b[38;5;241m.\u001b[39mcov(X\u001b[38;5;241m.\u001b[39mT)) \u001b[38;5;241m@\u001b[39m edr_part\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     52\u001b[0m     V1\u001b[38;5;241m.\u001b[39mappend(M)\n",
      "Cell \u001b[1;32mIn[69], line 30\u001b[0m, in \u001b[0;36msir_12\u001b[1;34m(X, y, num_slices, K)\u001b[0m\n\u001b[0;32m     27\u001b[0m X_centered \u001b[38;5;241m=\u001b[39m (X_means \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X_means, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m V_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(V_hat,ph_hat \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(X_centered\u001b[38;5;241m.\u001b[39mT, X_centered))\n\u001b[1;32m---> 30\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m K_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(np\u001b[38;5;241m.\u001b[39mabs(eigenvalues), X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mK) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mK\n\u001b[0;32m     32\u001b[0m K_largest_eigenvectors \u001b[38;5;241m=\u001b[39m eigenvectors[:, K_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\linalg.py:1329\u001b[0m, in \u001b[0;36meig\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1327\u001b[0m _assert_stacked_2d(a)\n\u001b[0;32m   1328\u001b[0m _assert_stacked_square(a)\n\u001b[1;32m-> 1329\u001b[0m \u001b[43m_assert_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[0;32m   1332\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(\n\u001b[0;32m   1333\u001b[0m     _raise_linalgerror_eigenvalues_nonconvergence)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\linalg.py:218\u001b[0m, in \u001b[0;36m_assert_finite\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "Test(ar_coeff, 2, 3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbeb8b0-0bad-4f82-8e9d-d58278883363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Without whitening: Using the remark, multiplying uniform $\\Sigma_{(x-q)(x-q)}^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e694ff-fb99-4053-afa8-0550b5ecc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_12(X, y, num_slices, K):\n",
    "    # X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    \n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    \n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = (X_means - np.mean(X_means, axis=0)) - np.mean(X, axis=0)\n",
    "    \n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    \n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "031ddbd6-1b5e-4828-9a18-355e28d7a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def Test2(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        # X = X -np.mean(X, axis = 0)\n",
    "        # covariance_matrix = np.cov(X, rowvar=False)\n",
    "        # eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    #     eigenvectors = np.real(eigenvectors)\n",
    "    # # Construct the transformation matrix with eigenvalues adjusted\n",
    "    #     transform_matrix = eigenvectors @ np.diag(1 / np.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "    \n",
    "    # # Apply the transformation to X\n",
    "    #     X_transformed = X @ transform_matrix\n",
    "        # _, V_hat = sir_11(X, y[0], H, K)\n",
    "        # A = np.power(V_hat, -1/2)\n",
    "        # X = X @ (V_hat)**(-1/2)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr_part, M = sir_12(X, y[a], H, K)\n",
    "            edr[a] = np.linalg.inv(np.cov(X.T)) @ edr_part.flatten()\n",
    "            V1.append(M)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "                # EDR += np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "            # Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(np.cov(X[:X.shape[0]-q].T)) @ V1[a] @ np.linalg.inv(np.cov(X[:X.shape[0]-q].T)))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "\n",
    "            \n",
    "            ## For Q>0, I don't know if it's appopriate to multiply np.linalg.inv(np.cov(X.T)) to transform back.\n",
    "\n",
    "            \n",
    "            edr_est = K_largest_eigenvectors\n",
    "            # edr_est = np.linalg.inv(V1[0]) @ K_largest_eigenvectors\n",
    "            # edr_est = K_largest_eigenvectors \n",
    "            \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += edr_est\n",
    "            # hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    print(L)\n",
    "    print(EDR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0cb2a99-923f-4508-89e3-483902c19385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.54218  & 0.765786 & -0.0018391  &  0.00136761 & 0.0413374 \\\\ \\hline\n",
      " 1 & 0.485398 & 0.668555 &  0.00610551 &  0.013447   & 0.0593743 \\\\ \\hline\n",
      " 2 & 0.448478 & 0.644463 & -0.00906163 &  0.00192498 & 0.0292271 \\\\ \\hline\n",
      " 3 & 0.425215 & 0.59763  & -0.0275903  & -0.020329   & 0.0448361 \\\\ \\hline\n",
      " 4 & 0.409769 & 0.57083  & -0.0144202  &  0.0005827  & 0.0511818 \\\\ \\hline\n",
      " 5 & 0.398951 & 0.537193 & -0.0165699  & -0.0153067  & 0.0759924 \\\\ \\hline\n",
      " 6 & 0.38841  & 0.545203 & -0.032914   & -0.0302815  & 0.0457473 \\\\ \\hline\n",
      " 7 & 0.388799 & 0.512585 & -0.0192266  & -0.0112626  & 0.0918398 \\\\ \\hline\n",
      " 8 & 0.375265 & 0.507318 & -0.0192327  & -0.00767221 & 0.0730379 \\\\ \\hline\n",
      " 9 & 0.358338 & 0.477938 & -0.00953313 & -0.0161782  & 0.083091  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.1094852165938277\n",
      "[ 0.33154161  0.42716074 -0.03310437  0.02474221]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "Test2(ar_coeff, 2, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32d473-b1bc-442d-ac98-1833c492fe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f1429-bcb9-4a12-89df-620fdce9f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test2(ar_coeff, 2, 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0b0b5-3569-447b-9a98-07934004722c",
   "metadata": {},
   "source": [
    "In the paper, the remark said \"just the eigenvectors for the eigenvalue decom-\r\n",
    " position ofnew V_hat1 with respectsigma_xxt, it is the generalized eigenvalue problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c0a86-51c4-4a5c-b584-64f65d721e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796b1fa-e8a8-423a-930d-b8ef11fe5ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c50ee-35b9-4a40-9f4f-a87c8d3fbc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ba6c861-476e-4c40-8a98-551b525c7ca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# first term by Z, following terms by X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287d988-5b9c-40ce-8e2d-0442f9e42dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def test1(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 25\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "\n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "\n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "    # print(g)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "    print(edr_est)\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "test1(ar_coeff, 2, 3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a77f6-2ebc-4dab-80dd-0baae71e66ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3229d906-6bd3-400f-b68a-9dd9634d9588",
   "metadata": {},
   "source": [
    "# Take sample covariance matrix by whitened Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d96d6e0-50ae-4a78-b93c-63d4a23460f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test1(ar_coeff, a1, a2, n_obs, S):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 25\n",
    "    # S = 20\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "\n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "\n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "    # print(g)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "    print(edr_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8155687-bb94-49b5-b158-9bcb3ab8b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.554628 & 0.832074 & -0.000102234 & 0.00055957  & 0.000105724 \\\\ \\hline\n",
      "  1 & 0.553198 & 0.833025 & -0.000124745 & 0.000542629 & 0.00258346  \\\\ \\hline\n",
      "  2 & 0.553181 & 0.833036 & -0.000126783 & 0.000540018 & 0.00261238  \\\\ \\hline\n",
      "  3 & 0.553181 & 0.833036 & -0.000126837 & 0.000539695 & 0.00261285  \\\\ \\hline\n",
      "  4 & 0.553181 & 0.833036 & -0.000126849 & 0.000539648 & 0.00261287  \\\\ \\hline\n",
      "  5 & 0.553181 & 0.833036 & -0.000126849 & 0.000539663 & 0.00261287  \\\\ \\hline\n",
      "  6 & 0.553181 & 0.833036 & -0.000126849 & 0.000539677 & 0.00261287  \\\\ \\hline\n",
      "  7 & 0.553181 & 0.833036 & -0.000126849 & 0.000539685 & 0.00261287  \\\\ \\hline\n",
      "  8 & 0.553181 & 0.833036 & -0.000126849 & 0.000539693 & 0.00261287  \\\\ \\hline\n",
      "  9 & 0.553181 & 0.833036 & -0.000126849 & 0.000539697 & 0.00261287  \\\\ \\hline\n",
      " 10 & 0.553181 & 0.833036 & -0.000126849 & 0.000539699 & 0.00261287  \\\\ \\hline\n",
      " 11 & 0.553181 & 0.833036 & -0.000126849 & 0.000539701 & 0.00261287  \\\\ \\hline\n",
      " 12 & 0.553181 & 0.833036 & -0.000126849 & 0.000539701 & 0.00261287  \\\\ \\hline\n",
      " 13 & 0.553181 & 0.833036 & -0.000126849 & 0.000539702 & 0.00261287  \\\\ \\hline\n",
      " 14 & 0.553181 & 0.833036 & -0.000126849 & 0.000539703 & 0.00261287  \\\\ \\hline\n",
      " 15 & 0.553181 & 0.833036 & -0.000126849 & 0.000539703 & 0.00261287  \\\\ \\hline\n",
      " 16 & 0.553181 & 0.833036 & -0.000126849 & 0.000539704 & 0.00261287  \\\\ \\hline\n",
      " 17 & 0.553181 & 0.833036 & -0.000126849 & 0.000539704 & 0.00261287  \\\\ \\hline\n",
      " 18 & 0.553181 & 0.833036 & -0.000126849 & 0.000539704 & 0.00261287  \\\\ \\hline\n",
      " 19 & 0.553181 & 0.833036 & -0.000126849 & 0.000539704 & 0.00261287  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.00010572402866038111\n",
      "[ 5.54628218e-01  8.32074282e-01 -1.02233773e-04  5.59570293e-04]\n",
      "[[ 0.55095895]\n",
      " [ 0.83451876]\n",
      " [ 0.00467134]\n",
      " [-0.00093035]]\n"
     ]
    }
   ],
   "source": [
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "test1(ar_coeff, 2, 3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c4a3ca1-beab-49c1-b4e1-f8b989c7bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.552821 & 0.828806 & 0.00760208 & 0.00024703  & 0.000342341 \\\\ \\hline\n",
      "  1 & 0.550644 & 0.830132 & 0.00663265 & 0.000102364 & 0.0033454   \\\\ \\hline\n",
      "  2 & 0.550427 & 0.830197 & 0.00651015 & 0.000112878 & 0.00365886  \\\\ \\hline\n",
      "  3 & 0.550373 & 0.83017  & 0.00648169 & 0.00013442  & 0.00370209  \\\\ \\hline\n",
      "  4 & 0.550347 & 0.830148 & 0.00648132 & 0.000174597 & 0.00371651  \\\\ \\hline\n",
      "  5 & 0.550334 & 0.830134 & 0.00647843 & 0.000165339 & 0.00372123  \\\\ \\hline\n",
      "  6 & 0.550325 & 0.830125 & 0.00647681 & 0.000161981 & 0.0037245   \\\\ \\hline\n",
      "  7 & 0.550319 & 0.830119 & 0.00647283 & 0.000171757 & 0.00372719  \\\\ \\hline\n",
      "  8 & 0.550315 & 0.830115 & 0.00647004 & 0.00017017  & 0.00372892  \\\\ \\hline\n",
      "  9 & 0.550312 & 0.830113 & 0.00646886 & 0.000167454 & 0.00372991  \\\\ \\hline\n",
      " 10 & 0.550311 & 0.830111 & 0.00646851 & 0.000168872 & 0.00373046  \\\\ \\hline\n",
      " 11 & 0.55031  & 0.830111 & 0.0064683  & 0.000169395 & 0.00373072  \\\\ \\hline\n",
      " 12 & 0.55031  & 0.83011  & 0.00646812 & 0.000169757 & 0.00373091  \\\\ \\hline\n",
      " 13 & 0.550309 & 0.83011  & 0.00646792 & 0.000169675 & 0.0037311   \\\\ \\hline\n",
      " 14 & 0.550309 & 0.830109 & 0.00646778 & 0.000169565 & 0.00373122  \\\\ \\hline\n",
      " 15 & 0.550309 & 0.830109 & 0.00646769 & 0.000169338 & 0.00373129  \\\\ \\hline\n",
      " 16 & 0.550309 & 0.830109 & 0.00646765 & 0.000169087 & 0.00373133  \\\\ \\hline\n",
      " 17 & 0.550309 & 0.830109 & 0.00646762 & 0.000168955 & 0.00373137  \\\\ \\hline\n",
      " 18 & 0.550309 & 0.830109 & 0.0064676  & 0.000168868 & 0.00373139  \\\\ \\hline\n",
      " 19 & 0.550309 & 0.830109 & 0.0064676  & 0.000168932 & 0.0037314   \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.0003423412471783571\n",
      "[5.52821203e-01 8.28806203e-01 7.60208005e-03 2.47030424e-04]\n",
      "[[ 0.53624023]\n",
      " [ 0.84384003]\n",
      " [ 0.01390129]\n",
      " [-0.01368084]]\n"
     ]
    }
   ],
   "source": [
    "test1(ar_coeff, 2, 3, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c17e01-57c8-40bf-9d70-8de732d720da",
   "metadata": {},
   "source": [
    "Compare the results where it's without the whitening step, the method with the QR whitening step seems to have higher accuracy for small number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0683b1fb-c110-43b7-9070-28acf6df67ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.547179 & 0.825606 & 0.000346157 & 0.00712697 & 0.00390571 \\\\ \\hline\n",
      "  1 & 0.543652 & 0.826861 & 0.001639    & 0.00743372 & 0.00917749 \\\\ \\hline\n",
      "  2 & 0.543134 & 0.826478 & 0.0018595   & 0.00760631 & 0.00949901 \\\\ \\hline\n",
      "  3 & 0.542945 & 0.826066 & 0.00184444  & 0.00805647 & 0.00940097 \\\\ \\hline\n",
      "  4 & 0.542819 & 0.825782 & 0.00184745  & 0.00829533 & 0.00932733 \\\\ \\hline\n",
      "  5 & 0.542737 & 0.825585 & 0.00182392  & 0.00845368 & 0.00926948 \\\\ \\hline\n",
      "  6 & 0.542679 & 0.82545  & 0.00180174  & 0.00856284 & 0.00923304 \\\\ \\hline\n",
      "  7 & 0.542649 & 0.825361 & 0.00178338  & 0.00867467 & 0.0091979  \\\\ \\hline\n",
      "  8 & 0.542627 & 0.82531  & 0.00177265  & 0.00873883 & 0.00918402 \\\\ \\hline\n",
      "  9 & 0.54261  & 0.825267 & 0.0017657   & 0.00876449 & 0.00916986 \\\\ \\hline\n",
      " 10 & 0.542599 & 0.82524  & 0.00176062  & 0.00877928 & 0.00916237 \\\\ \\hline\n",
      " 11 & 0.542593 & 0.825221 & 0.00175502  & 0.0088119  & 0.00915468 \\\\ \\hline\n",
      " 12 & 0.542589 & 0.825209 & 0.00175165  & 0.00882927 & 0.00914954 \\\\ \\hline\n",
      " 13 & 0.542586 & 0.825202 & 0.00175022  & 0.00884032 & 0.0091477  \\\\ \\hline\n",
      " 14 & 0.542585 & 0.825199 & 0.00174981  & 0.00884509 & 0.00914722 \\\\ \\hline\n",
      " 15 & 0.542584 & 0.825197 & 0.00174979  & 0.00884669 & 0.00914687 \\\\ \\hline\n",
      " 16 & 0.542583 & 0.825196 & 0.00174957  & 0.00884959 & 0.00914655 \\\\ \\hline\n",
      " 17 & 0.542583 & 0.825195 & 0.00174937  & 0.0088517  & 0.00914638 \\\\ \\hline\n",
      " 18 & 0.542582 & 0.825195 & 0.0017493   & 0.00885227 & 0.00914628 \\\\ \\hline\n",
      " 19 & 0.542582 & 0.825194 & 0.0017493   & 0.00885213 & 0.00914617 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.0039057106084611215\n",
      "[5.47179259e-01 8.25605755e-01 3.46156919e-04 7.12696550e-03]\n",
      "[[0.49885131]\n",
      " [0.86442589]\n",
      " [0.0490648 ]\n",
      " [0.03883177]]\n"
     ]
    }
   ],
   "source": [
    "test1(ar_coeff, 2, 3, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c60234-af19-42da-a4b1-c05f4deea504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.542276 & 0.824854 & -0.00427251 & 0.00794151 & 0.00924549 \\\\ \\hline\n",
      "  1 & 0.537501 & 0.824954 & -0.00480457 & 0.0119919  & 0.0151137  \\\\ \\hline\n",
      "  2 & 0.535147 & 0.820698 & -0.00503237 & 0.0148489  & 0.0146038  \\\\ \\hline\n",
      "  3 & 0.531651 & 0.814353 & -0.00519431 & 0.0186913  & 0.0138165  \\\\ \\hline\n",
      "  4 & 0.530575 & 0.81291  & -0.00517229 & 0.0193802  & 0.0139807  \\\\ \\hline\n",
      "  5 & 0.529662 & 0.811709 & -0.00523997 & 0.0195407  & 0.01414    \\\\ \\hline\n",
      "  6 & 0.528783 & 0.810541 & -0.0053174  & 0.0192929  & 0.0142839  \\\\ \\hline\n",
      "  7 & 0.527911 & 0.809466 & -0.00533842 & 0.0198213  & 0.0144949  \\\\ \\hline\n",
      "  8 & 0.527742 & 0.809198 & -0.00535016 & 0.0199383  & 0.0144879  \\\\ \\hline\n",
      "  9 & 0.527585 & 0.808978 & -0.00534118 & 0.0199366  & 0.0145046  \\\\ \\hline\n",
      " 10 & 0.527324 & 0.808677 & -0.00534107 & 0.0200464  & 0.0145841  \\\\ \\hline\n",
      " 11 & 0.527203 & 0.808513 & -0.00534378 & 0.0200546  & 0.0146016  \\\\ \\hline\n",
      " 12 & 0.527178 & 0.808464 & -0.00534166 & 0.0200529  & 0.0145939  \\\\ \\hline\n",
      " 13 & 0.527153 & 0.808429 & -0.00534025 & 0.0200644  & 0.0145952  \\\\ \\hline\n",
      " 14 & 0.527138 & 0.80841  & -0.0053391  & 0.0200636  & 0.014599   \\\\ \\hline\n",
      " 15 & 0.527128 & 0.808393 & -0.00533926 & 0.0200553  & 0.0145984  \\\\ \\hline\n",
      " 16 & 0.527109 & 0.808368 & -0.00534067 & 0.0200546  & 0.0146006  \\\\ \\hline\n",
      " 17 & 0.527095 & 0.80835  & -0.00534108 & 0.0200594  & 0.0146036  \\\\ \\hline\n",
      " 18 & 0.527087 & 0.808339 & -0.00534134 & 0.0200609  & 0.0146051  \\\\ \\hline\n",
      " 19 & 0.527084 & 0.808335 & -0.00534136 & 0.0200632  & 0.0146057  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.009245491085523638\n",
      "[ 0.54227649  0.824854   -0.00427251  0.00794151]\n",
      "[[0.47161148]\n",
      " [0.8508575 ]\n",
      " [0.11009542]\n",
      " [0.20372314]]\n"
     ]
    }
   ],
   "source": [
    "test1(ar_coeff, 2, 3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e567a6a-5655-4013-b77b-ac048a099d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.554591 & 0.813418 & -0.00355024 & 0.00709497 & 0.0151365  \\\\ \\hline\n",
      "  1 & 0.548439 & 0.813866 & -0.00255082 & 0.0123327  & 0.0072028  \\\\ \\hline\n",
      "  2 & 0.545398 & 0.810244 & -0.00297596 & 0.0185755  & 0.00646113 \\\\ \\hline\n",
      "  3 & 0.543592 & 0.807711 & -0.00325046 & 0.0196078  & 0.00633567 \\\\ \\hline\n",
      "  4 & 0.542475 & 0.805749 & -0.00327891 & 0.0211374  & 0.00658828 \\\\ \\hline\n",
      "  5 & 0.541648 & 0.80415  & -0.00316726 & 0.022678   & 0.0068988  \\\\ \\hline\n",
      "  6 & 0.541142 & 0.803131 & -0.00308922 & 0.0232613  & 0.00712411 \\\\ \\hline\n",
      "  7 & 0.540757 & 0.802646 & -0.00295353 & 0.0225897  & 0.00705066 \\\\ \\hline\n",
      "  8 & 0.54058  & 0.802324 & -0.00286452 & 0.0224894  & 0.00710056 \\\\ \\hline\n",
      "  9 & 0.540508 & 0.802121 & -0.00278827 & 0.0225944  & 0.00718182 \\\\ \\hline\n",
      " 10 & 0.540427 & 0.801947 & -0.00274743 & 0.0225086  & 0.00722666 \\\\ \\hline\n",
      " 11 & 0.540369 & 0.801846 & -0.00272796 & 0.0225049  & 0.0072403  \\\\ \\hline\n",
      " 12 & 0.540322 & 0.801765 & -0.00270709 & 0.0224889  & 0.00724897 \\\\ \\hline\n",
      " 13 & 0.540294 & 0.801717 & -0.00270196 & 0.0224789  & 0.00725452 \\\\ \\hline\n",
      " 14 & 0.540277 & 0.80169  & -0.00269893 & 0.0224721  & 0.00725682 \\\\ \\hline\n",
      " 15 & 0.540264 & 0.80167  & -0.00269614 & 0.0224659  & 0.00725596 \\\\ \\hline\n",
      " 16 & 0.540257 & 0.801659 & -0.00269445 & 0.0224675  & 0.0072566  \\\\ \\hline\n",
      " 17 & 0.540254 & 0.801654 & -0.0026934  & 0.0224695  & 0.00725726 \\\\ \\hline\n",
      " 18 & 0.54025  & 0.801648 & -0.00269209 & 0.0224723  & 0.00725841 \\\\ \\hline\n",
      " 19 & 0.540249 & 0.801645 & -0.00269178 & 0.0224741  & 0.00725872 \\\\ \\hline\n",
      " 20 & 0.540248 & 0.801643 & -0.00269122 & 0.022474   & 0.00725906 \\\\ \\hline\n",
      " 21 & 0.540247 & 0.801642 & -0.00269115 & 0.0224743  & 0.0072593  \\\\ \\hline\n",
      " 22 & 0.540247 & 0.801642 & -0.00269105 & 0.0224744  & 0.00725945 \\\\ \\hline\n",
      " 23 & 0.540247 & 0.801641 & -0.00269089 & 0.0224746  & 0.00725965 \\\\ \\hline\n",
      " 24 & 0.540247 & 0.801641 & -0.00269073 & 0.0224749  & 0.00725985 \\\\ \\hline\n",
      " 25 & 0.540247 & 0.801641 & -0.00269066 & 0.0224748  & 0.00725989 \\\\ \\hline\n",
      " 26 & 0.540247 & 0.801641 & -0.00269062 & 0.0224747  & 0.00725993 \\\\ \\hline\n",
      " 27 & 0.540247 & 0.801641 & -0.00269059 & 0.0224747  & 0.00725996 \\\\ \\hline\n",
      " 28 & 0.540247 & 0.80164  & -0.00269056 & 0.0224747  & 0.00725997 \\\\ \\hline\n",
      " 29 & 0.540247 & 0.80164  & -0.00269056 & 0.0224747  & 0.00725998 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.015136496435216196\n",
      "[ 0.55459076  0.8134177  -0.00355024  0.00709497]\n",
      "[[0.55769209]\n",
      " [0.81777468]\n",
      " [0.1137389 ]\n",
      " [0.08536728]]\n"
     ]
    }
   ],
   "source": [
    "test1(ar_coeff, 2, 3, 25, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e23fea6-78f2-41d7-9fc3-f2d2077aab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      "  0 & 0.497919 & 0.558648 & 0.0173635  & 0.0302184 & 0.224626 \\\\ \\hline\n",
      "  1 & 0.393234 & 0.433367 & 0.00631743 & 0.0452213 & 0.240724 \\\\ \\hline\n",
      "  2 & 0.348566 & 0.273022 & 0.0226256  & 0.112343  & 0.610029 \\\\ \\hline\n",
      "  3 & 0.329335 & 0.256345 & 0.0350648  & 0.122695  & 0.618064 \\\\ \\hline\n",
      "  4 & 0.30932  & 0.227451 & 0.0326091  & 0.151573  & 0.693274 \\\\ \\hline\n",
      "  5 & 0.299517 & 0.206283 & 0.0369062  & 0.172283  & 0.785306 \\\\ \\hline\n",
      "  6 & 0.293857 & 0.202238 & 0.0363789  & 0.173997  & 0.786363 \\\\ \\hline\n",
      "  7 & 0.288783 & 0.198741 & 0.0368015  & 0.176434  & 0.786397 \\\\ \\hline\n",
      "  8 & 0.28538  & 0.193013 & 0.0355556  & 0.156669  & 0.811886 \\\\ \\hline\n",
      "  9 & 0.283064 & 0.190611 & 0.036306   & 0.157566  & 0.81837  \\\\ \\hline\n",
      " 10 & 0.281843 & 0.189423 & 0.0364975  & 0.158224  & 0.821237 \\\\ \\hline\n",
      " 11 & 0.280901 & 0.188544 & 0.0366514  & 0.158729  & 0.823176 \\\\ \\hline\n",
      " 12 & 0.280289 & 0.188029 & 0.0366627  & 0.159108  & 0.823999 \\\\ \\hline\n",
      " 13 & 0.279981 & 0.187674 & 0.0367394  & 0.159239  & 0.825181 \\\\ \\hline\n",
      " 14 & 0.279775 & 0.18747  & 0.0367661  & 0.159362  & 0.825705 \\\\ \\hline\n",
      " 15 & 0.279635 & 0.187311 & 0.0368183  & 0.159433  & 0.826225 \\\\ \\hline\n",
      " 16 & 0.279538 & 0.187234 & 0.0368197  & 0.159484  & 0.826325 \\\\ \\hline\n",
      " 17 & 0.279486 & 0.187181 & 0.0368244  & 0.15951   & 0.826467 \\\\ \\hline\n",
      " 18 & 0.279453 & 0.187149 & 0.0368309  & 0.15952   & 0.826547 \\\\ \\hline\n",
      " 19 & 0.279427 & 0.187124 & 0.036836   & 0.159538  & 0.826602 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.22462559932430237\n",
      "[0.49791862 0.55864798 0.01736347 0.03021844]\n",
      "[[ 0.0065981 ]\n",
      " [-0.03991198]\n",
      " [ 0.22865113]\n",
      " [ 0.97266755]]\n"
     ]
    }
   ],
   "source": [
    "test1(ar_coeff, 2, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7f95b-5758-4ada-ab14-024695badf9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## traverse parameter \\phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bc642f5-1ae8-47a4-94bd-004c5e574b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\hline\n",
      " 0 & 0.097  \\\\ \\hline\n",
      " 1 & 0.0905 \\\\ \\hline\n",
      " 2 & 0.5558 \\\\ \\hline\n",
      " 3 & 0.1525 \\\\ \\hline\n",
      " 4 & 0.6686 \\\\ \\hline\n",
      " 5 & 0.1264 \\\\ \\hline\n",
      " 6 & 0.1083 \\\\ \\hline\n",
      " 7 & 0.2009 \\\\ \\hline\n",
      " 8 & 0.1319 \\\\ \\hline\n",
      " 9 & 0.3784 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def test1(ar_coeff, a1, a2, n):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    n_obs = 10\n",
    "    # S = 12\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    # n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        # hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        # hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "\n",
    "    return g\n",
    "    # print(index_array)\n",
    "\n",
    "    # array = np.array(g)\n",
    "    # table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # # Split the table into lines\n",
    "    # lines = table.split('\\n')\n",
    "    \n",
    "    # # Insert \\hline after each row\n",
    "    # latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    # print(latex_table)\n",
    "\n",
    "    # EDR = EDR / n\n",
    "    # L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "\n",
    "    # print(g)\n",
    "    # print(L)\n",
    "    # print(EDR[0])\n",
    "    # print(edr_est)\n",
    "\n",
    "# Example usage\n",
    "S = 10\n",
    "nn = 10\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "for i in range(S):\n",
    "    g[i] = test1(ar_coeff, 2, 3, nn)[i]\n",
    "index_array = list(range(len(g)))\n",
    "for i in range(S):\n",
    "    g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))\n",
    "# for n in range(nn, nn+800, 100):\n",
    "#     h = test1(ar_coeff, 2, 3, nn)\n",
    "#     for i in range(S):\n",
    "#         g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "\n",
    "formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "# array = np.array(g)\n",
    "table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "\n",
    "# Split the table into lines\n",
    "lines = table.split('\\n')\n",
    "\n",
    "# Insert \\hline after each row\n",
    "latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba968e57-cead-42bc-b83a-7309ed5e6ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acea951-bda9-4985-81bd-1b068423ae59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1fa9586-64aa-495e-9634-e655b0ed1117",
   "metadata": {},
   "source": [
    "## traverse H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59caf391-589a-4124-abf6-c930bb3f3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrr}\n",
      "\\hline\n",
      " 0 & 1.7292 & 0.1801 & 0.0318 & 0.3015 & 1.9715 & 0.0913 & 0.0048 \\\\ \\hline\n",
      " 1 & 0.6985 & 0.0845 & 0.0398 & 0.0028 & 0.7006 & 0.1725 & 0.21   \\\\ \\hline\n",
      " 2 & 1.4618 & 0.0128 & 1.1889 & 0.3274 & 1.7366 & 0.171  & 0.2446 \\\\ \\hline\n",
      " 3 & 0.0616 & 0.0314 & 2.4018 & 0.1387 & 1.6995 & 0.4692 & 0.2646 \\\\ \\hline\n",
      " 4 & 0.3632 & 0.0545 & 3.0432 & 0.0731 & 7.4903 & 4.6551 & 0.2447 \\\\ \\hline\n",
      " 5 & 0.0066 & 0.0765 & 0.908  & 0.0638 & 7.5635 & 3.6308 & 0.2508 \\\\ \\hline\n",
      " 6 & 0.2621 & 0.1159 & 2.9838 & 0.0571 & 8.3918 & 0.7494 & 0.2569 \\\\ \\hline\n",
      " 7 & 0.0533 & 0.0133 & 2.8049 & 0.0466 & 8.3823 & 0.8254 & 0.2621 \\\\ \\hline\n",
      " 8 & 0.4367 & 0.0163 & 2.7354 & 0.0375 & 8.2752 & 2.5693 & 0.2642 \\\\ \\hline\n",
      " 9 & 0.0101 & 0.0204 & 2.6399 & 0.0285 & 8.2319 & 2.5099 & 0.2679 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test1(ar_coeff, a1, a2, H):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    n_obs = 10\n",
    "    # S = 12\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    # H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 10\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        # hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        # hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "\n",
    "    return g\n",
    "    # print(index_array)\n",
    "\n",
    "    # array = np.array(g)\n",
    "    # table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # # Split the table into lines\n",
    "    # lines = table.split('\\n')\n",
    "    \n",
    "    # # Insert \\hline after each row\n",
    "    # latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    # print(latex_table)\n",
    "\n",
    "    # EDR = EDR / n\n",
    "    # L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "\n",
    "    # print(g)\n",
    "    # print(L)\n",
    "    # print(EDR[0])\n",
    "    # print(edr_est)\n",
    "\n",
    "# Example usage\n",
    "S = 10\n",
    "nn = 5\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "for i in range(S):\n",
    "    g[i] = test1(ar_coeff, 2, 3, nn)[i]\n",
    "index_array = list(range(len(g)))\n",
    "for i in range(S):\n",
    "    g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))\n",
    "for n in range(nn, nn+60, 10):\n",
    "    h = test1(ar_coeff, 2, 3, nn)\n",
    "    for i in range(S):\n",
    "        g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "\n",
    "formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "# array = np.array(g)\n",
    "table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "\n",
    "# Split the table into lines\n",
    "lines = table.split('\\n')\n",
    "\n",
    "# Insert \\hline after each row\n",
    "latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1922b8d-b8cd-4ac7-81ab-046e50c89ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a6414-1cdf-45cf-91a7-8d4f58114617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d5bc6c-5816-40ba-be2f-a2c502237b04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## traverse number of replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37cb0639-69ef-4f02-81f3-ee4f775bd911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.011  & 0.0098 & 0.0148 & 0.0079 & 0.0293 & 0.0096 & 0.0125 & 0.0125 & 0.0283 \\\\ \\hline\n",
      " 1 & 0.0449 & 0.061  & 0.0762 & 0.0551 & 0.0811 & 0.0416 & 0.0636 & 0.0505 & 0.0861 \\\\ \\hline\n",
      " 2 & 0.0704 & 0.0694 & 0.0862 & 0.0659 & 0.094  & 0.0526 & 0.0718 & 0.06   & 0.0975 \\\\ \\hline\n",
      " 3 & 0.0894 & 0.0239 & 0.088  & 0.0686 & 0.0971 & 0.0531 & 0.0559 & 0.0617 & 0.0988 \\\\ \\hline\n",
      " 4 & 0.0788 & 0.0274 & 0.0881 & 0.0694 & 0.0975 & 0.0517 & 0.0572 & 0.0649 & 0.0984 \\\\ \\hline\n",
      " 5 & 0.1161 & 0.0273 & 0.0885 & 0.0702 & 0.0982 & 0.0498 & 0.0577 & 0.0662 & 0.098  \\\\ \\hline\n",
      " 6 & 0.0589 & 0.0263 & 0.0885 & 0.0711 & 0.0979 & 0.0496 & 0.0584 & 0.0677 & 0.0978 \\\\ \\hline\n",
      " 7 & 0.0695 & 0.0255 & 0.0884 & 0.0713 & 0.0975 & 0.0498 & 0.0583 & 0.0689 & 0.0977 \\\\ \\hline\n",
      " 8 & 0.0702 & 0.0255 & 0.0885 & 0.0714 & 0.097  & 0.0499 & 0.0586 & 0.0698 & 0.0975 \\\\ \\hline\n",
      " 9 & 0.0664 & 0.0252 & 0.0885 & 0.0715 & 0.0971 & 0.0499 & 0.0587 & 0.0698 & 0.0974 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test1(ar_coeff, a1, a2, n):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    n_obs = 20\n",
    "    # S = 12\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    # n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        # hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        # hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "\n",
    "    return g\n",
    "    # print(index_array)\n",
    "\n",
    "    # array = np.array(g)\n",
    "    # table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # # Split the table into lines\n",
    "    # lines = table.split('\\n')\n",
    "    \n",
    "    # # Insert \\hline after each row\n",
    "    # latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    # print(latex_table)\n",
    "\n",
    "    # EDR = EDR / n\n",
    "    # L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "\n",
    "    # print(g)\n",
    "    # print(L)\n",
    "    # print(EDR[0])\n",
    "    # print(edr_est)\n",
    "\n",
    "# Example usage\n",
    "S = 10\n",
    "nn = 50\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "for i in range(S):\n",
    "    g[i] = test1(ar_coeff, 2, 3, nn)[i]\n",
    "index_array = list(range(len(g)))\n",
    "for i in range(S):\n",
    "    g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))\n",
    "for n in range(nn, nn+80, 10):\n",
    "    h = test1(ar_coeff, 2, 3, nn)\n",
    "    for i in range(S):\n",
    "        g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "\n",
    "formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "# array = np.array(g)\n",
    "table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "\n",
    "# Split the table into lines\n",
    "lines = table.split('\\n')\n",
    "\n",
    "# Insert \\hline after each row\n",
    "latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54553e-2a3e-44ad-862a-cafa0c7f430f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beef31ea-eac9-4d88-9351-4e344ebd712e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## traverse number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff1d4852-1a0d-422e-8087-be47e4cb8055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrrrrrr}\n",
      "\\hline\n",
      " 0 & 0.0013 & 0.0043 & 0.0054 & 0.017  & 0.0366 & 0.0091 & 0.0136 & 0.024  & 0.0076 \\\\ \\hline\n",
      " 1 & 0.0264 & 0.0332 & 0.0274 & 0.0525 & 0.0002 & 0.0226 & 0.0415 & 0.0112 & 0.0275 \\\\ \\hline\n",
      " 2 & 0.0249 & 0.0362 & 0.0306 & 0.0563 & 0.0041 & 0.0247 & 0.0447 & 0.0157 & 0.0318 \\\\ \\hline\n",
      " 3 & 0.0711 & 0.0368 & 0.0314 & 0.0569 & 0.0049 & 0.0252 & 0.0454 & 0.0162 & 0.0325 \\\\ \\hline\n",
      " 4 & 0.0847 & 0.037  & 0.0316 & 0.057  & 0.0051 & 0.0253 & 0.0455 & 0.0163 & 0.0327 \\\\ \\hline\n",
      " 5 & 0.0572 & 0.037  & 0.0317 & 0.057  & 0.0052 & 0.0254 & 0.0456 & 0.0163 & 0.0327 \\\\ \\hline\n",
      " 6 & 0.064  & 0.037  & 0.0317 & 0.057  & 0.0052 & 0.0254 & 0.0456 & 0.0163 & 0.0327 \\\\ \\hline\n",
      " 7 & 0.0946 & 0.037  & 0.0318 & 0.057  & 0.0052 & 0.0254 & 0.0456 & 0.0163 & 0.0327 \\\\ \\hline\n",
      " 8 & 0.0196 & 0.037  & 0.0318 & 0.057  & 0.0052 & 0.0254 & 0.0456 & 0.0163 & 0.0327 \\\\ \\hline\n",
      " 9 & 0.0066 & 0.037  & 0.0318 & 0.057  & 0.0052 & 0.0254 & 0.0456 & 0.0163 & 0.0327 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "def test1(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    # S = 12\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 10\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] ,_ , M, Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ V1[a] @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum((phi[j] ** a) * (Q2[a] @ V1[a] @ np.linalg.inv(Q2[a]))[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "    \n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        # hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        # hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "\n",
    "    return g\n",
    "    # print(index_array)\n",
    "\n",
    "    # array = np.array(g)\n",
    "    # table = tabulate(array, tablefmt='latex_raw')\n",
    "    \n",
    "    # # Split the table into lines\n",
    "    # lines = table.split('\\n')\n",
    "    \n",
    "    # # Insert \\hline after each row\n",
    "    # latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    # print(latex_table)\n",
    "\n",
    "    # EDR = EDR / n\n",
    "    # L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "\n",
    "    # print(g)\n",
    "    # print(L)\n",
    "    # print(EDR[0])\n",
    "    # print(edr_est)\n",
    "\n",
    "# Example usage\n",
    "S = 10\n",
    "nn = 100\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "g = [np.zeros((1, 1)) for _ in range(S)]\n",
    "for i in range(S):\n",
    "    g[i] = test1(ar_coeff, 2, 3, nn)[i]\n",
    "index_array = list(range(len(g)))\n",
    "for i in range(S):\n",
    "    g[i] = np.vstack((np.array([[index_array[i]]]) ,g[i]))\n",
    "for n in range(nn, nn+800, 100):\n",
    "    h = test1(ar_coeff, 2, 3, nn)\n",
    "    for i in range(S):\n",
    "        g[i] = np.vstack((g[i], h[i].reshape(-1,1)))\n",
    "\n",
    "formatted_array = np.vectorize(lambda x: f\"{x:.4f}\")(g)\n",
    "# array = np.array(g)\n",
    "table = tabulate(formatted_array, tablefmt='latex_raw')\n",
    "\n",
    "# Split the table into lines\n",
    "lines = table.split('\\n')\n",
    "\n",
    "# Insert \\hline after each row\n",
    "latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cda701-7d50-4ea3-b9b5-088cbc3aa7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352a397-8fe9-4689-81c9-74ab3364520e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b844648-095f-4e15-a73a-993a069fe2c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Take sample covariance matrix by unwhitened X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a5293022-13db-4858-830f-b84aeceedb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.551862 & 0.804171 & 0.00834409 & -0.0261078 & 0.0195826  \\\\ \\hline\n",
      " 1 & 0.539692 & 0.795889 & 0.00613204 & -0.0412635 & 0.0114321  \\\\ \\hline\n",
      " 2 & 0.530437 & 0.786094 & 0.0053654  & -0.0479281 & 0.00810836 \\\\ \\hline\n",
      " 3 & 0.519903 & 0.758112 & 0.00749389 & -0.0371327 & 0.0191199  \\\\ \\hline\n",
      " 4 & 0.515066 & 0.752194 & 0.00796879 & -0.0370938 & 0.0180847  \\\\ \\hline\n",
      " 5 & 0.51197  & 0.737299 & 0.00777171 & -0.0528522 & 0.0277184  \\\\ \\hline\n",
      " 6 & 0.509376 & 0.734327 & 0.00798675 & -0.0533566 & 0.0269965  \\\\ \\hline\n",
      " 7 & 0.507718 & 0.732136 & 0.00810177 & -0.0544358 & 0.0268082  \\\\ \\hline\n",
      " 8 & 0.5069   & 0.730752 & 0.00796889 & -0.0558828 & 0.0270028  \\\\ \\hline\n",
      " 9 & 0.506369 & 0.729526 & 0.00773089 & -0.0576772 & 0.0274406  \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.07832799413471236\n",
      "[ 0.5708818   0.76628979 -0.00510866 -0.00327897]\n",
      "[[ 0.46083377]\n",
      " [ 0.83782069]\n",
      " [ 0.18676375]\n",
      " [-0.22540639]]\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def test2(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    # n_obs = 10\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 100\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] , M , _ , Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                edr[0] = np.linalg.inv(np.cov(X.T)) @ edr[0]\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (V1[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            # edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            edr_est = np.linalg.inv(np.cov(X.T)) @ K_largest_eigenvectors \n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            # hat[q - 1] += edr_est\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "\n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "\n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "    # print(g)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "    print(edr_est)\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.3, 0.5, 0.8]\n",
    "test2(ar_coeff, 2, 3, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97af4e8-0f87-45a2-912e-aa93ba9e4b85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# By multiplying uniform Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f36792-6af7-4b41-bd06-82ff32bc1c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\hline\n",
      " 0 & 0.351463 & -0.0469681 & -0.00647294 & -0.00410173 & 7.9116  \\\\ \\hline\n",
      " 1 & 0.336751 & -0.0474621 & -0.00683192 & -0.0050314  & 7.52373 \\\\ \\hline\n",
      " 2 & 0.335613 & -0.0474905 & -0.00683665 & -0.00525159 & 7.49551 \\\\ \\hline\n",
      " 3 & 0.335512 & -0.0474907 & -0.00684354 & -0.00534694 & 7.49337 \\\\ \\hline\n",
      " 4 & 0.335501 & -0.0474909 & -0.00684341 & -0.00541173 & 7.49309 \\\\ \\hline\n",
      " 5 & 0.335498 & -0.0474914 & -0.00684392 & -0.00543649 & 7.49297 \\\\ \\hline\n",
      " 6 & 0.335497 & -0.047492  & -0.00684429 & -0.00544617 & 7.49285 \\\\ \\hline\n",
      " 7 & 0.335496 & -0.0474925 & -0.00684415 & -0.00545523 & 7.49276 \\\\ \\hline\n",
      " 8 & 0.335496 & -0.047493  & -0.00684432 & -0.00545868 & 7.49268 \\\\ \\hline\n",
      " 9 & 0.335496 & -0.0474932 & -0.00684451 & -0.00546024 & 7.49264 \\\\ \\hline\n",
      "\\hline \\hline\n",
      "\\end{tabular} \\hline\n",
      "0.0008008700502919464\n",
      "[3.93228047e-01 9.19249909e-01 1.04862632e-04 2.88912916e-03]\n",
      "[[ 0.33155318]\n",
      " [ 0.94220931]\n",
      " [-0.02378119]\n",
      " [-0.04181567]]\n"
     ]
    }
   ],
   "source": [
    "#from 0 to Q double sum\n",
    "#2 * ar_series[0][t]/(5 * ar_series[1][t] + 1)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def test3(ar_coeff, a1, a2, n_obs):\n",
    "    import numpy as np\n",
    "    from tabulate import tabulate\n",
    "    num_N = 5\n",
    "    S = 10\n",
    "    noise = np.zeros((num_N, n_obs+S))\n",
    "    H = 5\n",
    "    P = 4\n",
    "    K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "    hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    g = np.zeros((S, 1))\n",
    "    n1 = 0\n",
    "    l = 1  \n",
    "    n = 40\n",
    "    edr = np.zeros((S+1, P))\n",
    "    EDR = np.zeros((1, P))\n",
    "    while n1 < n:\n",
    "        for h in range(num_N):\n",
    "            noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "        ar_series = np.zeros((num_N, n_obs+S))\n",
    "        for t in range(0, n_obs+S):\n",
    "            ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "            ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "            ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "            ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "            ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise[4][t]\n",
    "        for a in range(0, S+1):\n",
    "            y[a] = ar_series[4][a:n_obs+a]\n",
    "        X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "        V1 = []\n",
    "        Q2 = []\n",
    "        for a in range(0, S + 1):\n",
    "            edr[a] , M , _ , Q1 = sir_modified1(X, y[a], H, K)\n",
    "            if a == 0:\n",
    "                if edr[0][0]<0:\n",
    "                    edr[0] = -edr[0]\n",
    "                edr[0] = edr[0]/np.linalg.norm(edr[0])\n",
    "                EDR += edr[0]\n",
    "            V1.append(M)\n",
    "            Q2.append(Q1)\n",
    "        for q in range(1, S + 1):\n",
    "            Q3 = np.zeros((P, P))\n",
    "            phi = ar_coeff\n",
    "            for j in range(P):\n",
    "                for k in range(P):\n",
    "                    #transform back to find V_hat\n",
    "                    Q3[j, k] = sum((phi[j] ** a) * (V1[a])[j, k] * (phi[k] ** a) for a in range(0, q))\n",
    "                    # Q3[j, k] = sum(sum((phi[j] ** a) * (np.linalg.inv(Q2[a]) @ np.linalg.inv(Q2[a]) @ V1[a] @ (np.linalg.inv(Q2[a])).T @ Q2[a])[j, k] * (phi[k] ** a) for a in range(0, l)) for l in range(1, q + 1))\n",
    "            #Q2[a] @ V[a] @ Q2[a].T by sample covariance matrix\n",
    "            eigenvalues1, eigenvectors1 = np.linalg.eig(Q3)\n",
    "            edr_est = solve_triangular(Q2[0], eigenvectors1)\n",
    "            K_index = np.argpartition(np.abs(eigenvalues1), P - K) >= P - K\n",
    "            # # K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            # K_largest_eigenvectors = eigenvectors1[:, K_index]\n",
    "            K_largest_eigenvectors = edr_est[:, K_index]\n",
    "            #multiply R after that\n",
    "            edr_est = K_largest_eigenvectors\n",
    "            if edr_est[0] < 0:\n",
    "                edr_est = -edr_est\n",
    "            edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "            hat[q - 1] += np.real(edr_est)\n",
    "        n1 += 1\n",
    "\n",
    "    index_array = list(range(len(hat)))\n",
    "    \n",
    "    for i in range(S):\n",
    "        hat[i] = hat[i] / n\n",
    "        g[i] = abs(hat[i][0] / hat[i][1] - a1/a2)\n",
    "        hat[i] = np.vstack((hat[i], g[i].reshape(1,-1)))\n",
    "        hat[i] = np.vstack((np.array([[index_array[i]]]), hat[i]))\n",
    "    \n",
    "    # print(index_array)\n",
    "    array = np.array(hat)\n",
    "    table = tabulate(array, tablefmt='latex_raw')\n",
    "\n",
    "    # Split the table into lines\n",
    "    lines = table.split('\\n')\n",
    "    \n",
    "    # Insert \\hline after each row\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    \n",
    "    print(latex_table)\n",
    "    EDR = EDR / n\n",
    "    L = abs(EDR[0][0] / EDR[0][1] - a1/a2)\n",
    "    # array = np.array(hat)\n",
    "    # print(tabulate(array, tablefmt='latex'))\n",
    "    # print(g)\n",
    "    print(L)\n",
    "    print(EDR[0])\n",
    "    print(edr_est)\n",
    "# Example usage\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "test3(ar_coeff, 3, 7, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb7558-5136-4318-9f9e-e08ce4e07715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X - np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba681869-4f28-448f-b460-690a947bcbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260266c3-bcd4-40b7-a542-cca06a7bdbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ff7fbd-3ffb-4ded-aaa9-d7ba9d7e645f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Checking if the covariance relationship exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025f7fc4-7438-4173-816b-88d65f3d2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.14440926,  7.05865946, -0.43096876, -2.5844906 ],\n",
       "       [ 0.        , 14.03190128, -1.5150993 , -9.67387158],\n",
       "       [ 0.        ,  0.        ,  1.74528559, -0.79628651],\n",
       "       [ 0.        ,  0.        ,  0.        ,  5.52303073]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "ar_coeff = [0.2, 0.5, 0.5, 0.8]\n",
    "num_N = 5\n",
    "n_obs = 10\n",
    "S = 10\n",
    "noise = np.zeros((num_N, n_obs+S))\n",
    "H = 5\n",
    "P = 4\n",
    "K = 1\n",
    "y = [np.zeros((num_N, n_obs+i)) for i in range(S+1)]\n",
    "hat = [np.zeros((P, 1)) for _ in range(S)]\n",
    "g = np.zeros((S, 1))\n",
    "n1 = 0\n",
    "l = 1  \n",
    "n = 100\n",
    "edr = np.zeros((S+1, P))\n",
    "EDR = np.zeros((1, P))\n",
    "\n",
    "for h in range(num_N):\n",
    "    noise[h] = np.random.normal(0, 1, size=(n_obs+S))  # Normally distributed noise\n",
    "ar_series = np.zeros((num_N, n_obs+S))\n",
    "for t in range(0, n_obs+S):\n",
    "    ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise[0][t]\n",
    "    ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise[1][t]\n",
    "    ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise[2][t]\n",
    "    ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise[3][t]\n",
    "    ar_series[4][t] = 2 * ar_series[0][t] + 3 * ar_series[1][t] + noise[4][t]\n",
    "for a in range(0, S+1):\n",
    "    y[a] = ar_series[4][a:n_obs+a]\n",
    "X = np.concatenate([ar_series[i][0:n_obs].reshape(-1, 1) for i in range(4)], axis=1)\n",
    "\n",
    "X1 = X - np.mean(X, axis=0)\n",
    "#reduced QR decomposition\n",
    "Q, R = np.linalg.qr(X1)\n",
    "\n",
    "R @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e20e7-3dc5-42d6-a9be-f66cb796f9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fa41d7-e0a3-4631-9043-c8355d986fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(R @ R).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab25ce4f-143d-4cc3-bec8-5f9053f1d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X.T).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882f8ab8-9432-4078-bcd4-f84949375491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33069085,  0.09204591,  0.01396628,  0.03964654],\n",
       "       [-0.        , -0.26695726, -0.06042237, -0.18704795],\n",
       "       [-0.        , -0.        , -0.75694922, -0.06986162],\n",
       "       [-0.        , -0.        , -0.        , -0.42551147]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e257e71d-f40b-447c-864e-a842e933b2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.02397243,  0.        ,  0.        ,  0.        ],\n",
       "       [-1.04265491, -3.74591795,  0.        ,  0.        ],\n",
       "       [ 0.02743387,  0.29901246, -1.32109257,  0.        ],\n",
       "       [ 0.17207493,  1.5975522 ,  0.21690056, -2.35011292]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f97c56-1d8a-4ff9-98a2-e818624dcaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.14440926,  3.15295971, -0.08295927, -0.52034985],\n",
       "       [ 3.15295971, 15.11903055, -1.14868021, -6.16371425],\n",
       "       [-0.08295927, -1.14868021,  1.83544666,  0.19586299],\n",
       "       [-0.52034985, -6.16371425,  0.19586299,  8.15185941]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.T @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "327d01d1-1a85-4eee-b6b0-7cce8e9a41fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.2783443 , -0.04223364, -0.11989003],\n",
       "       [ 0.34479643,  0.90402788,  0.21177524,  0.65932863],\n",
       "       [-0.00907213, -0.07729837,  0.98231611,  0.03745166],\n",
       "       [-0.0569036 , -0.41063937, -0.25830736,  0.69285028]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.T @ np.linalg.inv(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e857e015-e49e-4d66-92df-ff771603552a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  3.46944695e-18,\n",
       "         2.77555756e-17],\n",
       "       [ 0.00000000e+00,  1.00000000e+00, -1.38777878e-17,\n",
       "        -5.55111512e-17],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        -2.77555756e-17],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(R) @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f196bd71-dcea-4dc9-943d-998538239247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00914441,  0.00705866, -0.00043097, -0.00258449],\n",
       "       [ 0.        ,  0.0140319 , -0.0015151 , -0.00967387],\n",
       "       [ 0.        ,  0.        ,  0.00174529, -0.00079629],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.00552303]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R @ R/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3c82c5e-9716-4020-875d-cae2e073c3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.14440926,  3.15295971, -0.08295927, -0.52034985],\n",
       "       [ 3.15295971, 15.11903055, -1.14868021, -6.16371425],\n",
       "       [-0.08295927, -1.14868021,  1.83544666,  0.19586299],\n",
       "       [-0.52034985, -6.16371425,  0.19586299,  8.15185941]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.T @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee421e44-868c-460a-a766-5e3355a17135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53acfd-e68d-4760-a57b-aa22ffe7d4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24d60c-0d96-462d-9b88-a96980560a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc4178-e693-41b0-b2b7-7bc96e5c7bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcbaf7c-ae4d-4ac3-8e6d-5dc31801e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the step size and the range\n",
    "step_size = 1\n",
    "range_values = [round(i * step_size, 1) for i in range(int(1/step_size) + 1)]\n",
    "\n",
    "# Generate all possible combinations\n",
    "grid_points = list(itertools.product(range_values, repeat=4))\n",
    "\n",
    "# Display the result\n",
    "for point in grid_points:\n",
    "    test2(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed765e37-6c41-458a-bffa-d1cd73d71aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b6f75-bdcf-4cdf-a39b-d9c58f7ff9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
