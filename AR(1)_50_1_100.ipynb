{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9202e598-ba91-40e9-be49-b95075098898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = (X_means - np.mean(X, axis=0))\n",
    "    # X_centered = (X_means - np.mean(X, axis=0))/np.linalg.norm(X_means - np.mean(X, axis=0))\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dde3d71-cbac-4093-8d94-99a8bd6fbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "def ave(arr, N):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i]/N \n",
    "    return arr \n",
    "def compute_eigen(Q4, P, K):\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(Q4)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues2), P - K) >= P - K\n",
    "    K_largest_eigenvectors = eigenvectors2[:, K_index]\n",
    "    edr_est = K_largest_eigenvectors  \n",
    "    if edr_est[0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    return edr_est    \n",
    "def proj(edr_est): \n",
    "    E = edr_est @ np.linalg.inv(edr_est.T @ edr_est) @ edr_est.T\n",
    "    return E\n",
    "def exhi(obj1):        \n",
    "    array1 = np.vectorize(lambda x: f\"{x:.6f}\")(obj1)\n",
    "    table = tabulate(array1, tablefmt='latex_raw')\n",
    "    lines = table.split('\\n')\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    print(latex_table)\n",
    "def MSE(X, y):\n",
    "    Mse = 0\n",
    "    # Split using time series cross-validation (e.g., 5 splits)\n",
    "    train_window = int(np.round(0.75 * len(X),0))  # Fixed size of training set (e.g., 75 time steps)\n",
    "    test_window = 1   # Fixed size of test set (e.g., 25 time steps)\n",
    "    # Sliding window cross-validation\n",
    "    for i in range(0, len(X) - train_window - test_window + 1):\n",
    "        X_train = X[i:i + train_window]\n",
    "        y_train = y[i:i + train_window]\n",
    "        X_test = X[i + train_window:i + train_window + test_window]\n",
    "        y_test = y[i + train_window:i + train_window + test_window]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate errors\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        Mse += mse \n",
    "    Mse = Mse/(len(X) - train_window - test_window)\n",
    "    return np.sqrt(Mse)    \n",
    "def optimal_values(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    return smallest   \n",
    "def optimal_Q(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == smallest:\n",
    "            return i # Return the first matched index\n",
    "    return -1\n",
    "def plotyy(x, li1, li2, li3, label1 ,label2 ,label3, title, xlabel, ylabel):\n",
    "    plt.plot(x, li1, label = label1, color='blue', marker='o', linestyle='--', alpha = 0.5)\n",
    "    plt.plot(x, li2, label = label2, color='red', marker='^', linestyle='-.', alpha = 0.7)\n",
    "    plt.plot(x, li3, label = label3, color='black', marker='s', alpha = 0.3)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.ylim(0, 9)\n",
    "    # plt.yticks(np.arange(-2, 3, 1))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()    \n",
    "def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep):\n",
    "    num_N = 5;P = 4;K = 1 \n",
    "    noise1 = np.zeros((num_N, n_gene))\n",
    "    noise2 = np.zeros((num_N, (n_rep+1)*n_obs+10*n_rep+n_rep*S))\n",
    "    for h in range(num_N):\n",
    "        noise1[h] = np.random.normal(0, sigma, size=(n_gene)) \n",
    "        noise2[h] = np.random.normal(0, sigma, size=((n_rep+1)*n_obs+10*n_rep+n_rep*S))\n",
    "    ar_series = np.zeros((num_N, (n_rep + 1)*n_obs+10*n_rep+n_rep*S+1))\n",
    "    for i in range(num_N):\n",
    "        ar_series[i][0] = initial_value  \n",
    "    AR1 = initial_value\n",
    "    AR2 = initial_value\n",
    "    AR3 = initial_value\n",
    "    AR4 = initial_value\n",
    "    for t in range(1, n_gene + 1):\n",
    "        AR1 = ar_coeff[0] * AR1 + noise1[0][t-1]\n",
    "        AR2 = ar_coeff[1] * AR2 + noise1[1][t-1]\n",
    "        AR3 = ar_coeff[2] * AR3 + noise1[2][t-1]\n",
    "        AR4 = ar_coeff[3] * AR4 + noise1[3][t-1]\n",
    "    ar_series[0][0] = AR1 \n",
    "    ar_series[1][0] = AR2 \n",
    "    ar_series[2][0] = AR3 \n",
    "    ar_series[3][0] = AR4 \n",
    "    # Generation of AR data\n",
    "    for t in range((n_rep+1)*n_obs+10*n_rep+n_rep*S+1): \n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise2[0][t - 1]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise2[1][t - 1]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise2[2][t - 1]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise2[3][t - 1]\n",
    "        ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise2[4][t - 1]\n",
    "    n = 0\n",
    "    t_start = 0\n",
    "    t_end = n_obs + S + 1\n",
    "    while n < n_rep:\n",
    "        df = pd.DataFrame(ar_series[:, t_start:  t_end])\n",
    "        path = fr'C:\\Users\\yhuang73\\Desktop\\experiments_{n_obs}_{sigma}_{n_rep}\\datatest_{ar_coeff[2]}\\array_data_numberofsamples{n_obs}_replicas{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx'\n",
    "        df.to_excel(path, index=False, header=False)\n",
    "        t_start += n_obs + 10 \n",
    "        t_end += n_obs + 10\n",
    "        n += 1\n",
    "def Calculation(ar_series_xlsx, ar_coeff, H, S, n):\n",
    "    num_N = 5;P = 4;K = 1\n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S)]\n",
    "    X1 = [[np.zeros((num_N, n_obs)) for i in range(P)] for i in range(S)]\n",
    "    obj_1 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    obj_2 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "    proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "    error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "    error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "    projection_1_norm = np.zeros((S, 1))\n",
    "    projection_2_norm = np.zeros((S, 1))\n",
    "    True_projection = np.array([[2],[3],[0],[0]])/((np.linalg.norm(np.array([[2],[3],[0],[0]]))))\n",
    "    obj_2_avevec = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    obj2_ave = np.zeros((P, 1))\n",
    "    error_11 = 0\n",
    "    prediction_mse_11 = 0\n",
    "    proj_error_11 = 0\n",
    "    df = pd.read_excel(ar_series_xlsx, header=None)\n",
    "    ar_series = df.to_numpy()\n",
    "    for a in range(0, S):\n",
    "        y[a] = ar_series[4][a:n_obs+a]\n",
    "        X1[a] = np.concatenate([ar_series[i][a:n_obs+a].reshape(-1, 1) for i in range(P)], axis = 1)\n",
    "    X = X1[0]\n",
    "    edr_est1, M1 = sir_11(X, y[0], H, K)\n",
    "    edr_est1 = compute_eigen(np.linalg.inv(np.cov(X.T)) @ M1 @ np.linalg.inv(np.cov(X.T)), P, K)\n",
    "    if edr_est1[0] < 0:\n",
    "        edr_est1 = -edr_est1\n",
    "    edr_est1 = np.real(edr_est1 / np.linalg.norm(edr_est1))\n",
    "    error_11 += abs(edr_est1[0] / edr_est1[1] - a1/a2)\n",
    "    prediction_mse_11 += MSE(X @ edr_est1, y[0]) \n",
    "    proj_error_11 += np.linalg.norm((proj(edr_est1) - proj(True_projection)), 'fro')**2\n",
    "    V1 = []\n",
    "    for a in range(0, S):\n",
    "        _, M = sir_11(X, y[a], H, K)\n",
    "        V1.append(M)\n",
    "    # objective 1: experiment\n",
    "    for q in range(0, S):\n",
    "        phi = ar_coeff\n",
    "        Q3 = np.zeros((P, P))\n",
    "        for j in range(P):\n",
    "            for k in range(P):\n",
    "                Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(np.cov(X.T)) @ V1[a] @ np.linalg.inv(np.cov(X.T)))[j, k] * (phi[k] ** a) for a in range(0, q + 1))\n",
    "        edr_est = compute_eigen(Q3, P, K)\n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        error_1[q] += abs(edr_est[0] / edr_est[1] - a1/a2)\n",
    "        prediction_mse_1[q] += MSE(X @ edr_est, y[0]) \n",
    "        proj_error_1[q] += np.linalg.norm((proj(edr_est) - proj(True_projection)), 'fro')**2      \n",
    "    # objective 2: experiment\n",
    "    for q in range(0, S):\n",
    "        Q4 = np.linalg.inv(np.cov(X1[q].T)) @ V1[q] @ np.linalg.inv(np.cov(X1[q].T))   # multiply np.linalg.inv(np.cov(X1[q].T)), by stationarity, it should cause no influence.\n",
    "        # Q3 = np.linalg.inv(np.cov(X.T)) @ V1[q] @ np.linalg.inv(np.cov(X.T)), if we multiply np.linalg.inv(np.cov(X.T)) like this line, result for q = 0 should be the same.   \n",
    "        K_largest_eigenvectors = compute_eigen(Q4, P, K)\n",
    "        edr_est = np.multiply(np.power(ar_coeff, -q), K_largest_eigenvectors.flatten())   \n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        obj_2[q] += edr_est.reshape(-1, 1)       \n",
    "    # Average among lags Q\n",
    "    for j in range(S):\n",
    "        for i in range(j, S, 1):\n",
    "            obj_2_avevec[i] += obj_2[j]\n",
    "    for j in range(S):\n",
    "        obj_2_avevec[j] = ave(obj_2_avevec[j], j + 1)\n",
    "    for q in range(0, S):\n",
    "        error_2[q] += abs(obj_2_avevec[q][0] / obj_2_avevec[q][1] - a1/a2)\n",
    "        prediction_mse_2[q] += MSE(X @ obj_2_avevec[q], y[0])\n",
    "        proj_error_2[q] += np.linalg.norm((proj(obj_2_avevec[q]) - proj(True_projection)), 'fro')**2    \n",
    "    return error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2\n",
    "def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "    num_N = 5;P = 4;K = 1\n",
    "    error_1 = ave(error_1, n_rep)    \n",
    "    error_2 = ave(error_2, n_rep)\n",
    "    prediction_mse_1 = ave(prediction_mse_1, n_rep)\n",
    "    prediction_mse_2 = ave(prediction_mse_2, n_rep)\n",
    "    proj_error_1 = ave(proj_error_1, n_rep)\n",
    "    proj_error_2 = ave(proj_error_2, n_rep)\n",
    "    index_array = list(range(S))\n",
    "    SIR_values = [error_1[0], prediction_mse_1[0], proj_error_1[0]]\n",
    "    Obj1_optimal_values = [optimal_values(error_1), optimal_values(prediction_mse_1), optimal_values(proj_error_1)]\n",
    "    Obj2_optimal_values = [optimal_values(error_2), optimal_values(prediction_mse_2), optimal_values(proj_error_2)]\n",
    "    Obj1_optimal_Q = [optimal_Q(error_1),optimal_Q(prediction_mse_1),optimal_Q(proj_error_1)]\n",
    "    Obj2_optimal_Q = [optimal_Q(error_2),optimal_Q(prediction_mse_2),optimal_Q(proj_error_2)]\n",
    "    return SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q\n",
    "def Graph(n_obs, sigma, H, S, n_rep):\n",
    "    for k in np.arange(0.1, 1.0, 0.1):\n",
    "        for i in np.arange(0.1, 1.0, 0.1):\n",
    "            for l in np.arange(0.1, 1.0, 0.1):\n",
    "                sir_values = [[], [], []]\n",
    "                obj1_optimal_values = [[], [], []]\n",
    "                obj2_optimal_values = [[], [], []]\n",
    "                obj1_optimal_Q = [[],[],[]]\n",
    "                obj2_optimal_Q = [[],[],[]]\n",
    "                for h in np.arange(0.1, 1.0, 0.1):\n",
    "                    Prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "                    Prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "                    Proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "                    Proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "                    Error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "                    Error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "                    ar_coeff = [round(val, 1) for val in [h, i, l, k]]\n",
    "                    for n in range(n_rep):\n",
    "                        filepath = fr'C:\\Users\\yhuang73\\Desktop\\experiments_{n_obs}_{sigma}_{n_rep}\\datatest_{l}\\array_data_numberofsamples{n_obs}_replicas{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx'\n",
    "                        error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 = Calculation(filepath, ar_coeff, H, S, n)    \n",
    "                        for s in range(S):\n",
    "                            Error_1[s] += error_1[s]\n",
    "                            Prediction_mse_1[s] += prediction_mse_1[s]\n",
    "                            Proj_error_1[s] += proj_error_1[s]\n",
    "                            Error_2[s] += error_2[s]\n",
    "                            Prediction_mse_2[s] += prediction_mse_2[s]\n",
    "                            Proj_error_2[s] += proj_error_2[s]\n",
    "                    SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q = Evaluation(Error_1, Prediction_mse_1, Proj_error_1, Error_2, Prediction_mse_2, Proj_error_2, H, S, n_rep)\n",
    "                    for j in range(3):\n",
    "                        sir_values[j].append(SIR_values[j])\n",
    "                        obj1_optimal_values[j].append(Obj1_optimal_values[j])\n",
    "                        obj2_optimal_values[j].append(Obj2_optimal_values[j])\n",
    "                        obj1_optimal_Q[j].append(Obj1_optimal_Q[j])\n",
    "                        obj2_optimal_Q[j].append(Obj2_optimal_Q[j]) \n",
    "                        if j == 1:\n",
    "                            sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                            obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                            obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "                        if j == 2:\n",
    "                            sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                            obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                            obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                # Subplot 1 (1 row, 2 columns, 1st plot)\n",
    "                plt.subplot(2, 3, 1)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), sir_values[0], obj1_optimal_values[0], obj2_optimal_values[0],'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal Absolute error')\n",
    "                # Subplot 2 (1 row, 2 columns, 2nd plot)\n",
    "                plt.subplot(2, 3, 2)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), sir_values[1], obj1_optimal_values[1], obj2_optimal_values[1], 'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal MSE')\n",
    "                plt.subplot(2, 3, 3)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), sir_values[2], obj1_optimal_values[2], obj2_optimal_values[2], 'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal Risk')\n",
    "                plt.subplot(2, 3, 4)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), [0 for _ in range(9)], obj1_optimal_Q[0], obj2_optimal_Q[0],'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal lag Q for Absolute error')\n",
    "                plt.subplot(2, 3, 5)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), [0 for _ in range(9)], obj1_optimal_Q[1], obj2_optimal_Q[1], 'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal lag Q for MSE')                \n",
    "                plt.subplot(2, 3, 6)\n",
    "                plotyy(np.arange(0.1, 1.0, 0.1), [0 for _ in range(9)], obj1_optimal_Q[2], obj2_optimal_Q[2], 'SIR', 'Model 1','Model 2' ,'' , 'from 0.1 to 0.9, step size 0.1', 'Optimal lag Q for Risk')\n",
    "                plt.savefig(fr'C:\\Users\\yhuang73\\Desktop\\experiments_{n_obs}_{sigma}_{n_rep}\\figuretest_{l}\\arcoeff{\"_\".join(map(str, [ round(val, 1) for val in [i,l,k] ]))}.png', format='png')\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa6eec-b904-432f-9f3f-2755a1897fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def Removefiles(folder_path):\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # Removes directory and contents            \n",
    "a1=2; a2=3; initial_value = 0; n_gene = 1000; n_obs = 50; H = 5; S=10; sigma = 1; n_rep = 100\n",
    "larger_folder = fr'C:\\Users\\yhuang73\\Desktop\\experiments_{n_obs}_{sigma}_{n_rep}'\n",
    "# Create the larger folder if it doesn't exist\n",
    "os.makedirs(larger_folder, exist_ok=True)\n",
    "# Create subfolders iteratively inside the larger folder\n",
    "for l in np.arange(0.1, 1.0, 0.1):\n",
    "    subfolder1 = os.path.join(larger_folder, f'figuretest_{round(l, 1)}')\n",
    "    subfolder2 = os.path.join(larger_folder, f'datatest_{round(l, 1)}')\n",
    "    os.makedirs(subfolder1, exist_ok=True)\n",
    "    os.makedirs(subfolder2, exist_ok=True)\n",
    "arr = []\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    for j in np.arange(0.1, 1.0, 0.1):\n",
    "        for l in np.arange(0.1, 1.0, 0.1):\n",
    "            for k in np.arange(0.1, 1.0, 0.1):\n",
    "                arr.append([i, j, l, k])       \n",
    "for index in range(len(arr)):\n",
    "    arr[index] = [round(val, 1) for val in arr[index]] \n",
    "for ar_coeff in arr:\n",
    "    Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39a9d1-a140-4483-bfe7-f376078ab848",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=2; a2=3; initial_value = 0; n_gene = 1000; n_obs = 50; H = 5; S=10; sigma = 1; n_rep = 100\n",
    "Graph(n_obs, sigma, H, S, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc7c0e-c3cd-4066-9b68-7e5c3c293b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c974a8d-cf5f-4e38-a9d1-59a5c650273c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b35ebf-9f3d-4231-93fe-845e2355febe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
