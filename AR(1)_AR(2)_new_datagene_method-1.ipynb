{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9202e598-ba91-40e9-be49-b95075098898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_11(X, y, num_slices, K):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    n_samples, n_features = X.shape\n",
    "    V_hat = np.zeros([X.shape[1], X.shape[1]])\n",
    "    # Step 1: Sort the data by the response variable\n",
    "    sorted_indices = np.argsort(y)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    # Step 2: Divide the data into slices\n",
    "    slice_size = n_samples // num_slices\n",
    "    ph_hat = slice_size/n_samples\n",
    "    slices = []\n",
    "    for i in range(num_slices):\n",
    "        start_idx = i * slice_size\n",
    "        if i < num_slices - 1:\n",
    "            end_idx = (i + 1) * slice_size\n",
    "        else:  # Last slice includes any remaining samples\n",
    "            end_idx = n_samples\n",
    "        slices.append((X_sorted[start_idx:end_idx], y_sorted[start_idx:end_idx]))\n",
    "    # Step 3: Compute the means of the predictors within each slice\n",
    "    X_means = np.array([np.mean(slice_X, axis=0) for slice_X, _ in slices])\n",
    "    # Step 4: Center the predictor means\n",
    "    X_centered = (X_means - np.mean(X, axis=0))\n",
    "    # X_centered = (X_means - np.mean(X, axis=0))/np.linalg.norm(X_means - np.mean(X, axis=0))\n",
    "    V_hat = np.add(V_hat,ph_hat * np.matmul(X_centered.T, X_centered))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(V_hat)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues), X.shape[1]-K) >= X.shape[1]-K\n",
    "    K_largest_eigenvectors = eigenvectors[:, K_index]\n",
    "    edr_est =  K_largest_eigenvectors\n",
    "    return edr_est, V_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dde3d71-cbac-4093-8d94-99a8bd6fbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "\n",
    "def ave(arr, N):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i]/N \n",
    "    return arr \n",
    "def compute_eigen(Q4, P, K):\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(Q4)\n",
    "    K_index = np.argpartition(np.abs(eigenvalues2), P - K) >= P - K\n",
    "    K_largest_eigenvectors = eigenvectors2[:, K_index]\n",
    "    edr_est = K_largest_eigenvectors  \n",
    "    if edr_est[0] < 0:\n",
    "        edr_est = -edr_est\n",
    "    edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "    return edr_est    \n",
    "def proj(edr_est): \n",
    "    E = edr_est @ np.linalg.inv(edr_est.T @ edr_est) @ edr_est.T\n",
    "    return E\n",
    "def exhi(obj1):        \n",
    "    array1 = np.vectorize(lambda x: f\"{x:.6f}\")(obj1)\n",
    "    table = tabulate(array1, tablefmt='latex_raw')\n",
    "    lines = table.split('\\n')\n",
    "    latex_table = '\\n'.join([line + (' \\\\hline' if (idx > 1) else '') for idx, line in enumerate(lines)])\n",
    "    print(latex_table)    \n",
    "\n",
    "def MSE(X, y):\n",
    "    Mse = 0\n",
    "    # Split using time series cross-validation (e.g., 5 splits)\n",
    "    train_window = int(np.round(0.75 * len(X),0))  # Fixed size of training set (e.g., 75 time steps)\n",
    "    test_window = 1   # Fixed size of test set (e.g., 25 time steps)\n",
    "    # Sliding window cross-validation\n",
    "    for i in range(0, len(X) - train_window - test_window + 1):\n",
    "        X_train = X[i:i + train_window]\n",
    "        y_train = y[i:i + train_window]\n",
    "        X_test = X[i + train_window:i + train_window + test_window]\n",
    "        y_test = y[i + train_window:i + train_window + test_window]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate errors\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        Mse += mse \n",
    "    Mse = Mse/(len(X) - train_window - test_window)\n",
    "    return np.sqrt(Mse)\n",
    "    \n",
    "def optimal_values(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    return smallest   \n",
    "def optimal_Q(arr):\n",
    "    if len(arr) == 0:\n",
    "        return None  # Handle the case of an empty array\n",
    "    smallest = arr[0]  # Assume the first element is the smallest\n",
    "    for num in arr:\n",
    "        if num < smallest:\n",
    "            smallest = num\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == smallest:\n",
    "            return i # Return the first matched index\n",
    "    return -1\n",
    "def plotyy(x, li1, li2, li3, label1 ,label2 ,label3, title, xlabel, ylabel):\n",
    "    # plt.plot(x, obj1_optimal_values, label= label_variable, color='blue', marker='o')\n",
    "    plt.plot(x, li1, label = label1, color='blue', marker='o', linestyle='--')\n",
    "    plt.plot(x, li2, label = label2, color='red', marker='^', linestyle='-.')\n",
    "    plt.plot(x, li3, label = label3, color='black', marker='s')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "\n",
    "def plotyy1(x, li1, li2, li3, li4, li5, li6, label1 ,label2 ,label3, title_1, xlabel_1, ylabel_1, title_2, xlabel_2, ylabel_2):\n",
    "    # plt.plot(x, obj1_optimal_values, label= label_variable, color='blue', marker='o')\n",
    "    plt.plot(x, li1, label = label1, color='blue', marker='o', linestyle='--')\n",
    "    plt.plot(x, li2, label = label2, color='red', marker='^', linestyle='-.')\n",
    "    plt.plot(x, li3, label = label3, color='black', marker='s')\n",
    "    plt.title(title_1)\n",
    "    plt.xlabel(xlabel_1)\n",
    "    plt.ylabel(ylabel_1)\n",
    "    plt.legend()\n",
    "    plt.plot(x, li1, label = label1, color='blue', marker='o', linestyle='--')\n",
    "    plt.plot(x, li2, label = label2, color='red', marker='^', linestyle='-.')\n",
    "    plt.plot(x, li3, label = label3, color='black', marker='s')\n",
    "    plt.title(title_2)\n",
    "    plt.xlabel(xlabel_2)\n",
    "    plt.ylabel(ylabel_2)\n",
    "    plt.legend()\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep):\n",
    "    num_N = 5;P = 4;K = 1;l = 1 \n",
    "    noise1 = np.zeros((num_N, n_gene))\n",
    "    noise2 = np.zeros((num_N, (n_rep+1)*n_obs+10*n_rep+n_rep*S))\n",
    "    for h in range(num_N):\n",
    "        noise1[h] = np.random.normal(0, sigma, size=(n_gene)) \n",
    "        noise2[h] = np.random.normal(0, sigma, size=((n_rep+1)*n_obs+10*n_rep+n_rep*S))\n",
    "    ar_series = np.zeros((num_N, (n_rep + 1)*n_obs+10*n_rep+n_rep*S+1))\n",
    "    for i in range(num_N):\n",
    "        ar_series[i][0] = initial_value  \n",
    "    AR1 = initial_value\n",
    "    AR2 = initial_value\n",
    "    AR3 = initial_value\n",
    "    AR4 = initial_value\n",
    "    for t in range(1, n_gene + 1):\n",
    "        AR1 = ar_coeff[0] * AR1 + noise1[0][t-1]\n",
    "        AR2 = ar_coeff[1] * AR2 + noise1[1][t-1]\n",
    "        AR3 = ar_coeff[2] * AR3 + noise1[2][t-1]\n",
    "        AR4 = ar_coeff[3] * AR4 + noise1[3][t-1]\n",
    "    ar_series[0][0] = AR1 \n",
    "    ar_series[1][0] = AR2 \n",
    "    ar_series[2][0] = AR3 \n",
    "    ar_series[3][0] = AR4 \n",
    "    # Generation of AR data\n",
    "    for t in range((n_rep+1)*n_obs+10*n_rep+n_rep*S+1): \n",
    "        ar_series[0][t] = ar_coeff[0] * ar_series[0][t - 1] + noise2[0][t - 1]\n",
    "        ar_series[1][t] = ar_coeff[1] * ar_series[1][t - 1] + noise2[1][t - 1]\n",
    "        ar_series[2][t] = ar_coeff[2] * ar_series[2][t - 1] + noise2[2][t - 1]\n",
    "        ar_series[3][t] = ar_coeff[3] * ar_series[3][t - 1] + noise2[3][t - 1]\n",
    "        ar_series[4][t] = a1 * ar_series[0][t] + a2 * ar_series[1][t] + noise2[4][t - 1]\n",
    "    n = 0\n",
    "    t_start = 0\n",
    "    t_end = n_obs + S + 1\n",
    "    \n",
    "    # replacing the replication step\n",
    "    while n < n_rep:  \n",
    "        # pause every 10 time points and use the next (number of samples = n_obs) time points\n",
    "        df = pd.DataFrame(ar_series[:, t_start:  t_end])\n",
    "        df.to_excel(fr'C:\\Users\\yhuang73\\Desktop\\data\\array_data_numberofsamples{n_obs}_replicas{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx', index=False, header=False)\n",
    "        t_start += n_obs + 10 \n",
    "        t_end += n_obs + 10\n",
    "        # if t_end > len(ar_series):\n",
    "        #     t_end = len(ar_series)\n",
    "        #     break\n",
    "        n += 1\n",
    "        \n",
    "def Calculation(ar_series_xlsx, ar_coeff, H, S, n):\n",
    "    num_N = 5;P = 4;K = 1;l = 1 \n",
    "    y = [np.zeros((num_N, n_obs+i)) for i in range(S)]\n",
    "    X1 = [[np.zeros((num_N, n_obs)) for i in range(P)] for i in range(S)]\n",
    "    obj_1 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    obj_2 = [np.zeros((P, 1)) for _ in range(S)]  \n",
    "    prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "    proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "    proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "    error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "    error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "    projection_1_norm = np.zeros((S, 1))\n",
    "    projection_2_norm = np.zeros((S, 1))\n",
    "    True_projection = np.array([[2],[3],[0],[0]])/((np.linalg.norm(np.array([[2],[3],[0],[0]]))))\n",
    "    obj_2_avevec = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    obj2_ave = np.zeros((P, 1))\n",
    "    error_11 = 0\n",
    "    prediction_mse_11 = 0\n",
    "    proj_error_11 = 0\n",
    "    \n",
    "    df = pd.read_excel(ar_series_xlsx, header=None)\n",
    "    ar_series = df.to_numpy()\n",
    "    \n",
    "    for a in range(0, S):\n",
    "        y[a] = ar_series[4][a:n_obs+a]\n",
    "        X1[a] = np.concatenate([ar_series[i][a:n_obs+a].reshape(-1, 1) for i in range(P)], axis = 1)\n",
    "    X = X1[0]\n",
    "    edr_est1, M1 = sir_11(X, y[0], H, K)\n",
    "    edr_est1 = compute_eigen(np.linalg.inv(np.cov(X.T)) @ M1 @ np.linalg.inv(np.cov(X.T)), P, K)\n",
    "    if edr_est1[0] < 0:\n",
    "        edr_est1 = -edr_est1\n",
    "    edr_est1 = np.real(edr_est1 / np.linalg.norm(edr_est1))\n",
    "    error_11 += abs(edr_est1[0] / edr_est1[1] - a1/a2)\n",
    "    prediction_mse_11 += MSE(X @ edr_est1, y[0]) \n",
    "    proj_error_11 += np.linalg.norm((proj(edr_est1) - proj(True_projection)), 'fro')**2\n",
    "    V1 = []\n",
    "    for a in range(0, S):\n",
    "        _, M = sir_11(X, y[a], H, K)\n",
    "        V1.append(M)\n",
    "    # objective 1: experiment\n",
    "    for q in range(0, S):\n",
    "        phi = ar_coeff\n",
    "        Q3 = np.zeros((P, P))\n",
    "        for j in range(P):\n",
    "            for k in range(P):\n",
    "                Q3[j, k] = sum((phi[j] ** a) * (np.linalg.inv(np.cov(X.T)) @ V1[a] @ np.linalg.inv(np.cov(X.T)))[j, k] * (phi[k] ** a) for a in range(0, q + 1))\n",
    "        edr_est = compute_eigen(Q3, P, K)\n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        error_1[q] += abs(edr_est[0] / edr_est[1] - a1/a2)\n",
    "        prediction_mse_1[q] += MSE(X @ edr_est, y[0]) \n",
    "        proj_error_1[q] += np.linalg.norm((proj(edr_est) - proj(True_projection)), 'fro')**2      \n",
    "    # objective 2: experiment\n",
    "    for q in range(0, S):\n",
    "        Q4 = np.linalg.inv(np.cov(X1[q].T)) @ V1[q] @ np.linalg.inv(np.cov(X1[q].T))   # multiply np.linalg.inv(np.cov(X1[q].T)), by stationarity, it should cause no influence.\n",
    "        # Q3 = np.linalg.inv(np.cov(X.T)) @ V1[q] @ np.linalg.inv(np.cov(X.T)), if we multiply np.linalg.inv(np.cov(X.T)) like this line, result for q = 0 should be the same.   \n",
    "        K_largest_eigenvectors = compute_eigen(Q4, P, K)\n",
    "        edr_est = np.multiply(np.power(ar_coeff, -q), K_largest_eigenvectors.flatten())   \n",
    "        if edr_est[0] < 0:\n",
    "            edr_est = -edr_est\n",
    "        edr_est = edr_est / np.linalg.norm(edr_est)\n",
    "        obj_2[q] += edr_est.reshape(-1, 1)       \n",
    "    # Average among lags Q\n",
    "    for j in range(S):\n",
    "        for i in range(j, S, 1):\n",
    "            obj_2_avevec[i] += obj_2[j]\n",
    "    for j in range(S):\n",
    "        obj_2_avevec[j] = ave(obj_2_avevec[j], j + 1)\n",
    "    for q in range(0, S):\n",
    "        error_2[q] += abs(obj_2_avevec[q][0] / obj_2_avevec[q][1] - a1/a2)\n",
    "        prediction_mse_2[q] += MSE(X @ obj_2_avevec[q], y[0])\n",
    "        proj_error_2[q] += np.linalg.norm((proj(obj_2_avevec[q]) - proj(True_projection)), 'fro')**2    \n",
    "    return error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2\n",
    "    \n",
    "def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "    num_N = 5;P = 4;K = 1;l = 1\n",
    "    # Exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    # Exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    # exhi_1 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    # exhi_2 = [np.zeros((P, 1)) for _ in range(S)]\n",
    "    error_1 = ave(error_1, n_rep)    \n",
    "    error_2 = ave(error_2, n_rep)\n",
    "    prediction_mse_1 = ave(prediction_mse_1, n_rep)\n",
    "    prediction_mse_2 = ave(prediction_mse_2, n_rep)\n",
    "    proj_error_1 = ave(proj_error_1, n_rep)\n",
    "    proj_error_2 = ave(proj_error_2, n_rep)\n",
    "    index_array = list(range(S))\n",
    "    SIR_values = [error_1[0], prediction_mse_1[0], proj_error_1[0]]\n",
    "    Obj1_optimal_values = [optimal_values(error_1), optimal_values(prediction_mse_1), optimal_values(proj_error_1)]\n",
    "    Obj2_optimal_values = [optimal_values(error_2), optimal_values(prediction_mse_2), optimal_values(proj_error_2)]\n",
    "    Obj1_optimal_Q = [optimal_Q(error_1),optimal_Q(prediction_mse_1),optimal_Q(proj_error_1)]\n",
    "    Obj2_optimal_Q = [optimal_Q(error_2),optimal_Q(prediction_mse_2),optimal_Q(proj_error_2)]\n",
    "    # table\n",
    "    # for i in range(S):\n",
    "    #     exhi_1[i] = error_1[i]\n",
    "    #     exhi_1[i] = np.vstack((exhi_1[i], proj_error_1[i]))\n",
    "    #     exhi_1[i] = np.vstack((exhi_1[i], prediction_mse_1[i]))\n",
    "    #     exhi_1[i] = np.vstack((np.array([[index_array[i]]]), exhi_1[i]))\n",
    "    # for i in range(S):\n",
    "    #     exhi_2[i] = error_2[i]\n",
    "    #     exhi_2[i] = np.vstack((exhi_2[i], proj_error_2[i]))\n",
    "    #     exhi_2[i] = np.vstack((exhi_2[i], prediction_mse_2[i]))\n",
    "    #     exhi_2[i] = np.vstack((np.array([[index_array[i]]]), exhi_2[i]))\n",
    "    return SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q\n",
    "def Graph(H, S, n_rep):\n",
    "    for k in [0.2,0.5,0.8]:\n",
    "        for i in np.arange(0.1, 1.0, 0.1):\n",
    "            sir_values = [[], [], []]\n",
    "            obj1_optimal_values = [[], [], []]\n",
    "            obj2_optimal_values = [[], [], []]\n",
    "            obj1_optimal_Q = [[],[],[]]\n",
    "            obj2_optimal_Q = [[],[],[]]\n",
    "            for j in np.arange(0.1, 1.0, 0.1):\n",
    "                \n",
    "                Prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "                Prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "                Proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "                Proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "                Error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "                Error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "                ar_coeff = [round(val, 1) for val in [j,i,k,k]]\n",
    "                \n",
    "                for n in range(n_rep):\n",
    "                    filepath = fr'C:\\Users\\yhuang73\\Desktop\\data\\array_data_numberofsamples{n_obs}_replicas{n}_AR1_{\"_\".join(map(str, ar_coeff))}.xlsx'\n",
    "                    error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 = Calculation(filepath, ar_coeff, H, S, n)\n",
    "                    # CHECK\n",
    "                    for s in range(S):\n",
    "                        Error_1[s] += error_1[s]\n",
    "                        Prediction_mse_1[s] += prediction_mse_1[s]\n",
    "                        Proj_error_1[s] += proj_error_1[s]\n",
    "                        Error_2[s] += error_2[s]\n",
    "                        Prediction_mse_2[s] += prediction_mse_2[s]\n",
    "                        Proj_error_2[s] += proj_error_2[s]\n",
    "                SIR_values, Obj1_optimal_values, Obj2_optimal_values, Obj1_optimal_Q, Obj2_optimal_Q = Evaluation(Error_1, Prediction_mse_1, Proj_error_1, Error_2, Prediction_mse_2, Proj_error_2, H, S, n_rep)\n",
    "                \n",
    "                for j in range(3):\n",
    "                    sir_values[j].append(SIR_values[j])\n",
    "                    obj1_optimal_values[j].append(Obj1_optimal_values[j])\n",
    "                    obj2_optimal_values[j].append(Obj2_optimal_values[j])\n",
    "                    obj1_optimal_Q[j].append(Obj1_optimal_Q[j])\n",
    "                    obj2_optimal_Q[j].append(Obj2_optimal_Q[j])\n",
    "                    if j == 1:\n",
    "                        sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                        obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                        obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "                    if j == 2:\n",
    "                        sir_values[j] = [np.array([arr.squeeze()]) for arr in sir_values[j]]\n",
    "                        obj1_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj1_optimal_values[j]]\n",
    "                        obj2_optimal_values[j] = [np.array([arr.squeeze()]) for arr in obj2_optimal_values[j]]\n",
    "            for j in range(3):\n",
    "                if j ==0:\n",
    "                    plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j],'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Absolute error')\n",
    "                    plt.savefig(fr'C:\\Users\\yhuang73\\Desktop\\figure\\plot_arcoeff{\"_\".join(map(str, [ round(val, 1) for val in [i,k,k] ]))}_Optimal_Absolute_Error.png', format='png')\n",
    "                    plt.close()\n",
    "                if j ==1:\n",
    "                    plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j], 'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Mse')\n",
    "                    plt.savefig(fr'C:\\Users\\yhuang73\\Desktop\\figure\\plot_arcoeff{\"_\".join(map(str, [ round(val, 1) for val in [i,k,k] ]))}_Optimal_MSE.png', format='png')\n",
    "                    plt.close()\n",
    "                if j ==2:\n",
    "                    plotyy(np.arange(0.1, 1.0, 0.1), sir_values[j], obj1_optimal_values[j], obj2_optimal_values[j], 'SIR', 'obj1','obj2' ,'' , 'from 0.1 to 1, step size 0.1', 'Optimal Risk')\n",
    "                    plt.savefig(fr'C:\\Users\\yhuang73\\Desktop\\figure\\plot_arcoeff{\"_\".join(map(str, [ round(val, 1) for val in [i,k,k] ]))}_Optimal_Risk.png', format='png')\n",
    "                    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a074e79d-0f82-4b26-8f6e-3ed2e278b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction_mse_1 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "Prediction_mse_2 = [np.zeros((1, 1)) for _ in range(S)]\n",
    "Proj_error_1 = [np.zeros((1, )) for _ in range(S)] \n",
    "Proj_error_2 = [np.zeros((1, )) for _ in range(S)] \n",
    "Error_1 = [np.zeros((1, )) for _ in range(S)]\n",
    "Error_2 = [np.zeros((1, )) for _ in range(S)]\n",
    "for n in range(n_rep):\n",
    "    filepath = r'C:\\Users\\yhuang73\\Desktop\\data\\array_data_numberofsamples50_replicas0_AR1_0.1_0.1_0.2_0.2.xlsx'\n",
    "    error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 = Calculation(filepath, ar_coeff, H, S, n)\n",
    "    # CHECK\n",
    "    Error_1 += error_1\n",
    "    Prediction_mse_1 += prediction_mse_1 \n",
    "    Proj_error_1 += proj_error_1\n",
    "    Error_2 += error_2\n",
    "    Prediction_mse_2 += prediction_mse_2\n",
    "    Proj_error_2 += proj_error_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ba1d9c-cab5-4e24-b408-4de954c4921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_coeff=[0.1,0.1,0.2,0.2]; H=5; S=10\n",
    "error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 = Calculation(r'C:\\Users\\yhuang73\\Desktop\\data\\array_data_numberofsamples50_replicas0_AR1_0.1_0.1_0.2_0.2.xlsx', ar_coeff, H, S, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fdacf35-160b-4171-9e67-ce2a1226d305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.1763753]),\n",
       " array([0.17593879]),\n",
       " array([0.17594121]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115]),\n",
       " array([0.17594115])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfaa6eec-b904-432f-9f3f-2755a1897fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import os\n",
    "import shutil\n",
    "folder_path1 = fr'C:\\Users\\yhuang73\\Desktop\\figure'\n",
    "folder_path2 = fr'C:\\Users\\yhuang73\\Desktop\\data'\n",
    "# Remove all files and folders\n",
    "def Removefiles(folder_path):\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # Removes directory and contents            \n",
    "Removefiles(folder_path2)\n",
    "arr = []\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    for j in np.arange(0.1, 1.0, 0.1):\n",
    "        arr.append([i, j, 0.2, 0.2])       \n",
    "        arr.append([i, j, 0.5, 0.5])        \n",
    "        arr.append([i, j, 0.8, 0.8])\n",
    "\n",
    "for index in range(len(arr)):\n",
    "    arr[index] = [round(val, 1) for val in arr[index]]\n",
    "    \n",
    "a1=2; a2=3; initial_value = 0; n_gene = 10000; n_obs = 50; H = 5; S=10; sigma = 5; n_rep = 5\n",
    "for ar_coeff in arr:\n",
    "    Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep)\n",
    "\n",
    "# def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep):\n",
    "#     # def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, n_rep):\n",
    "#     # def Calculation(ar_series_xlsx, H, S, n):\n",
    "#     # def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "#     # def Graph(ar_series_xlsx, SIR_values, obj1_optimal_values, obj2_optimal_values, obj1_optimal_Q, obj2_optimal_Q):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2272a999-cdc5-404e-87fc-c9aa135ac389",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removefiles(folder_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d39a9d1-a140-4483-bfe7-f376078ab848",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rep\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[57], line 274\u001b[0m, in \u001b[0;36mGraph\u001b[1;34m(H, S, n_rep)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_rep):\n\u001b[0;32m    273\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myhuang73\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124marray_data_numberofsamples\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_obs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_replicas\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_AR1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39mar_coeff))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 274\u001b[0m     error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2 \u001b[38;5;241m=\u001b[39m \u001b[43mCalculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_coeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# CHECK\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S):\n",
      "Cell \u001b[1;32mIn[57], line 194\u001b[0m, in \u001b[0;36mCalculation\u001b[1;34m(ar_series_xlsx, ar_coeff, H, S, n)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(P):\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(P):\n\u001b[1;32m--> 194\u001b[0m         Q3[j, k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mV1\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m edr_est \u001b[38;5;241m=\u001b[39m compute_eigen(Q3, P, K)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edr_est[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[57], line 194\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(P):\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(P):\n\u001b[1;32m--> 194\u001b[0m         Q3[j, k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((phi[j] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m a) \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m@\u001b[39m V1[a] \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(np\u001b[38;5;241m.\u001b[39mcov(X\u001b[38;5;241m.\u001b[39mT)))[j, k] \u001b[38;5;241m*\u001b[39m (phi[k] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    195\u001b[0m edr_est \u001b[38;5;241m=\u001b[39m compute_eigen(Q3, P, K)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edr_est[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\function_base.py:2747\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2746\u001b[0m     X_T \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m*\u001b[39mw)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 2747\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_T\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2748\u001b[0m c \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrue_divide(\u001b[38;5;241m1\u001b[39m, fact)\n\u001b[0;32m   2749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Graph(H, S, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f238563-b85a-430c-9423-922944dee5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86c587-c4d7-4290-8d06-c2bb2938be8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910e7ee-33dc-48c0-a878-1533066fcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import os\n",
    "import shutil\n",
    "folder_path1 = fr'C:\\Users\\yhuang73\\Desktop\\figure'\n",
    "folder_path2 = fr'C:\\Users\\yhuang73\\Desktop\\data'\n",
    "# Remove all files and folders\n",
    "def Removefiles(folder_path):\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # Removes directory and contents            \n",
    "Removefiles(folder_path2)\n",
    "arr = []\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    for j in np.arange(0.1, 1.0, 0.1):\n",
    "        arr.append([i, j, 0.2, 0.2])       \n",
    "        arr.append([i, j, 0.5, 0.5])        \n",
    "        arr.append([i, j, 0.8, 0.8])\n",
    "\n",
    "for index in range(len(arr)):\n",
    "    arr[index] = [round(val, 1) for val in arr[index]]\n",
    "    \n",
    "a1=2; a2=3; initial_value = 0; n_gene = 10000; n_obs = 1000; H = 5; S=10; sigma = 5; n_rep = 100\n",
    "for ar_coeff in arr:\n",
    "    Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep)\n",
    "# def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, sigma, n_rep):\n",
    "#     # def Generation(ar_coeff, a1, a2, initial_value, n_gene, n_obs, H, S, n_rep):\n",
    "#     # def Calculation(ar_series_xlsx, H, S, n):\n",
    "#     # def Evaluation(error_1, prediction_mse_1, proj_error_1, error_2, prediction_mse_2, proj_error_2, H, S, n_rep):\n",
    "#     # def Graph(ar_series_xlsx, SIR_values, obj1_optimal_values, obj2_optimal_values, obj1_optimal_Q, obj2_optimal_Q):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f118e-2fca-4acb-a468-2a5049c40979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7362e-05a6-4c2c-afc7-df8138d4bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
